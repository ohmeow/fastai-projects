{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, shutil\n",
    "sys.path.append('../../../fastai')\n",
    "\n",
    "# this file contains all the main external libs used\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH = '../../datasets/in-or-out'\n",
    "PATH = 'data/in-or-out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet34\n",
    "sz = 224\n",
    "bsz = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(f'{DS_PATH}/train')\n",
    "shutil.rmtree(f'{DS_PATH}/test')\n",
    "shutil.rmtree(f'{DS_PATH}/valid')\n",
    "shutil.rmtree(f'{DS_PATH}/sample')\n",
    "\n",
    "CLASSES = [ os.path.basename(d) for d in glob(os.path.join(DS_PATH, '*')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = glob(f'{DS_PATH}/*/*')\n",
    "\n",
    "for f in g:\n",
    "    img = PIL.Image.open(f)\n",
    "    if (img.mode == 'P' and img.format == 'PNG' and not f.endswith('.jpg')):\n",
    "        img = scipy.misc.imread(f, mode='RGBA')\n",
    "        img = PIL.Image.fromarray(img)\n",
    "        img.save(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove gif and jpegs with weird transparency settings\n",
    "g = glob(f'{DS_PATH}/*/*')\n",
    "for f in g:\n",
    "    img = PIL.Image.open(f)\n",
    "    if (img.mode == 'P'):\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train, validation, test, and sample dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in CLASSES:\n",
    "    os.makedirs(f'{DS_PATH}/train/{d}', exist_ok=True)\n",
    "    os.makedirs(f'{DS_PATH}/valid/{d}', exist_ok=True)\n",
    "    os.makedirs(f'{DS_PATH}/sample/train/{d}', exist_ok=True)\n",
    "    os.makedirs(f'{DS_PATH}/sample/valid/{d}', exist_ok=True)\n",
    "    \n",
    "os.makedirs(f'{DS_PATH}/sample/test/unknown', exist_ok=True)\n",
    "os.makedirs(f'{DS_PATH}/test/unknown', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move training, validation, and test data into appropriate sub-dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY images into /train directory\n",
    "for d in CLASSES:\n",
    "    for f in os.listdir(f'{DS_PATH}/{d}'): \n",
    "        if (not f.startswith('.')): shutil.copyfile(f'{DS_PATH}/{d}/{f}', f'{DS_PATH}/train/{d}/{f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE a subset of /train images into /valid\n",
    "g = glob(f'{DS_PATH}/train/*/*')\n",
    "n_valid = int(len(g) * 0.2)\n",
    "\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(n_valid): os.rename(shuf[i], shuf[i].replace('train', 'valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy a small subset of training data into /sample dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPY a small subset of each class into /sample\n",
    "g = glob(f'{DS_PATH}/train/*/*')\n",
    "\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(100): shutil.copyfile(shuf[i], shuf[i].replace('train', 'sample/train'))\n",
    "    \n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): shutil.copyfile(shuf[i], shuf[i].replace('train', 'sample/valid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}/models', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/tmp', exist_ok=True)\n",
    "\n",
    "abs_ds_path = os.path.abspath(DS_PATH)\n",
    "\n",
    "# symlink to root datasets so can use same data in other projects\n",
    "!ln -s {abs_ds_path}/train {PATH}\n",
    "!ln -s {abs_ds_path}/valid {PATH}\n",
    "!ln -s {abs_ds_path}/test {PATH}\n",
    "!ln -s {abs_ds_path}/sample {PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Review Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = glob(f'{PATH}/train/*/*')\n",
    "size_d = {f: PIL.Image.open(f).size for f in g}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz, col_sz = list(zip(*size_d.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz = np.array(row_sz); col_sz=np.array(col_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(row_sz[row_sz<1000])\n",
    "plt.show()\n",
    "plt.hist(col_sz[col_sz<1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "**Review: easy steps to train a world-class image classifier:**\n",
    "1. Enable data augmentation, and precompute=True\n",
    "1. Use lr_find() to find highest learning rate where loss is still clearly improving\n",
    "1. Train last layer from precomputed activations for 1-2 epochs\n",
    "1. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "1. Unfreeze all layers\n",
    "1. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "1. Use lr_find() again\n",
    "1. Train full network with cycle_mult=2 until over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the below if you need to reset your precomputed activations\n",
    "!rm -rf {PATH}/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Enable data augmentation, and precompute=True\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, bs=bsz, tfms=tfms)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use lr_find() to find highest learning rate where loss is still clearly improving\n",
    "lrf = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.sched.plot_lr()\n",
    "# plt.show()\n",
    "learn.sched.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train last layer from precomputed activations for 1-2 epochs\n",
    "learn.fit(1e-3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "learn.precompute = False\n",
    "learn.fit(1e-3, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Unfreeze all layers\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "lr = np.array([1e-5, 1e-4, 1e-3])\n",
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Use lr_find() again\n",
    "lrf = learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Train full network with cycle_mult=2 until over-fitting\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, shutil\n",
    "sys.path.append('../../../fastai')\n",
    "\n",
    "# this file contains all the main external libs used\n",
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH = '../../../../_datasets/kaggle_dog-breed-identification'\n",
    "# DS_PATH = '../../../datasets/kaggle_dog-breed-identification'\n",
    "\n",
    "PATH = 'data/kaggle_dog-breed-identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet34\n",
    "sz = 224\n",
    "bsz = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}/models', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/tmp', exist_ok=True)\n",
    "\n",
    "abs_ds_path = os.path.abspath(DS_PATH)\n",
    "\n",
    "# symlink to root datasets so can use same data in other projects\n",
    "!ln -s {abs_ds_path}/train {PATH}\n",
    "!ln -s {abs_ds_path}/test {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv = f'{DS_PATH}/labels.csv'\n",
    "\n",
    "labels_df = pd.read_csv(labels_csv)\n",
    "n = len(labels_df)\n",
    "\n",
    "print(n)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cross validation indexes using fastai framework (default = %20 of train)\n",
    "val_idxs = get_cv_idxs(n)\n",
    "\n",
    "print(n, len(val_idxs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is the class distribution? (what are 10 most common classes)\n",
    "print(f'Unique classes: {len(labels_df.breed.unique())}')\n",
    "\n",
    "labels_df.pivot_table(index='breed', aggfunc=len).sort_values('id', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the image size distribution? (what is the avg. height(rows) and width(cols))\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "\n",
    "data = ImageClassifierData.from_csv(PATH, csv_fname=f'{DS_PATH}/labels.csv', \n",
    "                                    folder='train', test_name='test', \n",
    "                                    bs=bsz, tfms=tfms, val_idxs=val_idxs, suffix='.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = f'{DS_PATH}/{data.trn_ds.fnames[0]}'; fname\n",
    "img = Image.open(fname)\n",
    "\n",
    "print(img.size)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sizes = { fname: Image.open(f'{DS_PATH}/{fname}').size for fname in data.trn_ds.fnames }\n",
    "trn_sizes[data.trn_ds.fnames[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sz, col_sz = list(zip(*trn_sizes.values()))\n",
    "\n",
    "row_sz = np.array(row_sz)\n",
    "col_sz = np.array(col_sz)\n",
    "\n",
    "print(f'Average image size (H x W): {int(row_sz.mean())} x {int(col_sz.mean())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height distribution\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4) )\n",
    "ax1.hist(row_sz)\n",
    "ax2.hist(row_sz[row_sz < 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width distribution\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4) )\n",
    "ax1.hist(col_sz)\n",
    "ax2.hist(col_sz[col_sz < 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "**Review: easy steps to train a world-class image classifier:**\n",
    "1. Enable data augmentation, and precompute=True\n",
    "1. Use lr_find() to find highest learning rate where loss is still clearly improving\n",
    "1. Train last layer from precomputed activations for 1-2 epochs\n",
    "1. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "1. Unfreeze all layers\n",
    "1. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "1. Use lr_find() again\n",
    "1. Train full network with cycle_mult=2 until over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sz, bsz, val_idxs=[0], test_name='test'):\n",
    "    # 20171112 - due to current bug in framework, you can't set val_idxs=None so we\n",
    "    #            set it to [0] which will use all but 1 example for training\n",
    "    \n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "\n",
    "    data = ImageClassifierData.from_csv(PATH, csv_fname=f'{DS_PATH}/labels.csv', \n",
    "                                        folder='train', test_name=test_name, \n",
    "                                        bs=bsz, tfms=tfms, val_idxs=val_idxs, suffix='.jpg')\n",
    "\n",
    "    # Why is minimum size 300?\n",
    "    # see http://forums.fast.ai/t/dog-breed-identification-challenge/7464/53?u=wgpubs\n",
    "    # \"Since we have max_zoom=1.1, I figured we should ensure our images are at release sz*1.1\n",
    "    # and I figured resizing them to 340x340 would save plenty of time, and leave plenty of room to experiment.\n",
    "    return data if sz > 300 else data.resize(340, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Enable data augmentation, and precompute=True\n",
    "data = get_data(sz, bsz, val_idxs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=True, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use lr_find() to find highest learning rate where loss is still clearly improving\n",
    "learn.lr_find()\n",
    "\n",
    "learn.sched.plot_lr(); plt.show()\n",
    "learn.sched.plot(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train last layer from precomputed activations for 1-2 epochs\n",
    "lr = 1e-2\n",
    "\n",
    "learn.fit(lr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Train last layer with data augmentation (i.e. precompute=False) for 2-3 epochs with cycle_len=1\n",
    "learn.precompute = False\n",
    "\n",
    "learn.fit(lr, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underfitting, means cycle_len = 1 is too short ... e.g., is popping out before it finds something better\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "accuracy(log_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('rn34_224_step4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('rn34_224_step4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WILL NOT DO IN THIS PROBLEM - Because the training dataset is so similar to original training dataset,\n",
    "# trainign the convolutional layers will not improve network (in fact, this set is a subset of\n",
    "# ImageNet, the same dataset that our pre-trained model was trained on)\n",
    "\n",
    "# 5. Unfreeze all layers\n",
    "# learn.unfreeze()\n",
    "\n",
    "# 6. Set earlier layers to 3x-10x lower learning rate than next higher layer\n",
    "# lr = np.array([1e-7, 1e-6, 1e-5])\n",
    "\n",
    "# 7. Use lr_find() again\n",
    "# learn.lr_find(lr/1000)\n",
    "# learn.sched.plot()\n",
    "\n",
    "# update differential lrs if lr_find() informs us too.\n",
    "\n",
    "# 8. Train full network with cycle_mult=2 until over-fitting\n",
    "# learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n",
    "# learn.save('rn34_224_step8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Continue training on larger images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try increasing the size; moving to larger images can help reduce overfitting\n",
    "learn.set_data(get_data(299, bsz, val_idxs))\n",
    "\n",
    "learn.freeze() # just to make sure that every layer EXCEPT the last is frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# underfitting so add cycle_mult to give learner a chance to find best parameters before jumping out\n",
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last scores: [ 6.       0.53188  0.39652  0.87951]   \n",
    "log_preds, y = learn.TTA()\n",
    "accuracy(log_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('rn34_229_step4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('rn34_229_step4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Try using K-Fold CV - TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset hyperparams\n",
    "lr = 1e-2; sz=224; bsz=10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# get folds\n",
    "kfolds = [ (train_idxs, val_idxs) for train_idxs, val_idxs in skf.split(labels_df.id, labels_df.breed) ]\n",
    "print(len(kfolds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz, bsz, kfolds[0][1], test_name=None)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False, ps=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

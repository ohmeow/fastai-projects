{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31maclImdb_v1.tar.gz\u001b[0m  imdbEr.txt  imdb.vocab  \u001b[01;34mmodels\u001b[0m/  README  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH = 'data/aclImdb'\n",
    "\n",
    "os.makedirs(f'{PATH}/train/all', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/test/all', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/models', exist_ok=True)\n",
    "os.makedirs(f'{PATH}/tmp', exist_ok=True)\n",
    "\n",
    "TRN_PATH = 'train/all'\n",
    "VAL_PATH = 'test/all'\n",
    "\n",
    "TRN = f'{PATH}/{TRN_PATH}'\n",
    "VAL = f'{PATH}/{VAL_PATH}'\n",
    "\n",
    "# !!cp -r {PATH}/train/pos/* {TRN}/\n",
    "# !!cp -r {PATH}/train/neg/* {TRN}/\n",
    "# !!cp -r {PATH}/train/unsup/* {TRN}/ # have to run this line in terminal for it to work!\n",
    "\n",
    "# !!cp -r {PATH}/test/pos/* {VAL}/\n",
    "# !!cp -r {PATH}/test/neg/* {VAL}/\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in /train/all: 25001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0_3.txt',\n",
       " '0_9.txt',\n",
       " '10000_4.txt',\n",
       " '10000_8.txt',\n",
       " '10001_10.txt',\n",
       " '10001_4.txt',\n",
       " '10002_1.txt',\n",
       " '10002_7.txt',\n",
       " '10003_1.txt',\n",
       " '10003_8.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each review is stored as an individual text file\n",
    "trn_files = !ls {TRN}\n",
    "\n",
    "print(f'Total files in /train/all: {len(trn_files)}')\n",
    "trn_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry everyone,,, I know this is supposed to be an \"art\" film,, but wow, they should have handed out guns at the screening so people could blow their brains out and not watch. Although the scene design and photographic direction was excellent, this story is too painful to watch. The absence of a sound track was brutal. The loooonnnnng shots were too long. How long can you watch two people just sitting there and talking? Especially when the dialogue is two people complaining. I really had a hard time just getting through this film. The performances were excellent, but how much of that dark, sombre, uninspired, stuff can you take? The only thing i liked was Maureen Stapleton and her red dress and dancing scene. Otherwise this was a ripoff of Bergman. And i\\'m no fan f his either. I think anyone who says they enjoyed 1 1/2 hours of this is,, well, lying.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example review\n",
    "review = !cat {TRN}/{trn_files[6]}\n",
    "review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17486581\r\n"
     ]
    }
   ],
   "source": [
    "# how many words in the dataset (train)\n",
    "!find {TRN} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5686719\r\n"
     ]
    }
   ],
   "source": [
    "# how many words in the dataset (val)\n",
    "!find {VAL} -name '*.txt' | xargs cat | wc -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sorry everyone , , , I know this is supposed to be an \" art \" film , , but wow , they should have handed out guns at the screening so people could blow their brains out and not watch . Although the scene design and photographic direction was excellent , this story is too painful to watch . The absence of a sound track was brutal . The loooonnnnng shots were too long . How long can you watch two people just sitting there and talking ? Especially when the dialogue is two people complaining . I really had a hard time just getting through this film . The performances were excellent , but how much of that dark , sombre , uninspired , stuff can you take ? The only thing i liked was Maureen Stapleton and her red dress and dancing scene . Otherwise this was a ripoff of Bergman . And i \\'m no fan f his either . I think anyone who says they enjoyed 1 1/2 hours of this is , , well , lying .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize = split each sentence into a list of words\n",
    "' '.join(spacy_tok(review[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# createa torchtext field = describes how to preprocess a piece of text\n",
    "TEXT = data.Field(lower=True, tokenize=spacy_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ModelData object for language modeling\n",
    "bs = 8 #64\n",
    "bptt = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/nlp.py\u001b[0m(310)\u001b[0;36mfrom_text_files\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    308 \u001b[0;31m                                    path, text_field=field, train=train, validation=validation, test=test)\n",
      "\u001b[0m\u001b[0;32m    309 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 310 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    311 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    312 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "\n",
    "# min_freq = 10 says, \"treat any word that appears less than 10 times as the word <unk>\"\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after building the ModelData object, TEXT.vocab is set.  because this will be needed again, save it\n",
    "pickle.dump(TEXT, open(f'{PATH}/models/TEXT.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12257, 20270, 1, 6864658)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batches\n",
    "# of unique tokens in vocab\n",
    "# of items in training set (as LanguageModel is concerned, there is only one thing, the whole corpus)\n",
    "# of words\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is', 'it', 'in']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int to string mapping\n",
    "TEXT.vocab.itos[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string to int mapping\n",
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'movies',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'very',\n",
       " 'nostalgic',\n",
       " 'ending',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a LanguageModelData object there is only one item in each dataset: all the words joined together\n",
    "md.trn_ds[0].text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   37\n",
       "    7\n",
       "   72\n",
       "  519\n",
       "  114\n",
       "    3\n",
       "   22\n",
       "    6\n",
       "   66\n",
       " 4451\n",
       "  288\n",
       "    4\n",
       "[torch.cuda.LongTensor of size 12x1 (GPU 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchtext will handle turning this words into integer Ids\n",
    "TEXT.numericalize([md.trn_ds[0].text[:12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 8])\n",
      "torch.Size([648])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "     37    690     74     28  17528   3332    547    585\n",
       "      7      4     10     32     21     17   1284      4\n",
       "     72     38     16    439   9002      0     23     18\n",
       "    519     13   5140   2935      3    230      5     12\n",
       "    114     19     14      8    232     66    109    252\n",
       "      3     44     34     79     20  13537     10    112\n",
       "     22    439    857      6     58     29    233   5751\n",
       "      6    404  12157  11570     28     59      5      8\n",
       "     66     23     96      7     32     22   2728   1739\n",
       "   4451      4     36   1789    277    104      2      4\n",
       "    288     53    511   1512     41    125    183     12\n",
       "      4     30      8      4  11081      2   2435   3447\n",
       "      2     36    350     20     16   1049  12952    163\n",
       "     23  10727   1690     12  13552     17      5    478\n",
       "      9     11      0    315  15688    555   2980    134\n",
       "     54     43      4     41   2720      5     20      2\n",
       "      2   1362     10      2      7      2     13     23\n",
       "   3049   3302     16    388    173   1308     23   6411\n",
       "    228     51     44      7    765    112     56      8\n",
       "      3    488   2515     13      4     26      4     72\n",
       "    546  10939    249    733     24      5   1284   8369\n",
       "    488      4      4      3     53     33     25      3\n",
       "   3049    213   2838     71     30    311    242    592\n",
       "     29     32  12118    164     36     34     19      0\n",
       "      2    102      9     13   4514    118   1046      4\n",
       "    331    168     63     23      4    482    501     18\n",
       "     26      3      7      9    270  13587      3      0\n",
       "      9     24      6    199   2530      3     10     40\n",
       "     37     13   2510   2299      0      2     78     58\n",
       "      7    222     22      5     16    453      8     28\n",
       "      2    344   2041     73   1383     22   1072    158\n",
       "    304     36   1379     36      9      6      2   3534\n",
       "   1057     80      5   7030    145    487    696      8\n",
       "      7    260    118     41     11    482    156    345\n",
       "      2    230     24    762      2  12384    107     13\n",
       "   3483     11     10      3    208      4   2435    241\n",
       "      3    483     16     10    152   3434      3      3\n",
       "      2      4    400      9      3     16    467     12\n",
       "    453     71  17643    381     49    235      5    207\n",
       "      8     80      4     88     16      6    129     10\n",
       "    147    102   2887     63    777    735     17     21\n",
       "     10    129     38   3308      7    255     49   2491\n",
       "     13     91     13     87   2443      7     19     14\n",
       "    110     31    652    105      3    230     70     28\n",
       "      3   5774     57      7  13174    172   8315    158\n",
       "      5     13      8   3227   6862     11     57    468\n",
       "     44     23     36     16      8  14033     22    123\n",
       "   2786     16      6    114      2  15824     63      2\n",
       "     37    651     23      4  10736   3705    717     23\n",
       "      4    772     54    391     11      3     51      3\n",
       "     37      4      2     33      2     24   1219      5\n",
       "      7     13    874     96    279     34   4910     28\n",
       "      2     23   1164   1739     17    699  16909    198\n",
       "    363      9      7      8   1997  16206      4    163\n",
       "    500     44      2   4444      8     11      6    277\n",
       "      8    412  11369     20    111      2    858     21\n",
       "    137   8191     11      6      4     23    106     37\n",
       "      2    190    173   1627     24      9     51      7\n",
       "    170   2465    765      4     11    344   2515    120\n",
       "      7    428      4     12   3552    899   1284    197\n",
       "     34      4     59     73     22      4     23     11\n",
       "    331      2     10     76      2     18      9     13\n",
       "     29    105   3648    451    708    205   4115    925\n",
       "      6   1225     19     14     17      2      4     90\n",
       "    404    152      8     33   1793    526     18    472\n",
       "   1321     81    215   4682    545     45     13     26\n",
       "     26    160   2525    723     14   2382     25   5473\n",
       "      3     65      8   1789     10     39    744      0\n",
       "     46      2      6   1512    201      2      8      0\n",
       "     33      0    173      5     14    136     36      7\n",
       "   6001   7610   1164   2002    310      9    285     59\n",
       "     27     81      5     63     19  10224     99     28\n",
       "     34    242    110     11    408   9221   2012   1031\n",
       "    331     80      7      2     41     40     21     19\n",
       "     16   2960    124   5790   2775     12    160     44\n",
       "    521     21      3      7     16     35     45   4876\n",
       "      5  20004     21     15      3    223    247    352\n",
       "     84      4    309  14675     13     93     36     23\n",
       "      3   2830   1917     15    594      6      0      4\n",
       "     33      0      4      4      8    669     22    303\n",
       "   1086  18325     59     38    722    347      2     26\n",
       " [torch.cuda.LongTensor of size 81x8 (GPU 0)], Variable containing:\n",
       "      7\n",
       "      4\n",
       "     10\n",
       "     32\n",
       "     21\n",
       "     17\n",
       "   1284\n",
       "      4\n",
       "     72\n",
       "     38\n",
       "     16\n",
       "    439\n",
       "   9002\n",
       "      0\n",
       "     23\n",
       "     18\n",
       "    519\n",
       "     13\n",
       "   5140\n",
       "   2935\n",
       "      3\n",
       "    230\n",
       "      5\n",
       "     12\n",
       "    114\n",
       "     19\n",
       "     14\n",
       "      8\n",
       "    232\n",
       "     66\n",
       "    109\n",
       "    252\n",
       "      3\n",
       "     44\n",
       "     34\n",
       "     79\n",
       "     20\n",
       "  13537\n",
       "     10\n",
       "    112\n",
       "     22\n",
       "    439\n",
       "    857\n",
       "      6\n",
       "     58\n",
       "     29\n",
       "    233\n",
       "   5751\n",
       "      6\n",
       "    404\n",
       "  12157\n",
       "  11570\n",
       "     28\n",
       "     59\n",
       "      5\n",
       "      8\n",
       "     66\n",
       "     23\n",
       "     96\n",
       "      7\n",
       "     32\n",
       "     22\n",
       "   2728\n",
       "   1739\n",
       "   4451\n",
       "      4\n",
       "     36\n",
       "   1789\n",
       "    277\n",
       "    104\n",
       "      2\n",
       "      4\n",
       "    288\n",
       "     53\n",
       "    511\n",
       "   1512\n",
       "     41\n",
       "    125\n",
       "    183\n",
       "     12\n",
       "      4\n",
       "     30\n",
       "      8\n",
       "      4\n",
       "  11081\n",
       "      2\n",
       "   2435\n",
       "   3447\n",
       "      2\n",
       "     36\n",
       "    350\n",
       "     20\n",
       "     16\n",
       "   1049\n",
       "  12952\n",
       "    163\n",
       "     23\n",
       "  10727\n",
       "   1690\n",
       "     12\n",
       "  13552\n",
       "     17\n",
       "      5\n",
       "    478\n",
       "      9\n",
       "     11\n",
       "      0\n",
       "    315\n",
       "  15688\n",
       "    555\n",
       "   2980\n",
       "    134\n",
       "     54\n",
       "     43\n",
       "      4\n",
       "     41\n",
       "   2720\n",
       "      5\n",
       "     20\n",
       "      2\n",
       "      2\n",
       "   1362\n",
       "     10\n",
       "      2\n",
       "      7\n",
       "      2\n",
       "     13\n",
       "     23\n",
       "   3049\n",
       "   3302\n",
       "     16\n",
       "    388\n",
       "    173\n",
       "   1308\n",
       "     23\n",
       "   6411\n",
       "    228\n",
       "     51\n",
       "     44\n",
       "      7\n",
       "    765\n",
       "    112\n",
       "     56\n",
       "      8\n",
       "      3\n",
       "    488\n",
       "   2515\n",
       "     13\n",
       "      4\n",
       "     26\n",
       "      4\n",
       "     72\n",
       "    546\n",
       "  10939\n",
       "    249\n",
       "    733\n",
       "     24\n",
       "      5\n",
       "   1284\n",
       "   8369\n",
       "    488\n",
       "      4\n",
       "      4\n",
       "      3\n",
       "     53\n",
       "     33\n",
       "     25\n",
       "      3\n",
       "   3049\n",
       "    213\n",
       "   2838\n",
       "     71\n",
       "     30\n",
       "    311\n",
       "    242\n",
       "    592\n",
       "     29\n",
       "     32\n",
       "  12118\n",
       "    164\n",
       "     36\n",
       "     34\n",
       "     19\n",
       "      0\n",
       "      2\n",
       "    102\n",
       "      9\n",
       "     13\n",
       "   4514\n",
       "    118\n",
       "   1046\n",
       "      4\n",
       "    331\n",
       "    168\n",
       "     63\n",
       "     23\n",
       "      4\n",
       "    482\n",
       "    501\n",
       "     18\n",
       "     26\n",
       "      3\n",
       "      7\n",
       "      9\n",
       "    270\n",
       "  13587\n",
       "      3\n",
       "      0\n",
       "      9\n",
       "     24\n",
       "      6\n",
       "    199\n",
       "   2530\n",
       "      3\n",
       "     10\n",
       "     40\n",
       "     37\n",
       "     13\n",
       "   2510\n",
       "   2299\n",
       "      0\n",
       "      2\n",
       "     78\n",
       "     58\n",
       "      7\n",
       "    222\n",
       "     22\n",
       "      5\n",
       "     16\n",
       "    453\n",
       "      8\n",
       "     28\n",
       "      2\n",
       "    344\n",
       "   2041\n",
       "     73\n",
       "   1383\n",
       "     22\n",
       "   1072\n",
       "    158\n",
       "    304\n",
       "     36\n",
       "   1379\n",
       "     36\n",
       "      9\n",
       "      6\n",
       "      2\n",
       "   3534\n",
       "   1057\n",
       "     80\n",
       "      5\n",
       "   7030\n",
       "    145\n",
       "    487\n",
       "    696\n",
       "      8\n",
       "      7\n",
       "    260\n",
       "    118\n",
       "     41\n",
       "     11\n",
       "    482\n",
       "    156\n",
       "    345\n",
       "      2\n",
       "    230\n",
       "     24\n",
       "    762\n",
       "      2\n",
       "  12384\n",
       "    107\n",
       "     13\n",
       "   3483\n",
       "     11\n",
       "     10\n",
       "      3\n",
       "    208\n",
       "      4\n",
       "   2435\n",
       "    241\n",
       "      3\n",
       "    483\n",
       "     16\n",
       "     10\n",
       "    152\n",
       "   3434\n",
       "      3\n",
       "      3\n",
       "      2\n",
       "      4\n",
       "    400\n",
       "      9\n",
       "      3\n",
       "     16\n",
       "    467\n",
       "     12\n",
       "    453\n",
       "     71\n",
       "  17643\n",
       "    381\n",
       "     49\n",
       "    235\n",
       "      5\n",
       "    207\n",
       "      8\n",
       "     80\n",
       "      4\n",
       "     88\n",
       "     16\n",
       "      6\n",
       "    129\n",
       "     10\n",
       "    147\n",
       "    102\n",
       "   2887\n",
       "     63\n",
       "    777\n",
       "    735\n",
       "     17\n",
       "     21\n",
       "     10\n",
       "    129\n",
       "     38\n",
       "   3308\n",
       "      7\n",
       "    255\n",
       "     49\n",
       "   2491\n",
       "     13\n",
       "     91\n",
       "     13\n",
       "     87\n",
       "   2443\n",
       "      7\n",
       "     19\n",
       "     14\n",
       "    110\n",
       "     31\n",
       "    652\n",
       "    105\n",
       "      3\n",
       "    230\n",
       "     70\n",
       "     28\n",
       "      3\n",
       "   5774\n",
       "     57\n",
       "      7\n",
       "  13174\n",
       "    172\n",
       "   8315\n",
       "    158\n",
       "      5\n",
       "     13\n",
       "      8\n",
       "   3227\n",
       "   6862\n",
       "     11\n",
       "     57\n",
       "    468\n",
       "     44\n",
       "     23\n",
       "     36\n",
       "     16\n",
       "      8\n",
       "  14033\n",
       "     22\n",
       "    123\n",
       "   2786\n",
       "     16\n",
       "      6\n",
       "    114\n",
       "      2\n",
       "  15824\n",
       "     63\n",
       "      2\n",
       "     37\n",
       "    651\n",
       "     23\n",
       "      4\n",
       "  10736\n",
       "   3705\n",
       "    717\n",
       "     23\n",
       "      4\n",
       "    772\n",
       "     54\n",
       "    391\n",
       "     11\n",
       "      3\n",
       "     51\n",
       "      3\n",
       "     37\n",
       "      4\n",
       "      2\n",
       "     33\n",
       "      2\n",
       "     24\n",
       "   1219\n",
       "      5\n",
       "      7\n",
       "     13\n",
       "    874\n",
       "     96\n",
       "    279\n",
       "     34\n",
       "   4910\n",
       "     28\n",
       "      2\n",
       "     23\n",
       "   1164\n",
       "   1739\n",
       "     17\n",
       "    699\n",
       "  16909\n",
       "    198\n",
       "    363\n",
       "      9\n",
       "      7\n",
       "      8\n",
       "   1997\n",
       "  16206\n",
       "      4\n",
       "    163\n",
       "    500\n",
       "     44\n",
       "      2\n",
       "   4444\n",
       "      8\n",
       "     11\n",
       "      6\n",
       "    277\n",
       "      8\n",
       "    412\n",
       "  11369\n",
       "     20\n",
       "    111\n",
       "      2\n",
       "    858\n",
       "     21\n",
       "    137\n",
       "   8191\n",
       "     11\n",
       "      6\n",
       "      4\n",
       "     23\n",
       "    106\n",
       "     37\n",
       "      2\n",
       "    190\n",
       "    173\n",
       "   1627\n",
       "     24\n",
       "      9\n",
       "     51\n",
       "      7\n",
       "    170\n",
       "   2465\n",
       "    765\n",
       "      4\n",
       "     11\n",
       "    344\n",
       "   2515\n",
       "    120\n",
       "      7\n",
       "    428\n",
       "      4\n",
       "     12\n",
       "   3552\n",
       "    899\n",
       "   1284\n",
       "    197\n",
       "     34\n",
       "      4\n",
       "     59\n",
       "     73\n",
       "     22\n",
       "      4\n",
       "     23\n",
       "     11\n",
       "    331\n",
       "      2\n",
       "     10\n",
       "     76\n",
       "      2\n",
       "     18\n",
       "      9\n",
       "     13\n",
       "     29\n",
       "    105\n",
       "   3648\n",
       "    451\n",
       "    708\n",
       "    205\n",
       "   4115\n",
       "    925\n",
       "      6\n",
       "   1225\n",
       "     19\n",
       "     14\n",
       "     17\n",
       "      2\n",
       "      4\n",
       "     90\n",
       "    404\n",
       "    152\n",
       "      8\n",
       "     33\n",
       "   1793\n",
       "    526\n",
       "     18\n",
       "    472\n",
       "   1321\n",
       "     81\n",
       "    215\n",
       "   4682\n",
       "    545\n",
       "     45\n",
       "     13\n",
       "     26\n",
       "     26\n",
       "    160\n",
       "   2525\n",
       "    723\n",
       "     14\n",
       "   2382\n",
       "     25\n",
       "   5473\n",
       "      3\n",
       "     65\n",
       "      8\n",
       "   1789\n",
       "     10\n",
       "     39\n",
       "    744\n",
       "      0\n",
       "     46\n",
       "      2\n",
       "      6\n",
       "   1512\n",
       "    201\n",
       "      2\n",
       "      8\n",
       "      0\n",
       "     33\n",
       "      0\n",
       "    173\n",
       "      5\n",
       "     14\n",
       "    136\n",
       "     36\n",
       "      7\n",
       "   6001\n",
       "   7610\n",
       "   1164\n",
       "   2002\n",
       "    310\n",
       "      9\n",
       "    285\n",
       "     59\n",
       "     27\n",
       "     81\n",
       "      5\n",
       "     63\n",
       "     19\n",
       "  10224\n",
       "     99\n",
       "     28\n",
       "     34\n",
       "    242\n",
       "    110\n",
       "     11\n",
       "    408\n",
       "   9221\n",
       "   2012\n",
       "   1031\n",
       "    331\n",
       "     80\n",
       "      7\n",
       "      2\n",
       "     41\n",
       "     40\n",
       "     21\n",
       "     19\n",
       "     16\n",
       "   2960\n",
       "    124\n",
       "   5790\n",
       "   2775\n",
       "     12\n",
       "    160\n",
       "     44\n",
       "    521\n",
       "     21\n",
       "      3\n",
       "      7\n",
       "     16\n",
       "     35\n",
       "     45\n",
       "   4876\n",
       "      5\n",
       "  20004\n",
       "     21\n",
       "     15\n",
       "      3\n",
       "    223\n",
       "    247\n",
       "    352\n",
       "     84\n",
       "      4\n",
       "    309\n",
       "  14675\n",
       "     13\n",
       "     93\n",
       "     36\n",
       "     23\n",
       "      3\n",
       "   2830\n",
       "   1917\n",
       "     15\n",
       "    594\n",
       "      6\n",
       "      0\n",
       "      4\n",
       "     33\n",
       "      0\n",
       "      4\n",
       "      4\n",
       "      8\n",
       "    669\n",
       "     22\n",
       "    303\n",
       "   1086\n",
       "  18325\n",
       "     59\n",
       "     38\n",
       "    722\n",
       "    347\n",
       "      2\n",
       "     26\n",
       "    794\n",
       "   1484\n",
       "     97\n",
       "    113\n",
       "      2\n",
       "      7\n",
       "    764\n",
       "   5473\n",
       " [torch.cuda.LongTensor of size 648 (GPU 0)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(md.trn_dl))\n",
    "print(batch[0].size()), print(batch[1].size())\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_sz = 200       # size of each embedding vector\n",
    "nh = 500           # of hidden activations per layer\n",
    "nl = 3             # of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for NLP, configure Adam to use less momentum than the defaul of 0.9\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(72)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLockedDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropouti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLockedDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropouth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(145)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    143 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLockedDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtie_encoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtie_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 145 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    146 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    147 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "learner = md.get_model(opt_fn, emb_sz, nh, nl,\n",
    "                      dropouti=0.24, dropout=0.025, wdrop=0.05, dropoute=0.01, dropouth=0.025)\n",
    "\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf = learner.lr_find() # took about 20 mins on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038f0221686b48d69d5744f218177f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                  \n",
      "    0      5.173734   5.053396  \n",
      "    1      4.950676   4.841609                                  \n",
      "    2      4.8607     4.77143                                   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.7714305]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 2, wds=1e-6, cycle_len=1, cycle_mult=2) # took about "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('imdb_adam1_enc')\n",
    "# learner.load_encoder('imdb_adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(3e-3, 4, wds=1e-6, cycle_len=10, cycle_save_name='imdb_adam2_4_10')\n",
    "learner.fit(3e-3, 2, wds=1e-6, cycle_len=10, cycle_save_name='imdb_adam2_c2_cl10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('imdb_adam2_enc')\n",
    "# learner.load_encoder('imdb_adam2_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='imdb_adam2_1_20')\n",
    "learner.fit(3e-4, 1, wds=1e-6, cycle_len=10, cycle_save_name='imdb_adam3_c1_cl10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('imdb_adam3_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_cycle('imdb_adam2_c2_cl10', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric perplexity (how language model accuracy generally measured) = exp() of loss functino\n",
    "np.exp(4.21699)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\". I could n't believe this movie was so scary , but I loved it . The best part\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a short bit of text to \"prime\" the precitions, then use torchtext to numericalize it\n",
    "# so we can feed it into our language model\n",
    "m = learner.model\n",
    "ss = \"\"\". So, it wasn't quite what I was expecting, but I really liked it anways! The best\"\"\"\n",
    "ss = \"\"\". I couldn't believe this movie was so scary, but I loved it. The best part\"\"\"\n",
    "s = [spacy_tok(ss)]\n",
    "t = TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[0].bs = 1      # set batch size = 1\n",
    "m.eval()         # turn-off dropout\n",
    "m.reset()        # reset hidden state\n",
    "res, *_ = m(t)   # get predictions from model\n",
    "m[0].bs = bs     # put batch size back to what it was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-1].size()   # the prediction based on the full sentence; the last prediction\n",
    "len(res)         # the number of words in \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['of', 'is', 'was', ',', '.', ':', 'in', 'about', 'for', 'i']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 predictions for next word\n",
    "nexts = torch.topk(res[-1], 10)[1]           # return the 10 indexes of the top 10 predictions\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". I couldn't believe this movie was so scary, but I loved it. The best part \n",
      "\n",
      "of the film , and the film is a bit too long . \n",
      "\n",
      " the film is a bit of a good movie , but it is a very good movie . <eos> i have seen this movie on dvd and i was expecting a lot of fun . i ...\n"
     ]
    }
   ],
   "source": [
    "# try to generate more text\n",
    "print(ss, \"\\n\")\n",
    "\n",
    "for i in range(50):\n",
    "    n = res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0] == 0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res, *_ = m(n[0].unsqueeze(0))\n",
    "    \n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8 #64\n",
    "bptt = 70\n",
    "\n",
    "emb_sz = 200       # size of each embedding vector\n",
    "nh = 500           # of hidden activations per layer\n",
    "nl = 3             # of layers\n",
    "\n",
    "# for NLP, configure Adam to use less momentum than the defaul of 0.9\n",
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same vocab built from the language model so as to ensure words map to same Ids\n",
    "TEXT = pickle.load(open(f'{PATH}/models/TEXT.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB_LABEL = data.Field(sequential=False)\n",
    "splits = torchtext.datasets.IMDB.splits(TEXT, IMDB_LABEL, 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = splits[0].examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pos', 'one of my favorite movies , with a very nostalgic')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.label, ' '.join(t.text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/nlp.py\u001b[0m(355)\u001b[0;36mfrom_splits\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    353 \u001b[0;31m                 else len(getattr(splits[0][0], label_name)))\n",
      "\u001b[0m\u001b[0;32m    354 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 355 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    356 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    357 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mto_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> obj.bs\n",
      "8\n",
      "ipdb> objs.pad_idx\n",
      "*** NameError: name 'objs' is not defined\n",
      "ipdb> obj.pad_idx\n",
      "1\n",
      "ipdb> obj.nt\n",
      "20270\n",
      "ipdb> obj.c\n",
      "3\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "# fastai can create a ModelData object directly from torchtext splits\n",
    "md2 = TextData.from_splits(PATH, splits, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(72)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     70 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLockedDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropouti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     71 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLockedDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropouth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 72 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     74 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(172)\u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    170 \u001b[0;31m        self.layers = nn.ModuleList([\n",
      "\u001b[0m\u001b[0;32m    171 \u001b[0;31m            LinearBlock(layers[i], layers[i + 1], drops[i]) for i in range(len(layers) - 1)])\n",
      "\u001b[0m\u001b[0;32m--> 172 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    173 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    174 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(self.layers)\n",
      "1\n",
      "ipdb> len(layers)\n",
      "2\n",
      "ipdb> layers\n",
      "[600, 3]\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "m3 = md2.get_model(opt_fn, 1500, bptt, emb_sz=emb_sz, n_hid=nh, n_layers=nl,\n",
    "                      dropout=0.1, dropouti=0.4, wdrop=0.5, dropoute=0.05, dropouth=0.3)\n",
    "\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.load_encoder(f'imdb_adam1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(20270, 200, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(20270, 200, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(200, 500, dropout=0.3)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(500, 500, dropout=0.3)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(500, 200, dropout=0.3)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): ModuleList(\n",
       "      (0): LinearBlock(\n",
       "        (lin): Linear(in_features=600, out_features=3)\n",
       "        (drop): Dropout(p=0.1)\n",
       "        (bn): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 # contains two models, the first is an instance of RNN_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.clip = 25.\n",
    "lrs = np.array([1e-4, 1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5cd10993c14f608cb41c5d4239ccf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3124 [00:00<?, ?it/s]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input.size()\n",
      "torch.Size([189, 8])\n",
      "ipdb> self.bptt\n",
      "70\n",
      "ipdb> 70*3\n",
      "210\n",
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input\n",
      "([Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  3.0482e-01  1.4634e-02  8.2850e-08  ...  -2.9924e-03 -2.5956e-02 -1.6865e-02\n",
      "  6.2726e-01 -2.3886e-02  4.5073e-05  ...  -1.3863e-03 -6.5185e-03 -2.8018e-02\n",
      "  1.6438e-03 -4.1667e-01  5.9774e-02  ...  -1.5805e-01 -1.0211e-02 -3.7333e-02\n",
      "                 ...                                      ...                \n",
      "  7.2423e-01  1.3097e-01 -2.1679e-06  ...  -2.1566e-04 -2.4592e-02 -3.8522e-02\n",
      " -1.4999e-01 -8.2773e-07  2.9512e-06  ...  -1.4369e-05 -4.7184e-02 -5.1053e-02\n",
      "  7.4440e-01  2.6489e-01 -9.4652e-04  ...  -2.3397e-04  1.7172e-02 -3.2194e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  8.5194e-04  4.0759e-02  3.5672e-02  ...  -7.4968e-02 -1.8334e-03 -3.2396e-02\n",
      "  1.8823e-01  6.3061e-05  2.3715e-02  ...  -1.6540e-05 -2.6546e-03 -3.2292e-02\n",
      "  4.0109e-03 -9.7999e-03  1.8703e-02  ...  -9.9771e-07  7.9307e-03 -4.2351e-02\n",
      "                 ...                                      ...                \n",
      "  1.0892e-02  7.1028e-01  5.7497e-02  ...  -1.3266e-05 -9.8052e-03 -1.1334e-01\n",
      " -2.8333e-02  9.1031e-05  2.8364e-05  ...  -2.1666e-05 -4.5338e-02 -6.4884e-02\n",
      "  2.5185e-02  2.3267e-01  1.2838e-02  ...  -6.0487e-03  1.0820e-02 -7.7712e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  1.6074e-04  2.1414e-05  1.3620e-06  ...  -4.0574e-01  6.2819e-03 -4.1252e-02\n",
      "  1.1482e-02  1.7443e-02  1.1525e-04  ...  -8.9043e-08 -2.9620e-02 -5.1810e-02\n",
      "  4.4337e-04 -1.6344e-03  3.5525e-02  ...  -1.0582e-05 -3.1435e-02 -7.9167e-02\n",
      "                 ...                                      ...                \n",
      "  3.6297e-04  1.7087e-02  1.2970e-05  ...  -1.2981e-03 -2.4413e-02 -4.9162e-02\n",
      "  7.7973e-02  4.6160e-05 -2.4567e-09  ...  -2.5576e-06 -4.4233e-02 -5.8806e-02\n",
      "  3.1185e-01  7.1306e-01  5.6896e-04  ...  -2.3323e-08  3.3800e-02 -8.7065e-02\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  2.7079e-06 -9.5328e-06  8.6096e-07  ...  -7.9614e-01  2.1991e-02 -3.6256e-02\n",
      "  4.9438e-06 -1.0849e-04  2.5437e-08  ...  -9.7668e-01  1.5361e-02 -1.2178e-03\n",
      "  3.3358e-06  2.7108e-07  7.3287e-01  ...  -7.9036e-01 -4.3624e-02 -3.0207e-02\n",
      "                 ...                                      ...                \n",
      "  9.7578e-04  4.7620e-04  1.9502e-02  ...  -5.4415e-01 -3.6366e-02  6.1894e-02\n",
      "  2.7488e-05  6.5740e-02  4.1552e-06  ...  -1.6638e-06 -4.1929e-02 -1.5372e-02\n",
      "  4.1504e-05  9.0731e-05  6.7469e-01  ...  -6.3465e-01 -6.5128e-02  3.6681e-02\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4739e-04  3.0897e-05  2.0540e-01  ...  -1.4993e-02 -2.0515e-02 -3.4562e-02\n",
      "  1.5102e-04  2.1618e-05  1.1724e-01  ...  -8.9447e-03 -3.4510e-03 -1.1626e-02\n",
      "  4.0878e-08 -1.0973e-06  3.8190e-07  ...  -9.5726e-01 -1.7946e-02 -1.8095e-02\n",
      "                 ...                                      ...                \n",
      "  1.1736e-04 -4.5455e-06  5.1348e-05  ...  -9.8585e-01 -1.7128e-02  4.1561e-03\n",
      "  2.1084e-07  3.1649e-03  2.2568e-04  ...  -2.9503e-04 -2.8721e-02 -5.1907e-02\n",
      "  3.6941e-04  1.5813e-06  4.9644e-02  ...  -5.7854e-01 -3.7431e-02  3.0832e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  9.5869e-04  3.2496e-04  2.7776e-02  ...  -1.8834e-01 -5.4054e-03 -7.6172e-03\n",
      "  9.8977e-03  3.3119e-03  2.5711e-02  ...  -8.8638e-02  1.0494e-02  2.6615e-03\n",
      "  6.9465e-05  9.4429e-05  1.6826e-01  ...  -5.2498e-03 -5.8415e-02 -4.0764e-02\n",
      "                 ...                                      ...                \n",
      "  2.2918e-04  2.7397e-05  4.0743e-01  ...  -6.6446e-03 -6.7171e-02  8.5878e-03\n",
      "  2.6634e-06  6.2242e-10  5.2982e-08  ...  -9.7887e-01 -9.6571e-03 -1.4335e-02\n",
      "  2.0787e-06 -3.2297e-05  9.1702e-05  ...  -9.6644e-01 -2.6391e-02  5.7599e-04\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.8586e-01 -3.6524e-03  1.7137e-01  ...  -2.1141e-02  7.8316e-03 -1.8823e-02\n",
      " -3.2258e-01  3.3381e-03 -2.0310e-02  ...   1.1034e-02  1.6650e-02 -1.2350e-03\n",
      " -2.7754e-04  1.4840e-02  3.0265e-02  ...  -2.0429e-02 -5.5338e-03 -1.6280e-02\n",
      "                 ...                                      ...                \n",
      " -1.2931e-01 -7.5551e-03 -5.1831e-03  ...   7.9998e-04  1.7144e-02 -2.1101e-02\n",
      " -1.3185e-02 -2.6575e-03 -2.6135e-02  ...  -1.8713e-03 -4.5420e-03  7.3233e-03\n",
      " -3.0354e-03  6.4257e-03 -8.8136e-03  ...  -4.1447e-03  1.3313e-02 -5.1777e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -3.9639e-03 -8.5875e-03  1.8987e-02  ...  -5.7346e-03 -2.6880e-03  2.7380e-03\n",
      " -7.8691e-05  3.2879e-03 -2.7629e-02  ...   8.5360e-04  1.1318e-02  1.4976e-02\n",
      " -1.6951e-03 -1.4556e-03  3.4793e-02  ...  -1.5304e-02 -2.0326e-02 -5.4967e-03\n",
      "                 ...                                      ...                \n",
      " -2.2677e-04  2.4840e-03  2.7081e-02  ...   1.3057e-03  2.1121e-02 -3.5998e-03\n",
      " -6.7916e-02  1.2503e-02 -2.0534e-02  ...   1.1090e-02 -2.3694e-03  5.1017e-03\n",
      " -1.7389e-03 -1.8615e-03 -7.1063e-03  ...   5.7457e-03  8.1442e-03 -3.4185e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -2.5414e-05  4.0698e-05  1.1296e-03  ...  -7.4724e-03 -8.0539e-03  3.3686e-03\n",
      " -3.6950e-01 -3.6193e-03  1.0370e-01  ...   3.0464e-03  2.0005e-02  1.1973e-02\n",
      " -5.2493e-01 -1.9142e-04 -9.6760e-02  ...   5.9612e-03  8.3796e-04  5.1845e-03\n",
      "                 ...                                      ...                \n",
      " -8.4017e-01  1.4131e-02  3.6455e-02  ...   2.0885e-02  4.4325e-02  5.3241e-03\n",
      " -6.7454e-01  1.3196e-02 -2.7158e-02  ...   2.5735e-03 -3.7508e-03  3.2704e-02\n",
      " -2.2724e-04 -7.1061e-04  4.9241e-03  ...   5.1006e-03  1.4468e-02 -8.0552e-03\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      " -1.9523e-06  1.5284e-03  1.0179e-04  ...   3.7754e-03 -7.1500e-03  7.5567e-03\n",
      " -1.5294e-06 -8.7278e-03 -9.6089e-03  ...   8.7846e-03 -1.3841e-02 -1.7419e-02\n",
      " -2.0239e-03  9.4058e-03 -4.0304e-02  ...   1.6110e-02 -1.2140e-02 -2.3997e-02\n",
      "                 ...                                      ...                \n",
      " -9.1935e-03  2.5371e-03  2.9069e-02  ...   4.8967e-03  3.1217e-03 -6.4936e-03\n",
      " -9.8736e-04  8.7173e-03 -2.5589e-03  ...   8.0282e-03  1.3701e-03  3.7943e-03\n",
      " -8.2567e-03  5.8601e-03  1.5988e-02  ...   4.6611e-03  3.9467e-03  2.1346e-02\n",
      "\n",
      "(187,.,.) = \n",
      " -9.3389e-04  4.9917e-03 -1.3062e-02  ...   7.6681e-03 -2.3483e-02  7.1285e-03\n",
      " -8.1452e-03 -3.1968e-03 -3.3665e-02  ...   8.3691e-03 -2.5123e-02  4.1028e-03\n",
      " -1.4174e-07  1.2585e-02 -7.2533e-04  ...   7.9287e-03 -1.0427e-02 -2.1964e-02\n",
      "                 ...                                      ...                \n",
      " -3.9472e-06  3.8368e-03  8.4384e-03  ...   4.1650e-03 -9.8401e-03 -1.4598e-02\n",
      " -8.3435e-01  1.3211e-02 -5.7029e-02  ...   2.1040e-02  7.5629e-02  7.6196e-03\n",
      " -1.7163e-03  7.9448e-03  5.2304e-02  ...  -2.6306e-03  5.0965e-03  7.9693e-04\n",
      "\n",
      "(188,.,.) = \n",
      " -5.0105e-04  1.1649e-02 -6.9217e-03  ...   1.5714e-02 -2.9480e-02 -2.1888e-02\n",
      " -3.8948e-03  4.4095e-03 -2.2326e-02  ...   1.5268e-02 -2.2907e-02 -2.0498e-02\n",
      " -6.1418e-03  1.2173e-02 -2.7639e-02  ...   8.5190e-03 -2.1018e-02 -1.1054e-02\n",
      "                 ...                                      ...                \n",
      " -8.1060e-03  2.7829e-03 -2.4881e-02  ...   9.0857e-03 -1.4718e-02  3.6972e-03\n",
      " -1.7911e-06  5.9424e-03  9.1734e-03  ...   1.0131e-03  1.1363e-02  4.1700e-03\n",
      " -6.5393e-07  5.6092e-03  1.3340e-02  ...  -6.2517e-03 -6.0581e-03 -5.9970e-03\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.3501e-01 -1.9047e-02  1.6263e-01  ...  -7.3689e-02 -1.1781e-03  5.7154e-03\n",
      " -2.8141e-02 -3.8059e-02 -2.1128e-01  ...   2.4266e-02 -8.0584e-04  3.7372e-03\n",
      "  3.5554e-02  1.7791e-01 -1.8791e-02  ...  -1.8143e-01  2.4491e-02  5.6532e-02\n",
      "                 ...                                      ...                \n",
      " -1.4464e-01  1.6767e-02  2.3936e-01  ...  -3.5129e-02 -2.6848e-02  1.2881e-02\n",
      "  5.9751e-03  3.5120e-02 -7.0760e-03  ...  -2.4877e-02 -5.9188e-02  4.2381e-02\n",
      " -1.0946e-01  1.7107e-02  3.2354e-01  ...  -3.8421e-03 -8.4416e-03  3.1667e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.6591e-01  4.5821e-04 -1.4173e-02  ...  -8.2288e-02 -5.8149e-02  3.5861e-02\n",
      " -2.3416e-02  1.4861e-01 -1.6804e-01  ...  -8.3639e-02  6.1359e-03  1.4606e-02\n",
      "  1.7186e-01  6.6252e-02 -3.0466e-01  ...  -1.3552e-01 -5.0332e-03  6.1522e-03\n",
      "                 ...                                      ...                \n",
      " -6.9175e-02  2.7616e-01 -2.2785e-02  ...  -1.5282e-01  6.3021e-02  1.0289e-01\n",
      "  1.3848e-01  7.0319e-02 -3.0008e-02  ...   9.2312e-03 -6.9918e-03  5.4655e-03\n",
      " -4.7013e-02  1.2855e-01  1.9026e-01  ...   6.5513e-02  2.6572e-02  2.2439e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.6299e-02  1.1843e-01 -4.4796e-02  ...  -8.6652e-02 -9.5229e-02  1.6042e-02\n",
      "  6.4327e-02 -1.3643e-02  1.7669e-01  ...  -1.7309e-01  8.4070e-05  4.2038e-03\n",
      "  1.4836e-01 -5.3667e-02 -1.7917e-02  ...  -6.1568e-02 -9.9971e-05  4.9490e-04\n",
      "                 ...                                      ...                \n",
      " -2.2454e-01 -1.7050e-03 -1.4839e-01  ...  -7.7029e-03  4.8036e-03  1.8557e-04\n",
      " -3.9649e-02 -1.1931e-02 -3.4963e-02  ...  -9.9262e-03 -1.9601e-03  1.0700e-04\n",
      "  8.0892e-02  4.7321e-02  5.6229e-01  ...   5.0001e-02  1.1358e-03  2.7326e-04\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  1.7928e-02  1.9251e-01 -1.4573e-02  ...  -4.0407e-01 -2.5925e-02  5.3220e-03\n",
      " -3.9517e-02  5.6449e-02 -7.5761e-02  ...  -2.5972e-01 -2.1295e-02  5.6291e-04\n",
      "  2.0657e-02 -3.8236e-03 -2.5147e-01  ...  -1.0668e-01 -8.8601e-02  4.1514e-02\n",
      "                 ...                                      ...                \n",
      "  2.4689e-01  7.2678e-03 -5.1789e-02  ...  -6.2794e-02 -3.3140e-02  1.5538e-02\n",
      " -5.0831e-02 -2.8426e-02 -4.3009e-01  ...  -1.2142e-01  2.9594e-03  1.2049e-03\n",
      "  1.1865e-02  1.6366e-04 -2.1713e-01  ...  -2.8223e-01 -1.6595e-02  2.0508e-01\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4288e-02  3.5268e-03 -5.6180e-02  ...  -1.4507e-01 -8.0750e-02  2.9460e-02\n",
      " -1.2349e-02  1.0961e-02 -3.8088e-01  ...  -1.8690e-01 -2.1747e-01  5.5885e-02\n",
      "  9.9948e-03  3.2137e-01 -3.7573e-02  ...  -1.5623e-01 -3.1214e-02  3.6060e-03\n",
      "                 ...                                      ...                \n",
      "  5.3277e-02  1.1155e-01 -4.9413e-02  ...  -8.8345e-02 -8.1022e-03  6.3796e-03\n",
      "  8.6139e-03 -6.4700e-04 -3.2185e-01  ...  -1.1795e-02 -5.3211e-03  1.9172e-03\n",
      " -5.7279e-02  7.2673e-03 -1.7609e-01  ...  -2.0461e-01 -6.9263e-03  4.5981e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  5.2527e-03  3.7682e-02 -3.9355e-01  ...  -7.8286e-02 -8.6979e-03  5.2569e-02\n",
      " -2.5358e-02  3.7973e-02 -2.8737e-01  ...  -2.1209e-01 -2.7960e-02  2.3173e-02\n",
      "  1.2950e-02  2.5633e-03  1.4561e-01  ...   1.2202e-02 -6.1512e-02  2.4370e-02\n",
      "                 ...                                      ...                \n",
      "  2.5981e-02  7.4424e-04 -1.9298e-01  ...  -1.1458e-01 -4.3847e-02  9.7926e-03\n",
      "  5.3079e-03  1.2265e-01 -4.3439e-02  ...  -5.8563e-02  5.8286e-03  1.6545e-02\n",
      "  7.2943e-03  1.2119e-01 -4.9581e-02  ...  -4.7658e-01 -3.6244e-03  2.0079e-02\n",
      "[torch.cuda.FloatTensor of size 189x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0209  0.0000  ...  -0.0000 -0.0000 -0.0241\n",
      "  0.0000 -0.0341  0.0001  ...  -0.0020 -0.0000 -0.0400\n",
      "  0.0023 -0.5952  0.0854  ...  -0.2258 -0.0000 -0.0533\n",
      "           ...                          ...          \n",
      "  0.0000  0.1871 -0.0000  ...  -0.0003 -0.0351 -0.0550\n",
      " -0.2143 -0.0000  0.0000  ...  -0.0000 -0.0674 -0.0000\n",
      "  1.0634  0.0000 -0.0000  ...  -0.0003  0.0245 -0.0460\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0582  0.0510  ...  -0.0000 -0.0000 -0.0463\n",
      "  0.0000  0.0001  0.0339  ...  -0.0000 -0.0000 -0.0461\n",
      "  0.0057 -0.0140  0.0267  ...  -0.0000  0.0000 -0.0605\n",
      "           ...                          ...          \n",
      "  0.0000  1.0147  0.0821  ...  -0.0000 -0.0140 -0.1619\n",
      " -0.0405  0.0001  0.0000  ...  -0.0000 -0.0648 -0.0000\n",
      "  0.0360  0.0000  0.0000  ...  -0.0086  0.0155 -0.0111\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0000 -0.0589\n",
      "  0.0000  0.0249  0.0002  ...  -0.0000 -0.0000 -0.0740\n",
      "  0.0006 -0.0023  0.0508  ...  -0.0000 -0.0000 -0.1131\n",
      "           ...                          ...          \n",
      "  0.0000  0.0244  0.0000  ...  -0.0019 -0.0349 -0.0702\n",
      "  0.1114  0.0001 -0.0000  ...  -0.0000 -0.0632 -0.0000\n",
      "  0.4455  0.0000  0.0000  ...  -0.0000  0.0483 -0.1244\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000  0.0000 -0.0000\n",
      "  0.0000 -0.0002  0.0000  ...  -1.3953  0.0219 -0.0017\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0623 -0.0432\n",
      "           ...                          ...          \n",
      "  0.0014  0.0000  0.0279  ...  -0.7774 -0.0520  0.0884\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0599 -0.0000\n",
      "  0.0001  0.0001  0.9638  ...  -0.9066 -0.0000  0.0000\n",
      "\n",
      "(187,.,.) = \n",
      "  0.0006  0.0000  0.2934  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0002  0.0000  0.1675  ...  -0.0128 -0.0049 -0.0166\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000 -0.0256 -0.0258\n",
      "           ...                          ...          \n",
      "  0.0002 -0.0000  0.0001  ...  -1.4084 -0.0245  0.0059\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0410 -0.0000\n",
      "  0.0005  0.0000  0.0709  ...  -0.8265 -0.0000  0.0000\n",
      "\n",
      "(188,.,.) = \n",
      "  0.0014  0.0005  0.0397  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0141  0.0047  0.0367  ...  -0.1266  0.0150  0.0038\n",
      "  0.0001  0.0001  0.0000  ...  -0.0000 -0.0834 -0.0582\n",
      "           ...                          ...          \n",
      "  0.0003  0.0000  0.5820  ...  -0.0095 -0.0960  0.0123\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0138 -0.0000\n",
      "  0.0000 -0.0000  0.0001  ...  -1.3806 -0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.5512 -0.0052  0.0000  ...  -0.0302  0.0112 -0.0269\n",
      " -0.4608  0.0048 -0.0290  ...   0.0158  0.0000 -0.0018\n",
      " -0.0000  0.0212  0.0000  ...  -0.0292 -0.0000 -0.0233\n",
      "           ...                          ...          \n",
      " -0.1847 -0.0000 -0.0074  ...   0.0011  0.0000 -0.0301\n",
      " -0.0188 -0.0000 -0.0373  ...  -0.0000 -0.0065  0.0105\n",
      " -0.0000  0.0092 -0.0000  ...  -0.0000  0.0190 -0.0074\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0057 -0.0123  0.0000  ...  -0.0082 -0.0038  0.0039\n",
      " -0.0001  0.0047 -0.0395  ...   0.0012  0.0000  0.0214\n",
      " -0.0000 -0.0021  0.0000  ...  -0.0219 -0.0000 -0.0079\n",
      "           ...                          ...          \n",
      " -0.0003  0.0000  0.0387  ...   0.0019  0.0000 -0.0051\n",
      " -0.0970  0.0000 -0.0293  ...   0.0000 -0.0034  0.0073\n",
      " -0.0000 -0.0027 -0.0000  ...   0.0000  0.0116 -0.0488\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000  0.0001  0.0000  ...  -0.0107 -0.0115  0.0048\n",
      " -0.5279 -0.0052  0.1481  ...   0.0044  0.0000  0.0171\n",
      " -0.0000 -0.0003 -0.0000  ...   0.0085  0.0000  0.0074\n",
      "           ...                          ...          \n",
      " -1.2002  0.0000  0.0521  ...   0.0298  0.0000  0.0076\n",
      " -0.9636  0.0000 -0.0388  ...   0.0000 -0.0054  0.0467\n",
      " -0.0000 -0.0010  0.0000  ...   0.0000  0.0207 -0.0115\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      " -0.0000  0.0022  0.0001  ...   0.0054 -0.0102  0.0108\n",
      " -0.0000 -0.0125 -0.0000  ...   0.0000 -0.0000 -0.0249\n",
      " -0.0029  0.0000 -0.0576  ...   0.0000 -0.0173 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0131  0.0036  0.0415  ...   0.0070  0.0045 -0.0093\n",
      " -0.0014  0.0000 -0.0037  ...   0.0115  0.0020  0.0054\n",
      " -0.0118  0.0000  0.0000  ...   0.0067  0.0056  0.0305\n",
      "\n",
      "(187,.,.) = \n",
      " -0.0013  0.0071 -0.0187  ...   0.0110 -0.0335  0.0102\n",
      " -0.0116 -0.0046 -0.0000  ...   0.0000 -0.0000  0.0059\n",
      " -0.0000  0.0000 -0.0010  ...   0.0000 -0.0149 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0055  0.0121  ...   0.0059 -0.0141 -0.0209\n",
      " -1.1919  0.0000 -0.0815  ...   0.0301  0.1080  0.0109\n",
      " -0.0025  0.0000  0.0000  ...  -0.0038  0.0073  0.0011\n",
      "\n",
      "(188,.,.) = \n",
      " -0.0007  0.0166 -0.0099  ...   0.0224 -0.0421 -0.0313\n",
      " -0.0056  0.0063 -0.0000  ...   0.0000 -0.0000 -0.0293\n",
      " -0.0088  0.0000 -0.0395  ...   0.0000 -0.0300 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0116  0.0040 -0.0355  ...   0.0130 -0.0210  0.0053\n",
      " -0.0000  0.0000  0.0131  ...   0.0014  0.0162  0.0060\n",
      " -0.0000  0.0000  0.0000  ...  -0.0089 -0.0087 -0.0086\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.3501e-01 -1.9047e-02  1.6263e-01  ...  -7.3689e-02 -1.1781e-03  5.7154e-03\n",
      " -2.8141e-02 -3.8059e-02 -2.1128e-01  ...   2.4266e-02 -8.0584e-04  3.7372e-03\n",
      "  3.5554e-02  1.7791e-01 -1.8791e-02  ...  -1.8143e-01  2.4491e-02  5.6532e-02\n",
      "                 ...                                      ...                \n",
      " -1.4464e-01  1.6767e-02  2.3936e-01  ...  -3.5129e-02 -2.6848e-02  1.2881e-02\n",
      "  5.9751e-03  3.5120e-02 -7.0760e-03  ...  -2.4877e-02 -5.9188e-02  4.2381e-02\n",
      " -1.0946e-01  1.7107e-02  3.2354e-01  ...  -3.8421e-03 -8.4416e-03  3.1667e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.6591e-01  4.5821e-04 -1.4173e-02  ...  -8.2288e-02 -5.8149e-02  3.5861e-02\n",
      " -2.3416e-02  1.4861e-01 -1.6804e-01  ...  -8.3639e-02  6.1359e-03  1.4606e-02\n",
      "  1.7186e-01  6.6252e-02 -3.0466e-01  ...  -1.3552e-01 -5.0332e-03  6.1522e-03\n",
      "                 ...                                      ...                \n",
      " -6.9175e-02  2.7616e-01 -2.2785e-02  ...  -1.5282e-01  6.3021e-02  1.0289e-01\n",
      "  1.3848e-01  7.0319e-02 -3.0008e-02  ...   9.2312e-03 -6.9918e-03  5.4655e-03\n",
      " -4.7013e-02  1.2855e-01  1.9026e-01  ...   6.5513e-02  2.6572e-02  2.2439e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.6299e-02  1.1843e-01 -4.4796e-02  ...  -8.6652e-02 -9.5229e-02  1.6042e-02\n",
      "  6.4327e-02 -1.3643e-02  1.7669e-01  ...  -1.7309e-01  8.4070e-05  4.2038e-03\n",
      "  1.4836e-01 -5.3667e-02 -1.7917e-02  ...  -6.1568e-02 -9.9971e-05  4.9490e-04\n",
      "                 ...                                      ...                \n",
      " -2.2454e-01 -1.7050e-03 -1.4839e-01  ...  -7.7029e-03  4.8036e-03  1.8557e-04\n",
      " -3.9649e-02 -1.1931e-02 -3.4963e-02  ...  -9.9262e-03 -1.9601e-03  1.0700e-04\n",
      "  8.0892e-02  4.7321e-02  5.6229e-01  ...   5.0001e-02  1.1358e-03  2.7326e-04\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  1.7928e-02  1.9251e-01 -1.4573e-02  ...  -4.0407e-01 -2.5925e-02  5.3220e-03\n",
      " -3.9517e-02  5.6449e-02 -7.5761e-02  ...  -2.5972e-01 -2.1295e-02  5.6291e-04\n",
      "  2.0657e-02 -3.8236e-03 -2.5147e-01  ...  -1.0668e-01 -8.8601e-02  4.1514e-02\n",
      "                 ...                                      ...                \n",
      "  2.4689e-01  7.2678e-03 -5.1789e-02  ...  -6.2794e-02 -3.3140e-02  1.5538e-02\n",
      " -5.0831e-02 -2.8426e-02 -4.3009e-01  ...  -1.2142e-01  2.9594e-03  1.2049e-03\n",
      "  1.1865e-02  1.6366e-04 -2.1713e-01  ...  -2.8223e-01 -1.6595e-02  2.0508e-01\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4288e-02  3.5268e-03 -5.6180e-02  ...  -1.4507e-01 -8.0750e-02  2.9460e-02\n",
      " -1.2349e-02  1.0961e-02 -3.8088e-01  ...  -1.8690e-01 -2.1747e-01  5.5885e-02\n",
      "  9.9948e-03  3.2137e-01 -3.7573e-02  ...  -1.5623e-01 -3.1214e-02  3.6060e-03\n",
      "                 ...                                      ...                \n",
      "  5.3277e-02  1.1155e-01 -4.9413e-02  ...  -8.8345e-02 -8.1022e-03  6.3796e-03\n",
      "  8.6139e-03 -6.4700e-04 -3.2185e-01  ...  -1.1795e-02 -5.3211e-03  1.9172e-03\n",
      " -5.7279e-02  7.2673e-03 -1.7609e-01  ...  -2.0461e-01 -6.9263e-03  4.5981e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  5.2527e-03  3.7682e-02 -3.9355e-01  ...  -7.8286e-02 -8.6979e-03  5.2569e-02\n",
      " -2.5358e-02  3.7973e-02 -2.8737e-01  ...  -2.1209e-01 -2.7960e-02  2.3173e-02\n",
      "  1.2950e-02  2.5633e-03  1.4561e-01  ...   1.2202e-02 -6.1512e-02  2.4370e-02\n",
      "                 ...                                      ...                \n",
      "  2.5981e-02  7.4424e-04 -1.9298e-01  ...  -1.1458e-01 -4.3847e-02  9.7926e-03\n",
      "  5.3079e-03  1.2265e-01 -4.3439e-02  ...  -5.8563e-02  5.8286e-03  1.6545e-02\n",
      "  7.2943e-03  1.2119e-01 -4.9581e-02  ...  -4.7658e-01 -3.6244e-03  2.0079e-02\n",
      "[torch.cuda.FloatTensor of size 189x8x200 (GPU 0)]\n",
      "])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> input.size()\n",
      "*** AttributeError: 'tuple' object has no attribute 'size'\n",
      "ipdb> len(input)\n",
      "2\n",
      "ipdb> input[0]\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  3.0482e-01  1.4634e-02  8.2850e-08  ...  -2.9924e-03 -2.5956e-02 -1.6865e-02\n",
      "  6.2726e-01 -2.3886e-02  4.5073e-05  ...  -1.3863e-03 -6.5185e-03 -2.8018e-02\n",
      "  1.6438e-03 -4.1667e-01  5.9774e-02  ...  -1.5805e-01 -1.0211e-02 -3.7333e-02\n",
      "                 ...                                      ...                \n",
      "  7.2423e-01  1.3097e-01 -2.1679e-06  ...  -2.1566e-04 -2.4592e-02 -3.8522e-02\n",
      " -1.4999e-01 -8.2773e-07  2.9512e-06  ...  -1.4369e-05 -4.7184e-02 -5.1053e-02\n",
      "  7.4440e-01  2.6489e-01 -9.4652e-04  ...  -2.3397e-04  1.7172e-02 -3.2194e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  8.5194e-04  4.0759e-02  3.5672e-02  ...  -7.4968e-02 -1.8334e-03 -3.2396e-02\n",
      "  1.8823e-01  6.3061e-05  2.3715e-02  ...  -1.6540e-05 -2.6546e-03 -3.2292e-02\n",
      "  4.0109e-03 -9.7999e-03  1.8703e-02  ...  -9.9771e-07  7.9307e-03 -4.2351e-02\n",
      "                 ...                                      ...                \n",
      "  1.0892e-02  7.1028e-01  5.7497e-02  ...  -1.3266e-05 -9.8052e-03 -1.1334e-01\n",
      " -2.8333e-02  9.1031e-05  2.8364e-05  ...  -2.1666e-05 -4.5338e-02 -6.4884e-02\n",
      "  2.5185e-02  2.3267e-01  1.2838e-02  ...  -6.0487e-03  1.0820e-02 -7.7712e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  1.6074e-04  2.1414e-05  1.3620e-06  ...  -4.0574e-01  6.2819e-03 -4.1252e-02\n",
      "  1.1482e-02  1.7443e-02  1.1525e-04  ...  -8.9043e-08 -2.9620e-02 -5.1810e-02\n",
      "  4.4337e-04 -1.6344e-03  3.5525e-02  ...  -1.0582e-05 -3.1435e-02 -7.9167e-02\n",
      "                 ...                                      ...                \n",
      "  3.6297e-04  1.7087e-02  1.2970e-05  ...  -1.2981e-03 -2.4413e-02 -4.9162e-02\n",
      "  7.7973e-02  4.6160e-05 -2.4567e-09  ...  -2.5576e-06 -4.4233e-02 -5.8806e-02\n",
      "  3.1185e-01  7.1306e-01  5.6896e-04  ...  -2.3323e-08  3.3800e-02 -8.7065e-02\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  2.7079e-06 -9.5328e-06  8.6096e-07  ...  -7.9614e-01  2.1991e-02 -3.6256e-02\n",
      "  4.9438e-06 -1.0849e-04  2.5437e-08  ...  -9.7668e-01  1.5361e-02 -1.2178e-03\n",
      "  3.3358e-06  2.7108e-07  7.3287e-01  ...  -7.9036e-01 -4.3624e-02 -3.0207e-02\n",
      "                 ...                                      ...                \n",
      "  9.7578e-04  4.7620e-04  1.9502e-02  ...  -5.4415e-01 -3.6366e-02  6.1894e-02\n",
      "  2.7488e-05  6.5740e-02  4.1552e-06  ...  -1.6638e-06 -4.1929e-02 -1.5372e-02\n",
      "  4.1504e-05  9.0731e-05  6.7469e-01  ...  -6.3465e-01 -6.5128e-02  3.6681e-02\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4739e-04  3.0897e-05  2.0540e-01  ...  -1.4993e-02 -2.0515e-02 -3.4562e-02\n",
      "  1.5102e-04  2.1618e-05  1.1724e-01  ...  -8.9447e-03 -3.4510e-03 -1.1626e-02\n",
      "  4.0878e-08 -1.0973e-06  3.8190e-07  ...  -9.5726e-01 -1.7946e-02 -1.8095e-02\n",
      "                 ...                                      ...                \n",
      "  1.1736e-04 -4.5455e-06  5.1348e-05  ...  -9.8585e-01 -1.7128e-02  4.1561e-03\n",
      "  2.1084e-07  3.1649e-03  2.2568e-04  ...  -2.9503e-04 -2.8721e-02 -5.1907e-02\n",
      "  3.6941e-04  1.5813e-06  4.9644e-02  ...  -5.7854e-01 -3.7431e-02  3.0832e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  9.5869e-04  3.2496e-04  2.7776e-02  ...  -1.8834e-01 -5.4054e-03 -7.6172e-03\n",
      "  9.8977e-03  3.3119e-03  2.5711e-02  ...  -8.8638e-02  1.0494e-02  2.6615e-03\n",
      "  6.9465e-05  9.4429e-05  1.6826e-01  ...  -5.2498e-03 -5.8415e-02 -4.0764e-02\n",
      "                 ...                                      ...                \n",
      "  2.2918e-04  2.7397e-05  4.0743e-01  ...  -6.6446e-03 -6.7171e-02  8.5878e-03\n",
      "  2.6634e-06  6.2242e-10  5.2982e-08  ...  -9.7887e-01 -9.6571e-03 -1.4335e-02\n",
      "  2.0787e-06 -3.2297e-05  9.1702e-05  ...  -9.6644e-01 -2.6391e-02  5.7599e-04\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.8586e-01 -3.6524e-03  1.7137e-01  ...  -2.1141e-02  7.8316e-03 -1.8823e-02\n",
      " -3.2258e-01  3.3381e-03 -2.0310e-02  ...   1.1034e-02  1.6650e-02 -1.2350e-03\n",
      " -2.7754e-04  1.4840e-02  3.0265e-02  ...  -2.0429e-02 -5.5338e-03 -1.6280e-02\n",
      "                 ...                                      ...                \n",
      " -1.2931e-01 -7.5551e-03 -5.1831e-03  ...   7.9998e-04  1.7144e-02 -2.1101e-02\n",
      " -1.3185e-02 -2.6575e-03 -2.6135e-02  ...  -1.8713e-03 -4.5420e-03  7.3233e-03\n",
      " -3.0354e-03  6.4257e-03 -8.8136e-03  ...  -4.1447e-03  1.3313e-02 -5.1777e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -3.9639e-03 -8.5875e-03  1.8987e-02  ...  -5.7346e-03 -2.6880e-03  2.7380e-03\n",
      " -7.8691e-05  3.2879e-03 -2.7629e-02  ...   8.5360e-04  1.1318e-02  1.4976e-02\n",
      " -1.6951e-03 -1.4556e-03  3.4793e-02  ...  -1.5304e-02 -2.0326e-02 -5.4967e-03\n",
      "                 ...                                      ...                \n",
      " -2.2677e-04  2.4840e-03  2.7081e-02  ...   1.3057e-03  2.1121e-02 -3.5998e-03\n",
      " -6.7916e-02  1.2503e-02 -2.0534e-02  ...   1.1090e-02 -2.3694e-03  5.1017e-03\n",
      " -1.7389e-03 -1.8615e-03 -7.1063e-03  ...   5.7457e-03  8.1442e-03 -3.4185e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -2.5414e-05  4.0698e-05  1.1296e-03  ...  -7.4724e-03 -8.0539e-03  3.3686e-03\n",
      " -3.6950e-01 -3.6193e-03  1.0370e-01  ...   3.0464e-03  2.0005e-02  1.1973e-02\n",
      " -5.2493e-01 -1.9142e-04 -9.6760e-02  ...   5.9612e-03  8.3796e-04  5.1845e-03\n",
      "                 ...                                      ...                \n",
      " -8.4017e-01  1.4131e-02  3.6455e-02  ...   2.0885e-02  4.4325e-02  5.3241e-03\n",
      " -6.7454e-01  1.3196e-02 -2.7158e-02  ...   2.5735e-03 -3.7508e-03  3.2704e-02\n",
      " -2.2724e-04 -7.1061e-04  4.9241e-03  ...   5.1006e-03  1.4468e-02 -8.0552e-03\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      " -1.9523e-06  1.5284e-03  1.0179e-04  ...   3.7754e-03 -7.1500e-03  7.5567e-03\n",
      " -1.5294e-06 -8.7278e-03 -9.6089e-03  ...   8.7846e-03 -1.3841e-02 -1.7419e-02\n",
      " -2.0239e-03  9.4058e-03 -4.0304e-02  ...   1.6110e-02 -1.2140e-02 -2.3997e-02\n",
      "                 ...                                      ...                \n",
      " -9.1935e-03  2.5371e-03  2.9069e-02  ...   4.8967e-03  3.1217e-03 -6.4936e-03\n",
      " -9.8736e-04  8.7173e-03 -2.5589e-03  ...   8.0282e-03  1.3701e-03  3.7943e-03\n",
      " -8.2567e-03  5.8601e-03  1.5988e-02  ...   4.6611e-03  3.9467e-03  2.1346e-02\n",
      "\n",
      "(187,.,.) = \n",
      " -9.3389e-04  4.9917e-03 -1.3062e-02  ...   7.6681e-03 -2.3483e-02  7.1285e-03\n",
      " -8.1452e-03 -3.1968e-03 -3.3665e-02  ...   8.3691e-03 -2.5123e-02  4.1028e-03\n",
      " -1.4174e-07  1.2585e-02 -7.2533e-04  ...   7.9287e-03 -1.0427e-02 -2.1964e-02\n",
      "                 ...                                      ...                \n",
      " -3.9472e-06  3.8368e-03  8.4384e-03  ...   4.1650e-03 -9.8401e-03 -1.4598e-02\n",
      " -8.3435e-01  1.3211e-02 -5.7029e-02  ...   2.1040e-02  7.5629e-02  7.6196e-03\n",
      " -1.7163e-03  7.9448e-03  5.2304e-02  ...  -2.6306e-03  5.0965e-03  7.9693e-04\n",
      "\n",
      "(188,.,.) = \n",
      " -5.0105e-04  1.1649e-02 -6.9217e-03  ...   1.5714e-02 -2.9480e-02 -2.1888e-02\n",
      " -3.8948e-03  4.4095e-03 -2.2326e-02  ...   1.5268e-02 -2.2907e-02 -2.0498e-02\n",
      " -6.1418e-03  1.2173e-02 -2.7639e-02  ...   8.5190e-03 -2.1018e-02 -1.1054e-02\n",
      "                 ...                                      ...                \n",
      " -8.1060e-03  2.7829e-03 -2.4881e-02  ...   9.0857e-03 -1.4718e-02  3.6972e-03\n",
      " -1.7911e-06  5.9424e-03  9.1734e-03  ...   1.0131e-03  1.1363e-02  4.1700e-03\n",
      " -6.5393e-07  5.6092e-03  1.3340e-02  ...  -6.2517e-03 -6.0581e-03 -5.9970e-03\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.3501e-01 -1.9047e-02  1.6263e-01  ...  -7.3689e-02 -1.1781e-03  5.7154e-03\n",
      " -2.8141e-02 -3.8059e-02 -2.1128e-01  ...   2.4266e-02 -8.0584e-04  3.7372e-03\n",
      "  3.5554e-02  1.7791e-01 -1.8791e-02  ...  -1.8143e-01  2.4491e-02  5.6532e-02\n",
      "                 ...                                      ...                \n",
      " -1.4464e-01  1.6767e-02  2.3936e-01  ...  -3.5129e-02 -2.6848e-02  1.2881e-02\n",
      "  5.9751e-03  3.5120e-02 -7.0760e-03  ...  -2.4877e-02 -5.9188e-02  4.2381e-02\n",
      " -1.0946e-01  1.7107e-02  3.2354e-01  ...  -3.8421e-03 -8.4416e-03  3.1667e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.6591e-01  4.5821e-04 -1.4173e-02  ...  -8.2288e-02 -5.8149e-02  3.5861e-02\n",
      " -2.3416e-02  1.4861e-01 -1.6804e-01  ...  -8.3639e-02  6.1359e-03  1.4606e-02\n",
      "  1.7186e-01  6.6252e-02 -3.0466e-01  ...  -1.3552e-01 -5.0332e-03  6.1522e-03\n",
      "                 ...                                      ...                \n",
      " -6.9175e-02  2.7616e-01 -2.2785e-02  ...  -1.5282e-01  6.3021e-02  1.0289e-01\n",
      "  1.3848e-01  7.0319e-02 -3.0008e-02  ...   9.2312e-03 -6.9918e-03  5.4655e-03\n",
      " -4.7013e-02  1.2855e-01  1.9026e-01  ...   6.5513e-02  2.6572e-02  2.2439e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.6299e-02  1.1843e-01 -4.4796e-02  ...  -8.6652e-02 -9.5229e-02  1.6042e-02\n",
      "  6.4327e-02 -1.3643e-02  1.7669e-01  ...  -1.7309e-01  8.4070e-05  4.2038e-03\n",
      "  1.4836e-01 -5.3667e-02 -1.7917e-02  ...  -6.1568e-02 -9.9971e-05  4.9490e-04\n",
      "                 ...                                      ...                \n",
      " -2.2454e-01 -1.7050e-03 -1.4839e-01  ...  -7.7029e-03  4.8036e-03  1.8557e-04\n",
      " -3.9649e-02 -1.1931e-02 -3.4963e-02  ...  -9.9262e-03 -1.9601e-03  1.0700e-04\n",
      "  8.0892e-02  4.7321e-02  5.6229e-01  ...   5.0001e-02  1.1358e-03  2.7326e-04\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  1.7928e-02  1.9251e-01 -1.4573e-02  ...  -4.0407e-01 -2.5925e-02  5.3220e-03\n",
      " -3.9517e-02  5.6449e-02 -7.5761e-02  ...  -2.5972e-01 -2.1295e-02  5.6291e-04\n",
      "  2.0657e-02 -3.8236e-03 -2.5147e-01  ...  -1.0668e-01 -8.8601e-02  4.1514e-02\n",
      "                 ...                                      ...                \n",
      "  2.4689e-01  7.2678e-03 -5.1789e-02  ...  -6.2794e-02 -3.3140e-02  1.5538e-02\n",
      " -5.0831e-02 -2.8426e-02 -4.3009e-01  ...  -1.2142e-01  2.9594e-03  1.2049e-03\n",
      "  1.1865e-02  1.6366e-04 -2.1713e-01  ...  -2.8223e-01 -1.6595e-02  2.0508e-01\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4288e-02  3.5268e-03 -5.6180e-02  ...  -1.4507e-01 -8.0750e-02  2.9460e-02\n",
      " -1.2349e-02  1.0961e-02 -3.8088e-01  ...  -1.8690e-01 -2.1747e-01  5.5885e-02\n",
      "  9.9948e-03  3.2137e-01 -3.7573e-02  ...  -1.5623e-01 -3.1214e-02  3.6060e-03\n",
      "                 ...                                      ...                \n",
      "  5.3277e-02  1.1155e-01 -4.9413e-02  ...  -8.8345e-02 -8.1022e-03  6.3796e-03\n",
      "  8.6139e-03 -6.4700e-04 -3.2185e-01  ...  -1.1795e-02 -5.3211e-03  1.9172e-03\n",
      " -5.7279e-02  7.2673e-03 -1.7609e-01  ...  -2.0461e-01 -6.9263e-03  4.5981e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  5.2527e-03  3.7682e-02 -3.9355e-01  ...  -7.8286e-02 -8.6979e-03  5.2569e-02\n",
      " -2.5358e-02  3.7973e-02 -2.8737e-01  ...  -2.1209e-01 -2.7960e-02  2.3173e-02\n",
      "  1.2950e-02  2.5633e-03  1.4561e-01  ...   1.2202e-02 -6.1512e-02  2.4370e-02\n",
      "                 ...                                      ...                \n",
      "  2.5981e-02  7.4424e-04 -1.9298e-01  ...  -1.1458e-01 -4.3847e-02  9.7926e-03\n",
      "  5.3079e-03  1.2265e-01 -4.3439e-02  ...  -5.8563e-02  5.8286e-03  1.6545e-02\n",
      "  7.2943e-03  1.2119e-01 -4.9581e-02  ...  -4.7658e-01 -3.6244e-03  2.0079e-02\n",
      "[torch.cuda.FloatTensor of size 189x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> input[0].size(), input[1].size()\n",
      "*** AttributeError: 'list' object has no attribute 'size'\n",
      "ipdb> input[0]\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  3.0482e-01  1.4634e-02  8.2850e-08  ...  -2.9924e-03 -2.5956e-02 -1.6865e-02\n",
      "  6.2726e-01 -2.3886e-02  4.5073e-05  ...  -1.3863e-03 -6.5185e-03 -2.8018e-02\n",
      "  1.6438e-03 -4.1667e-01  5.9774e-02  ...  -1.5805e-01 -1.0211e-02 -3.7333e-02\n",
      "                 ...                                      ...                \n",
      "  7.2423e-01  1.3097e-01 -2.1679e-06  ...  -2.1566e-04 -2.4592e-02 -3.8522e-02\n",
      " -1.4999e-01 -8.2773e-07  2.9512e-06  ...  -1.4369e-05 -4.7184e-02 -5.1053e-02\n",
      "  7.4440e-01  2.6489e-01 -9.4652e-04  ...  -2.3397e-04  1.7172e-02 -3.2194e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  8.5194e-04  4.0759e-02  3.5672e-02  ...  -7.4968e-02 -1.8334e-03 -3.2396e-02\n",
      "  1.8823e-01  6.3061e-05  2.3715e-02  ...  -1.6540e-05 -2.6546e-03 -3.2292e-02\n",
      "  4.0109e-03 -9.7999e-03  1.8703e-02  ...  -9.9771e-07  7.9307e-03 -4.2351e-02\n",
      "                 ...                                      ...                \n",
      "  1.0892e-02  7.1028e-01  5.7497e-02  ...  -1.3266e-05 -9.8052e-03 -1.1334e-01\n",
      " -2.8333e-02  9.1031e-05  2.8364e-05  ...  -2.1666e-05 -4.5338e-02 -6.4884e-02\n",
      "  2.5185e-02  2.3267e-01  1.2838e-02  ...  -6.0487e-03  1.0820e-02 -7.7712e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  1.6074e-04  2.1414e-05  1.3620e-06  ...  -4.0574e-01  6.2819e-03 -4.1252e-02\n",
      "  1.1482e-02  1.7443e-02  1.1525e-04  ...  -8.9043e-08 -2.9620e-02 -5.1810e-02\n",
      "  4.4337e-04 -1.6344e-03  3.5525e-02  ...  -1.0582e-05 -3.1435e-02 -7.9167e-02\n",
      "                 ...                                      ...                \n",
      "  3.6297e-04  1.7087e-02  1.2970e-05  ...  -1.2981e-03 -2.4413e-02 -4.9162e-02\n",
      "  7.7973e-02  4.6160e-05 -2.4567e-09  ...  -2.5576e-06 -4.4233e-02 -5.8806e-02\n",
      "  3.1185e-01  7.1306e-01  5.6896e-04  ...  -2.3323e-08  3.3800e-02 -8.7065e-02\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  2.7079e-06 -9.5328e-06  8.6096e-07  ...  -7.9614e-01  2.1991e-02 -3.6256e-02\n",
      "  4.9438e-06 -1.0849e-04  2.5437e-08  ...  -9.7668e-01  1.5361e-02 -1.2178e-03\n",
      "  3.3358e-06  2.7108e-07  7.3287e-01  ...  -7.9036e-01 -4.3624e-02 -3.0207e-02\n",
      "                 ...                                      ...                \n",
      "  9.7578e-04  4.7620e-04  1.9502e-02  ...  -5.4415e-01 -3.6366e-02  6.1894e-02\n",
      "  2.7488e-05  6.5740e-02  4.1552e-06  ...  -1.6638e-06 -4.1929e-02 -1.5372e-02\n",
      "  4.1504e-05  9.0731e-05  6.7469e-01  ...  -6.3465e-01 -6.5128e-02  3.6681e-02\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4739e-04  3.0897e-05  2.0540e-01  ...  -1.4993e-02 -2.0515e-02 -3.4562e-02\n",
      "  1.5102e-04  2.1618e-05  1.1724e-01  ...  -8.9447e-03 -3.4510e-03 -1.1626e-02\n",
      "  4.0878e-08 -1.0973e-06  3.8190e-07  ...  -9.5726e-01 -1.7946e-02 -1.8095e-02\n",
      "                 ...                                      ...                \n",
      "  1.1736e-04 -4.5455e-06  5.1348e-05  ...  -9.8585e-01 -1.7128e-02  4.1561e-03\n",
      "  2.1084e-07  3.1649e-03  2.2568e-04  ...  -2.9503e-04 -2.8721e-02 -5.1907e-02\n",
      "  3.6941e-04  1.5813e-06  4.9644e-02  ...  -5.7854e-01 -3.7431e-02  3.0832e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  9.5869e-04  3.2496e-04  2.7776e-02  ...  -1.8834e-01 -5.4054e-03 -7.6172e-03\n",
      "  9.8977e-03  3.3119e-03  2.5711e-02  ...  -8.8638e-02  1.0494e-02  2.6615e-03\n",
      "  6.9465e-05  9.4429e-05  1.6826e-01  ...  -5.2498e-03 -5.8415e-02 -4.0764e-02\n",
      "                 ...                                      ...                \n",
      "  2.2918e-04  2.7397e-05  4.0743e-01  ...  -6.6446e-03 -6.7171e-02  8.5878e-03\n",
      "  2.6634e-06  6.2242e-10  5.2982e-08  ...  -9.7887e-01 -9.6571e-03 -1.4335e-02\n",
      "  2.0787e-06 -3.2297e-05  9.1702e-05  ...  -9.6644e-01 -2.6391e-02  5.7599e-04\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.8586e-01 -3.6524e-03  1.7137e-01  ...  -2.1141e-02  7.8316e-03 -1.8823e-02\n",
      " -3.2258e-01  3.3381e-03 -2.0310e-02  ...   1.1034e-02  1.6650e-02 -1.2350e-03\n",
      " -2.7754e-04  1.4840e-02  3.0265e-02  ...  -2.0429e-02 -5.5338e-03 -1.6280e-02\n",
      "                 ...                                      ...                \n",
      " -1.2931e-01 -7.5551e-03 -5.1831e-03  ...   7.9998e-04  1.7144e-02 -2.1101e-02\n",
      " -1.3185e-02 -2.6575e-03 -2.6135e-02  ...  -1.8713e-03 -4.5420e-03  7.3233e-03\n",
      " -3.0354e-03  6.4257e-03 -8.8136e-03  ...  -4.1447e-03  1.3313e-02 -5.1777e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -3.9639e-03 -8.5875e-03  1.8987e-02  ...  -5.7346e-03 -2.6880e-03  2.7380e-03\n",
      " -7.8691e-05  3.2879e-03 -2.7629e-02  ...   8.5360e-04  1.1318e-02  1.4976e-02\n",
      " -1.6951e-03 -1.4556e-03  3.4793e-02  ...  -1.5304e-02 -2.0326e-02 -5.4967e-03\n",
      "                 ...                                      ...                \n",
      " -2.2677e-04  2.4840e-03  2.7081e-02  ...   1.3057e-03  2.1121e-02 -3.5998e-03\n",
      " -6.7916e-02  1.2503e-02 -2.0534e-02  ...   1.1090e-02 -2.3694e-03  5.1017e-03\n",
      " -1.7389e-03 -1.8615e-03 -7.1063e-03  ...   5.7457e-03  8.1442e-03 -3.4185e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -2.5414e-05  4.0698e-05  1.1296e-03  ...  -7.4724e-03 -8.0539e-03  3.3686e-03\n",
      " -3.6950e-01 -3.6193e-03  1.0370e-01  ...   3.0464e-03  2.0005e-02  1.1973e-02\n",
      " -5.2493e-01 -1.9142e-04 -9.6760e-02  ...   5.9612e-03  8.3796e-04  5.1845e-03\n",
      "                 ...                                      ...                \n",
      " -8.4017e-01  1.4131e-02  3.6455e-02  ...   2.0885e-02  4.4325e-02  5.3241e-03\n",
      " -6.7454e-01  1.3196e-02 -2.7158e-02  ...   2.5735e-03 -3.7508e-03  3.2704e-02\n",
      " -2.2724e-04 -7.1061e-04  4.9241e-03  ...   5.1006e-03  1.4468e-02 -8.0552e-03\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      " -1.9523e-06  1.5284e-03  1.0179e-04  ...   3.7754e-03 -7.1500e-03  7.5567e-03\n",
      " -1.5294e-06 -8.7278e-03 -9.6089e-03  ...   8.7846e-03 -1.3841e-02 -1.7419e-02\n",
      " -2.0239e-03  9.4058e-03 -4.0304e-02  ...   1.6110e-02 -1.2140e-02 -2.3997e-02\n",
      "                 ...                                      ...                \n",
      " -9.1935e-03  2.5371e-03  2.9069e-02  ...   4.8967e-03  3.1217e-03 -6.4936e-03\n",
      " -9.8736e-04  8.7173e-03 -2.5589e-03  ...   8.0282e-03  1.3701e-03  3.7943e-03\n",
      " -8.2567e-03  5.8601e-03  1.5988e-02  ...   4.6611e-03  3.9467e-03  2.1346e-02\n",
      "\n",
      "(187,.,.) = \n",
      " -9.3389e-04  4.9917e-03 -1.3062e-02  ...   7.6681e-03 -2.3483e-02  7.1285e-03\n",
      " -8.1452e-03 -3.1968e-03 -3.3665e-02  ...   8.3691e-03 -2.5123e-02  4.1028e-03\n",
      " -1.4174e-07  1.2585e-02 -7.2533e-04  ...   7.9287e-03 -1.0427e-02 -2.1964e-02\n",
      "                 ...                                      ...                \n",
      " -3.9472e-06  3.8368e-03  8.4384e-03  ...   4.1650e-03 -9.8401e-03 -1.4598e-02\n",
      " -8.3435e-01  1.3211e-02 -5.7029e-02  ...   2.1040e-02  7.5629e-02  7.6196e-03\n",
      " -1.7163e-03  7.9448e-03  5.2304e-02  ...  -2.6306e-03  5.0965e-03  7.9693e-04\n",
      "\n",
      "(188,.,.) = \n",
      " -5.0105e-04  1.1649e-02 -6.9217e-03  ...   1.5714e-02 -2.9480e-02 -2.1888e-02\n",
      " -3.8948e-03  4.4095e-03 -2.2326e-02  ...   1.5268e-02 -2.2907e-02 -2.0498e-02\n",
      " -6.1418e-03  1.2173e-02 -2.7639e-02  ...   8.5190e-03 -2.1018e-02 -1.1054e-02\n",
      "                 ...                                      ...                \n",
      " -8.1060e-03  2.7829e-03 -2.4881e-02  ...   9.0857e-03 -1.4718e-02  3.6972e-03\n",
      " -1.7911e-06  5.9424e-03  9.1734e-03  ...   1.0131e-03  1.1363e-02  4.1700e-03\n",
      " -6.5393e-07  5.6092e-03  1.3340e-02  ...  -6.2517e-03 -6.0581e-03 -5.9970e-03\n",
      "[torch.cuda.FloatTensor of size 189x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.3501e-01 -1.9047e-02  1.6263e-01  ...  -7.3689e-02 -1.1781e-03  5.7154e-03\n",
      " -2.8141e-02 -3.8059e-02 -2.1128e-01  ...   2.4266e-02 -8.0584e-04  3.7372e-03\n",
      "  3.5554e-02  1.7791e-01 -1.8791e-02  ...  -1.8143e-01  2.4491e-02  5.6532e-02\n",
      "                 ...                                      ...                \n",
      " -1.4464e-01  1.6767e-02  2.3936e-01  ...  -3.5129e-02 -2.6848e-02  1.2881e-02\n",
      "  5.9751e-03  3.5120e-02 -7.0760e-03  ...  -2.4877e-02 -5.9188e-02  4.2381e-02\n",
      " -1.0946e-01  1.7107e-02  3.2354e-01  ...  -3.8421e-03 -8.4416e-03  3.1667e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.6591e-01  4.5821e-04 -1.4173e-02  ...  -8.2288e-02 -5.8149e-02  3.5861e-02\n",
      " -2.3416e-02  1.4861e-01 -1.6804e-01  ...  -8.3639e-02  6.1359e-03  1.4606e-02\n",
      "  1.7186e-01  6.6252e-02 -3.0466e-01  ...  -1.3552e-01 -5.0332e-03  6.1522e-03\n",
      "                 ...                                      ...                \n",
      " -6.9175e-02  2.7616e-01 -2.2785e-02  ...  -1.5282e-01  6.3021e-02  1.0289e-01\n",
      "  1.3848e-01  7.0319e-02 -3.0008e-02  ...   9.2312e-03 -6.9918e-03  5.4655e-03\n",
      " -4.7013e-02  1.2855e-01  1.9026e-01  ...   6.5513e-02  2.6572e-02  2.2439e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.6299e-02  1.1843e-01 -4.4796e-02  ...  -8.6652e-02 -9.5229e-02  1.6042e-02\n",
      "  6.4327e-02 -1.3643e-02  1.7669e-01  ...  -1.7309e-01  8.4070e-05  4.2038e-03\n",
      "  1.4836e-01 -5.3667e-02 -1.7917e-02  ...  -6.1568e-02 -9.9971e-05  4.9490e-04\n",
      "                 ...                                      ...                \n",
      " -2.2454e-01 -1.7050e-03 -1.4839e-01  ...  -7.7029e-03  4.8036e-03  1.8557e-04\n",
      " -3.9649e-02 -1.1931e-02 -3.4963e-02  ...  -9.9262e-03 -1.9601e-03  1.0700e-04\n",
      "  8.0892e-02  4.7321e-02  5.6229e-01  ...   5.0001e-02  1.1358e-03  2.7326e-04\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  1.7928e-02  1.9251e-01 -1.4573e-02  ...  -4.0407e-01 -2.5925e-02  5.3220e-03\n",
      " -3.9517e-02  5.6449e-02 -7.5761e-02  ...  -2.5972e-01 -2.1295e-02  5.6291e-04\n",
      "  2.0657e-02 -3.8236e-03 -2.5147e-01  ...  -1.0668e-01 -8.8601e-02  4.1514e-02\n",
      "                 ...                                      ...                \n",
      "  2.4689e-01  7.2678e-03 -5.1789e-02  ...  -6.2794e-02 -3.3140e-02  1.5538e-02\n",
      " -5.0831e-02 -2.8426e-02 -4.3009e-01  ...  -1.2142e-01  2.9594e-03  1.2049e-03\n",
      "  1.1865e-02  1.6366e-04 -2.1713e-01  ...  -2.8223e-01 -1.6595e-02  2.0508e-01\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4288e-02  3.5268e-03 -5.6180e-02  ...  -1.4507e-01 -8.0750e-02  2.9460e-02\n",
      " -1.2349e-02  1.0961e-02 -3.8088e-01  ...  -1.8690e-01 -2.1747e-01  5.5885e-02\n",
      "  9.9948e-03  3.2137e-01 -3.7573e-02  ...  -1.5623e-01 -3.1214e-02  3.6060e-03\n",
      "                 ...                                      ...                \n",
      "  5.3277e-02  1.1155e-01 -4.9413e-02  ...  -8.8345e-02 -8.1022e-03  6.3796e-03\n",
      "  8.6139e-03 -6.4700e-04 -3.2185e-01  ...  -1.1795e-02 -5.3211e-03  1.9172e-03\n",
      " -5.7279e-02  7.2673e-03 -1.7609e-01  ...  -2.0461e-01 -6.9263e-03  4.5981e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  5.2527e-03  3.7682e-02 -3.9355e-01  ...  -7.8286e-02 -8.6979e-03  5.2569e-02\n",
      " -2.5358e-02  3.7973e-02 -2.8737e-01  ...  -2.1209e-01 -2.7960e-02  2.3173e-02\n",
      "  1.2950e-02  2.5633e-03  1.4561e-01  ...   1.2202e-02 -6.1512e-02  2.4370e-02\n",
      "                 ...                                      ...                \n",
      "  2.5981e-02  7.4424e-04 -1.9298e-01  ...  -1.1458e-01 -4.3847e-02  9.7926e-03\n",
      "  5.3079e-03  1.2265e-01 -4.3439e-02  ...  -5.8563e-02  5.8286e-03  1.6545e-02\n",
      "  7.2943e-03  1.2119e-01 -4.9581e-02  ...  -4.7658e-01 -3.6244e-03  2.0079e-02\n",
      "[torch.cuda.FloatTensor of size 189x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> outputs[-1]\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.3501e-01 -1.9047e-02  1.6263e-01  ...  -7.3689e-02 -1.1781e-03  5.7154e-03\n",
      " -2.8141e-02 -3.8059e-02 -2.1128e-01  ...   2.4266e-02 -8.0584e-04  3.7372e-03\n",
      "  3.5554e-02  1.7791e-01 -1.8791e-02  ...  -1.8143e-01  2.4491e-02  5.6532e-02\n",
      "                 ...                                      ...                \n",
      " -1.4464e-01  1.6767e-02  2.3936e-01  ...  -3.5129e-02 -2.6848e-02  1.2881e-02\n",
      "  5.9751e-03  3.5120e-02 -7.0760e-03  ...  -2.4877e-02 -5.9188e-02  4.2381e-02\n",
      " -1.0946e-01  1.7107e-02  3.2354e-01  ...  -3.8421e-03 -8.4416e-03  3.1667e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.6591e-01  4.5821e-04 -1.4173e-02  ...  -8.2288e-02 -5.8149e-02  3.5861e-02\n",
      " -2.3416e-02  1.4861e-01 -1.6804e-01  ...  -8.3639e-02  6.1359e-03  1.4606e-02\n",
      "  1.7186e-01  6.6252e-02 -3.0466e-01  ...  -1.3552e-01 -5.0332e-03  6.1522e-03\n",
      "                 ...                                      ...                \n",
      " -6.9175e-02  2.7616e-01 -2.2785e-02  ...  -1.5282e-01  6.3021e-02  1.0289e-01\n",
      "  1.3848e-01  7.0319e-02 -3.0008e-02  ...   9.2312e-03 -6.9918e-03  5.4655e-03\n",
      " -4.7013e-02  1.2855e-01  1.9026e-01  ...   6.5513e-02  2.6572e-02  2.2439e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.6299e-02  1.1843e-01 -4.4796e-02  ...  -8.6652e-02 -9.5229e-02  1.6042e-02\n",
      "  6.4327e-02 -1.3643e-02  1.7669e-01  ...  -1.7309e-01  8.4070e-05  4.2038e-03\n",
      "  1.4836e-01 -5.3667e-02 -1.7917e-02  ...  -6.1568e-02 -9.9971e-05  4.9490e-04\n",
      "                 ...                                      ...                \n",
      " -2.2454e-01 -1.7050e-03 -1.4839e-01  ...  -7.7029e-03  4.8036e-03  1.8557e-04\n",
      " -3.9649e-02 -1.1931e-02 -3.4963e-02  ...  -9.9262e-03 -1.9601e-03  1.0700e-04\n",
      "  8.0892e-02  4.7321e-02  5.6229e-01  ...   5.0001e-02  1.1358e-03  2.7326e-04\n",
      "... \n",
      "\n",
      "(186,.,.) = \n",
      "  1.7928e-02  1.9251e-01 -1.4573e-02  ...  -4.0407e-01 -2.5925e-02  5.3220e-03\n",
      " -3.9517e-02  5.6449e-02 -7.5761e-02  ...  -2.5972e-01 -2.1295e-02  5.6291e-04\n",
      "  2.0657e-02 -3.8236e-03 -2.5147e-01  ...  -1.0668e-01 -8.8601e-02  4.1514e-02\n",
      "                 ...                                      ...                \n",
      "  2.4689e-01  7.2678e-03 -5.1789e-02  ...  -6.2794e-02 -3.3140e-02  1.5538e-02\n",
      " -5.0831e-02 -2.8426e-02 -4.3009e-01  ...  -1.2142e-01  2.9594e-03  1.2049e-03\n",
      "  1.1865e-02  1.6366e-04 -2.1713e-01  ...  -2.8223e-01 -1.6595e-02  2.0508e-01\n",
      "\n",
      "(187,.,.) = \n",
      "  4.4288e-02  3.5268e-03 -5.6180e-02  ...  -1.4507e-01 -8.0750e-02  2.9460e-02\n",
      " -1.2349e-02  1.0961e-02 -3.8088e-01  ...  -1.8690e-01 -2.1747e-01  5.5885e-02\n",
      "  9.9948e-03  3.2137e-01 -3.7573e-02  ...  -1.5623e-01 -3.1214e-02  3.6060e-03\n",
      "                 ...                                      ...                \n",
      "  5.3277e-02  1.1155e-01 -4.9413e-02  ...  -8.8345e-02 -8.1022e-03  6.3796e-03\n",
      "  8.6139e-03 -6.4700e-04 -3.2185e-01  ...  -1.1795e-02 -5.3211e-03  1.9172e-03\n",
      " -5.7279e-02  7.2673e-03 -1.7609e-01  ...  -2.0461e-01 -6.9263e-03  4.5981e-02\n",
      "\n",
      "(188,.,.) = \n",
      "  5.2527e-03  3.7682e-02 -3.9355e-01  ...  -7.8286e-02 -8.6979e-03  5.2569e-02\n",
      " -2.5358e-02  3.7973e-02 -2.8737e-01  ...  -2.1209e-01 -2.7960e-02  2.3173e-02\n",
      "  1.2950e-02  2.5633e-03  1.4561e-01  ...   1.2202e-02 -6.1512e-02  2.4370e-02\n",
      "                 ...                                      ...                \n",
      "  2.5981e-02  7.4424e-04 -1.9298e-01  ...  -1.1458e-01 -4.3847e-02  9.7926e-03\n",
      "  5.3079e-03  1.2265e-01 -4.3439e-02  ...  -5.8563e-02  5.8286e-03  1.6545e-02\n",
      "  7.2943e-03  1.2119e-01 -4.9581e-02  ...  -4.7658e-01 -3.6244e-03  2.0079e-02\n",
      "[torch.cuda.FloatTensor of size 189x8x200 (GPU 0)]\n",
      "\n",
      "ipdb> outputs[-1].size()\n",
      "torch.Size([189, 8, 200])\n",
      "ipdb> avg_pool.size()\n",
      "*** NameError: name 'avg_pool' is not defined\n",
      "ipdb> avgpool.size()\n",
      "torch.Size([8, 200])\n",
      "ipdb> mxpool.size()\n",
      "torch.Size([8, 200])\n",
      "ipdb> self.layers\n",
      "ModuleList(\n",
      "  (0): LinearBlock(\n",
      "    (lin): Linear(in_features=600, out_features=3)\n",
      "    (drop): Dropout(p=0.1)\n",
      "    (bn): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      ")\n",
      "ipdb> l_x\n",
      "Variable containing:\n",
      " 0.0668  0.2493  0.3530\n",
      " 0.0039  0.0594  0.1787\n",
      " 0.0391  0.0097  0.3880\n",
      " 0.2544 -0.2843 -0.2867\n",
      "-0.5436  0.1190  0.2461\n",
      "-0.1940 -0.7702 -0.1272\n",
      " 0.7624  0.3995 -0.5037\n",
      "-0.0402  0.2084 -0.0055\n",
      "[torch.cuda.FloatTensor of size 8x3 (GPU 0)]\n",
      "\n",
      "ipdb> c\n",
      "  0%|          | 1/3124 [09:35<499:35:10, 575.89s/it, loss=1.16]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> l_x\n",
      "Variable containing:\n",
      "-0.5846 -0.9510 -0.0915\n",
      " 0.3917 -0.4330 -0.1796\n",
      " 0.1742 -0.1254  0.1633\n",
      "-0.1107  0.4729 -0.1800\n",
      " 0.2022 -0.3249  0.1435\n",
      "-0.0683  0.5526 -0.2342\n",
      "-0.0849  0.8975  0.3898\n",
      "-0.2591 -0.0746  0.2050\n",
      "[torch.cuda.FloatTensor of size 8x3 (GPU 0)]\n",
      "\n",
      "ipdb> c\n",
      "  0%|          | 2/3124 [09:44<253:24:42, 292.21s/it, loss=1.17]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "[[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.1154 -0.0000  ...  -0.0002 -0.0351 -0.0380\n",
      "  0.0000  0.6630  0.0000  ...  -0.0000 -0.0132 -0.0810\n",
      "  0.0592 -0.0044 -0.0000  ...  -0.0240 -0.0167 -0.0000\n",
      "           ...                          ...          \n",
      "  1.0679  0.1805 -0.0000  ...  -0.0000 -0.0054 -0.0000\n",
      "  0.0000  0.2372  0.0000  ...  -0.0000 -0.0188 -0.0000\n",
      "  0.0000  0.5801  0.4926  ...  -0.0117 -0.0069 -0.0571\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0130  0.1593  ...  -0.0001 -0.0363 -0.0515\n",
      "  0.0000  0.0011  0.0000  ...  -0.0000 -0.0258 -0.0280\n",
      "  0.1891  0.0222  0.2178  ...  -0.1143 -0.0518 -0.0000\n",
      "           ...                          ...          \n",
      "  0.7182  0.0000 -0.0000  ...  -0.0000 -0.0019 -0.0000\n",
      "  0.0000  0.0140  0.0000  ...  -0.0000 -0.0094 -0.0000\n",
      "  0.0000  0.1610  1.0405  ...  -0.0003 -0.0063 -0.0536\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0017  0.0000  ...  -0.0000 -0.0127 -0.0596\n",
      "  0.0000  0.0118  0.0000  ...  -0.0000 -0.0898 -0.0163\n",
      "  0.0005  0.0000  0.0000  ...  -0.2943 -0.0032 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0002  0.0287  0.0000  ...  -0.0000 -0.0254 -0.0000\n",
      "  0.0000  0.0001  0.0000  ...  -0.0000  0.0076 -0.0000\n",
      "  0.0000  0.0028  0.3935  ...  -0.1004  0.0042 -0.0298\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0000  0.0001  ...  -0.0010 -0.0227 -0.1190\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0197 -0.0526\n",
      "  0.0009  0.0000  0.4520  ...  -0.1138 -0.0124 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0004 -0.0000  0.0000  ...  -0.0000 -0.0372  0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000  0.0364  0.0000\n",
      "  0.0000  0.0000  0.8950  ...  -0.0000  0.0194 -0.0756\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0000 -0.0000  ...  -0.0000 -0.0390 -0.1918\n",
      "  0.0000  0.0010  0.0000  ...  -0.0000 -0.0152 -0.0858\n",
      "  0.0000 -0.0000  0.0000  ...  -1.2250 -0.0044 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0288  0.0000  0.0000  ...  -0.0000 -0.0452  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0237 -0.0000\n",
      "  0.0000  0.0001  0.0000  ...  -0.6979  0.0032 -0.0281\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0003  0.9870  ...  -1.3144 -0.0259 -0.1329\n",
      "  0.0000  0.0001  0.0000  ...  -0.0000  0.0019 -0.2192\n",
      "  0.0067  0.0000  0.0004  ...  -0.0000 -0.0444 -0.0000\n",
      "           ...                          ...          \n",
      "  1.4245  0.0002  0.0000  ...  -0.0000 -0.0701 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0123 -0.0000\n",
      "  0.0000  0.0325  0.0000  ...  -1.3449 -0.0277 -0.0840\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0925 -0.0072 -0.0951  ...   0.0146 -0.0229  0.0090\n",
      " -0.0077  0.0240  0.0259  ...  -0.0011  0.0188 -0.0000\n",
      " -0.6367  0.0000 -0.0472  ...   0.0239  0.0011  0.0095\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0020  ...  -0.0058 -0.0195 -0.0371\n",
      " -0.0000  0.0005 -0.0147  ...   0.0030 -0.0000  0.0000\n",
      " -0.1950  0.0000  0.0000  ...   0.0196  0.0487  0.0228\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0013 -0.0116  0.0060  ...   0.0248 -0.0030  0.0065\n",
      " -0.0025  0.0208  0.0010  ...   0.0017 -0.0212  0.0000\n",
      " -0.0005 -0.0000 -0.0576  ...   0.0167  0.0552  0.0134\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0514  ...  -0.0067 -0.0267  0.0037\n",
      " -0.0000  0.0072 -0.0786  ...   0.0101 -0.0000  0.0000\n",
      " -1.0111  0.0000  0.0000  ...   0.0133  0.0371  0.0283\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000 -0.0009 -0.0119  ...   0.0211 -0.0264 -0.0259\n",
      " -0.0367  0.0138  0.0099  ...   0.0088 -0.0461  0.0000\n",
      " -0.0002 -0.0000 -0.0023  ...  -0.0059  0.0327 -0.0503\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0493  ...   0.0054 -0.0242  0.0083\n",
      " -0.0000  0.0180 -0.0109  ...   0.0027 -0.0000  0.0000\n",
      " -0.0521  0.0000  0.0000  ...   0.0069  0.0327  0.0185\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0207  0.0109  ...   0.0154 -0.0170 -0.0179\n",
      " -0.0002  0.0073  0.0100  ...  -0.0224  0.0313  0.0000\n",
      " -0.0003 -0.0000 -0.0626  ...  -0.0055  0.0075  0.0157\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0062  ...   0.0031  0.0521  0.0019\n",
      " -0.0000  0.0120 -0.1253  ...   0.0120 -0.0000  0.0000\n",
      " -0.0000 -0.0000  0.0000  ...   0.0050  0.0249  0.0016\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.7303  0.0092  0.3820  ...   0.0313 -0.0097  0.0210\n",
      " -0.9532  0.0030  0.2133  ...  -0.0185  0.0219  0.0000\n",
      " -0.0000  0.0000 -0.0060  ...  -0.0142 -0.0059 -0.0011\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0109  ...  -0.0020  0.0306  0.0149\n",
      " -0.0000  0.0151 -0.0151  ...  -0.0173 -0.0000  0.0000\n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0010  0.0168 -0.0001\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0001  0.0135  0.0788  ...   0.0191  0.0140 -0.0013\n",
      " -0.0034  0.0005 -0.0118  ...  -0.0053  0.0003  0.0000\n",
      " -1.3962  0.0000 -0.0954  ...   0.0040  0.0040  0.0047\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0017  ...  -0.0081 -0.0101  0.0034\n",
      " -0.0000  0.0134 -0.0233  ...   0.0188 -0.0000 -0.0000\n",
      " -0.0044 -0.0000  0.0000  ...   0.0011  0.0025 -0.0021\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -4.7130e-02  7.6495e-03  3.4440e-01  ...  -8.6015e-03 -2.1469e-02  1.2772e-02\n",
      "  4.9896e-02  2.5079e-02  3.6242e-02  ...  -1.7408e-02 -4.2284e-02  2.5083e-02\n",
      " -2.6490e-02 -1.3894e-02 -2.0574e-01  ...   5.9881e-03 -2.0463e-03  1.5789e-02\n",
      "                 ...                                      ...                \n",
      " -6.4389e-02  1.2812e-02  3.6798e-01  ...  -3.1750e-02 -2.7685e-02  1.3369e-02\n",
      "  1.1106e-02  2.0994e-02  1.5227e-01  ...  -1.9703e-02 -3.1593e-02  1.7055e-02\n",
      "  3.9244e-02 -1.4883e-02 -3.1155e-02  ...  -5.7892e-02 -1.1694e-01  1.9630e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -7.3588e-03  7.6363e-03  3.1937e-01  ...  -8.7965e-02 -1.0669e-02  6.3286e-04\n",
      "  7.2618e-03  5.3340e-02 -7.4752e-02  ...   5.1524e-03 -8.5941e-03  1.0037e-02\n",
      " -2.4331e-02 -4.5868e-04  5.4834e-01  ...   4.7788e-03 -2.4916e-02  1.0824e-01\n",
      "                 ...                                      ...                \n",
      "  8.1282e-03  2.3748e-02  3.3760e-01  ...  -9.6264e-02  1.4723e-03  1.1695e-03\n",
      "  2.5974e-02  2.9105e-02  8.1543e-02  ...  -4.5413e-02 -1.0559e-01  2.4144e-02\n",
      " -1.8482e-01 -4.2590e-02 -2.2680e-01  ...   2.6223e-02 -9.0137e-04  4.3236e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.0464e-02  8.5339e-02 -1.8439e-01  ...   7.0022e-02  1.5047e-02  4.4520e-03\n",
      "  5.5412e-02 -3.1817e-03 -1.6770e-02  ...  -3.3937e-02 -6.1396e-02  4.7629e-02\n",
      " -4.2940e-03 -6.0790e-02 -3.9003e-02  ...   1.2304e-02 -1.3251e-03  8.5977e-02\n",
      "                 ...                                      ...                \n",
      "  1.2929e-01  5.0029e-02 -9.0560e-02  ...  -1.4822e-01 -3.8158e-03  3.1432e-03\n",
      "  6.1758e-02  1.5410e-01  1.7956e-03  ...   1.6223e-01 -2.8349e-03  6.3202e-03\n",
      " -1.2682e-01 -3.7134e-02 -1.2325e-01  ...   5.9541e-03 -9.6914e-02  2.0954e-01\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  1.2571e-03  6.8977e-04 -6.9652e-02  ...   2.2239e-02 -8.7574e-04  3.8747e-03\n",
      " -5.8871e-02  1.3622e-02 -2.6877e-01  ...  -2.4690e-02 -1.6231e-02  4.3650e-02\n",
      "  3.8204e-02 -8.6972e-03 -1.6406e-01  ...   1.7511e-02 -3.5233e-01  3.4164e-02\n",
      "                 ...                                      ...                \n",
      " -3.0422e-02  1.1965e-02  1.7536e-01  ...  -2.5720e-03 -1.0321e-01  7.5849e-03\n",
      "  4.5894e-02 -2.6861e-02  2.4159e-02  ...   4.5467e-02  2.4418e-02  5.0035e-02\n",
      " -1.9929e-01 -6.6000e-02  3.5854e-04  ...  -1.1812e-02 -6.6222e-03  1.8750e-01\n",
      "\n",
      "(68 ,.,.) = \n",
      "  1.4256e-01 -5.3542e-02 -2.2113e-03  ...   9.0232e-03 -5.5678e-04 -4.5077e-05\n",
      "  5.4704e-02 -7.5021e-02 -1.0231e-01  ...   7.1480e-03 -6.9184e-03  8.0966e-04\n",
      "  1.1004e-03  2.5263e-01 -1.5542e-01  ...  -1.4107e-01 -1.3075e-01  1.9468e-03\n",
      "                 ...                                      ...                \n",
      " -5.3780e-03  4.6662e-02  4.0484e-01  ...  -3.6812e-03 -2.3763e-03  2.1214e-03\n",
      "  2.2297e-02  1.1946e-03  8.1166e-02  ...   3.8560e-02  6.4352e-02  5.5795e-02\n",
      "  3.2431e-03  1.0340e-01 -9.7966e-02  ...  -2.6094e-02 -2.7207e-03  5.4961e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      "  5.2168e-02 -1.8743e-03 -2.9596e-03  ...  -1.3677e-02 -9.4743e-02  1.1161e-01\n",
      "  7.5556e-02 -3.8442e-02 -2.1741e-03  ...  -7.7566e-02 -1.8160e-01  1.7369e-01\n",
      "  1.5590e-02  9.7981e-03 -5.7180e-01  ...  -8.3527e-02 -1.9005e-03  2.4478e-04\n",
      "                 ...                                      ...                \n",
      "  4.6883e-01 -2.5098e-02  1.2708e-01  ...   2.1655e-03 -4.3480e-03  6.4400e-03\n",
      "  6.3907e-03  5.7913e-03  2.4164e-02  ...   5.9277e-02  7.4782e-03  1.1071e-01\n",
      "  2.8236e-02  7.6316e-02 -5.1598e-02  ...  -4.1089e-01  3.0432e-02  4.0503e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.4057  0.0018  0.0000  ...  -0.0000  0.0134 -0.0767\n",
      "  0.0000  0.0000  0.2668  ...  -0.0000 -0.0000 -0.1083\n",
      "  0.0001  0.0006  0.9759  ...  -0.0249  0.0054 -0.1277\n",
      "           ...                          ...          \n",
      "  0.0000  0.0026  0.6522  ...  -0.0008 -0.1393 -0.0000\n",
      "  0.0000  0.0000  0.0001  ...  -0.0000  0.0305 -0.0000\n",
      "  0.0000 -0.0534  0.0158  ...  -1.3472 -0.0247 -0.0463\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0010  0.0001  0.0000  ...  -0.0000  0.0122 -0.1218\n",
      "  0.0000  0.1630  0.0001  ...  -0.0000 -0.0000 -0.0602\n",
      "  0.0002 -0.0002  0.0000  ...  -1.2257  0.0073 -0.0262\n",
      "           ...                          ...          \n",
      "  0.0000 -0.0229  0.0000  ...  -1.4009 -0.0462  0.0000\n",
      "  0.0000  0.0147  1.0752  ...  -0.0000 -0.0430 -0.0000\n",
      "  0.0128  0.0009 -0.0096  ...  -0.2744  0.0298 -0.1141\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0016  0.9304  0.0000  ...  -0.0000  0.0388 -0.0444\n",
      "  0.0000  0.0005  0.4442  ...  -0.0000 -0.0000 -0.0410\n",
      "  0.0001  0.3887  0.0000  ...  -1.2614 -0.0219 -0.0755\n",
      "           ...                          ...          \n",
      "  0.0000  0.0263  0.3200  ...  -0.0001 -0.0814 -0.0000\n",
      "  0.1037  0.0008  0.0000  ...  -0.0000 -0.0410 -0.0000\n",
      "  0.0009  0.0003  1.0293  ...  -0.0018 -0.0209 -0.0350\n",
      "... \n",
      "\n",
      "(50 ,.,.) = \n",
      "  0.0067  0.0005  0.0000  ...  -0.0018 -0.0433 -0.0052\n",
      "  0.0000  0.0026  0.1015  ...  -0.0000 -0.0000 -0.0443\n",
      "  0.0009  0.0018 -0.4095  ...  -0.0021 -0.0566 -0.0293\n",
      "           ...                          ...          \n",
      "  0.0000 -0.0620  0.4119  ...  -0.3296 -0.0392  0.0000\n",
      "  0.0002  0.2405  0.0010  ...  -0.0000 -0.0970 -0.0000\n",
      "  0.0053  0.1764 -0.0049  ...  -0.0001 -0.0557  0.0769\n",
      "\n",
      "(51 ,.,.) = \n",
      "  0.0020  0.0055  0.0000  ...  -0.0231 -0.0303  0.0371\n",
      "  0.0000  0.0094  0.0522  ...  -0.0000 -0.0000  0.0195\n",
      "  0.0139  0.0034  0.1198  ...  -0.0866 -0.0418  0.0225\n",
      "           ...                          ...          \n",
      "  0.0000  0.0038  0.1197  ...  -0.3310 -0.0315  0.0000\n",
      "  0.0001 -0.8008  0.0008  ...  -0.0000 -0.0909 -0.0000\n",
      "  0.0015  0.2328 -0.0000  ...  -0.0026 -0.1001  0.0716\n",
      "\n",
      "(52 ,.,.) = \n",
      "  0.0249  0.0164  0.0000  ...  -0.0539 -0.0284  0.0492\n",
      "  0.0000  0.0116  0.0495  ...  -0.0000 -0.0000  0.0501\n",
      "  0.0146  0.0033  0.1155  ...  -0.0394 -0.0379  0.0543\n",
      "           ...                          ...          \n",
      "  0.0000  0.0125  0.0816  ...  -0.2469 -0.0239  0.0000\n",
      "  0.0001 -1.0746  0.0009  ...  -0.0000 -0.0926 -0.0000\n",
      "  0.0000  0.1091 -0.0000  ...  -1.4008 -0.0590  0.0173\n",
      "[torch.cuda.FloatTensor of size 53x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0033  0.0271 -0.0000  ...   0.0195 -0.0000  0.0068\n",
      " -0.0000  0.0109 -0.0000  ...   0.0014 -0.0000  0.0456\n",
      " -0.0000  0.0000 -0.0000  ...   0.0006  0.0000  0.0163\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0072  ...  -0.0030 -0.0025  0.0048\n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0013 -0.0356 -0.0182\n",
      " -0.0812 -0.0070  0.0000  ...  -0.0024 -0.0000  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0021 -0.0000  ...   0.0135 -0.0000 -0.0581\n",
      " -1.3985  0.0052 -0.0000  ...   0.0313  0.0000  0.0264\n",
      " -0.0000  0.0000  0.0000  ...  -0.0033 -0.0000 -0.0011\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0588  ...  -0.0138 -0.0004  0.0030\n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0120 -0.0660  0.0111\n",
      " -0.0439 -0.0015 -0.0000  ...   0.0069 -0.0000 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0002 -0.0060 -0.0000  ...   0.0176  0.0000 -0.0301\n",
      " -0.0034  0.0017 -0.0000  ...   0.0239  0.0000  0.0972\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0008 -0.0000 -0.0070\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0358  ...   0.0019 -0.0259 -0.0080\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0698 -0.0746  0.0313\n",
      " -0.0018  0.0009 -0.0000  ...  -0.0029 -0.0000  0.0000\n",
      "... \n",
      "\n",
      "(50 ,.,.) = \n",
      " -0.0014 -0.0123  0.0000  ...  -0.0004 -0.0000  0.0025\n",
      " -0.0244 -0.0000  0.0000  ...   0.0181 -0.0000 -0.0268\n",
      " -0.0000 -0.0000 -0.0000  ...   0.0003 -0.0000  0.0212\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0230  ...  -0.0068 -0.0227 -0.0556\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0349 -0.0756 -0.0042\n",
      " -0.0345 -0.0126  0.0000  ...  -0.0027 -0.0000  0.0000\n",
      "\n",
      "(51 ,.,.) = \n",
      " -0.0039 -0.0025 -0.0000  ...   0.0057 -0.0000 -0.0134\n",
      " -0.0016  0.0134  0.0000  ...   0.0227 -0.0000 -0.0574\n",
      " -0.0000  0.0000 -0.0000  ...   0.0019 -0.0000  0.0157\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0168  ...  -0.0016 -0.0410 -0.0232\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0368 -0.0907 -0.0311\n",
      " -0.2541 -0.0040  0.0000  ...  -0.0125 -0.0000  0.0000\n",
      "\n",
      "(52 ,.,.) = \n",
      " -0.0011  0.0036 -0.0000  ...   0.0017 -0.0000 -0.0254\n",
      " -0.0010  0.0174  0.0000  ...   0.0170 -0.0000 -0.0610\n",
      " -0.0000  0.0000 -0.0000  ...  -0.0001 -0.0000  0.0113\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000 -0.0031  ...   0.0000 -0.0402 -0.0227\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0332 -0.0992 -0.0362\n",
      " -0.0000  0.0070  0.0000  ...  -0.0090 -0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 53x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.3071e-01  1.2196e-04  5.5412e-01  ...   1.8700e-03 -2.4610e-02  3.8199e-03\n",
      "  1.3653e-02 -1.2293e-03  5.6535e-03  ...  -1.9410e-02  8.5091e-02  4.3747e-02\n",
      "  5.5192e-02 -4.7896e-02  7.5265e-03  ...   1.8771e-02 -7.3736e-02  4.6082e-02\n",
      "                 ...                                      ...                \n",
      " -2.9605e-02 -8.1744e-02 -4.0770e-01  ...  -3.2330e-04  9.7036e-03  1.0167e-03\n",
      "  1.1064e-02  1.3048e-01 -4.5832e-02  ...  -1.7952e-02 -6.0714e-02  1.2507e-01\n",
      "  2.9442e-02  2.2135e-02 -1.4982e-01  ...  -2.9208e-01  7.2420e-03  4.1108e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.0793e-01 -1.3995e-01 -1.0931e-01  ...  -1.0786e-01 -3.7878e-03 -2.7431e-03\n",
      "  4.8135e-02 -6.0501e-02 -8.4278e-02  ...  -3.3593e-03 -6.5156e-04  2.8838e-04\n",
      "  1.6650e-02  1.9353e-01 -9.7999e-02  ...  -7.5413e-02 -4.2319e-03  3.8728e-02\n",
      "                 ...                                      ...                \n",
      "  1.6685e-01  3.5029e-01 -1.9570e-01  ...  -1.3589e-01  2.7032e-02  6.1218e-03\n",
      " -5.1924e-02  7.1304e-02 -3.3958e-01  ...   5.3193e-02  1.2011e-02  1.3141e-02\n",
      " -8.9645e-02 -9.8269e-03  5.1576e-02  ...  -1.6832e-01 -2.3473e-01  2.4440e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -6.0135e-02 -2.5643e-03 -1.7675e-01  ...   6.9987e-03 -1.7810e-03  3.0745e-03\n",
      "  5.5894e-02 -3.1639e-02 -1.1917e-01  ...  -1.6880e-03 -4.7421e-02  1.0398e-01\n",
      "  2.1163e-02  8.6286e-02 -1.4539e-01  ...  -2.7661e-01 -1.2779e-03  1.0242e-02\n",
      "                 ...                                      ...                \n",
      " -2.6077e-02  4.4766e-03  2.0570e-01  ...   7.5018e-03  1.5199e-02  9.5982e-02\n",
      " -1.6315e-01 -2.7577e-02 -2.2279e-01  ...   1.8260e-02 -5.8133e-02  6.0692e-03\n",
      " -1.0613e-01 -5.3420e-03  1.9128e-01  ...  -2.2439e-01 -1.1341e-02  1.3239e-02\n",
      "... \n",
      "\n",
      "(50 ,.,.) = \n",
      "  2.9462e-01  1.6518e-02 -3.1330e-01  ...  -3.3996e-01 -6.1980e-02  6.5375e-03\n",
      "  1.1191e-04  2.1459e-04  3.2474e-01  ...   6.3240e-02 -1.1798e-01  8.4504e-02\n",
      " -6.5016e-02  3.6008e-02 -3.4959e-01  ...  -5.2115e-02 -1.5164e-01  7.9019e-02\n",
      "                 ...                                      ...                \n",
      " -5.4421e-02  1.3944e-03  2.4005e-01  ...  -1.9442e-03  1.1325e-03  9.1100e-03\n",
      " -1.6833e-03  2.8447e-01 -7.8331e-01  ...  -8.1151e-02 -6.9435e-02  9.0659e-03\n",
      "  9.1380e-03  8.4537e-02 -1.0456e-02  ...  -2.0906e-01 -2.5955e-03  2.1223e-01\n",
      "\n",
      "(51 ,.,.) = \n",
      "  1.8880e-01  3.3783e-02 -3.4724e-01  ...  -1.8795e-01 -5.7978e-02  4.0972e-02\n",
      " -2.0436e-02  6.9170e-04  1.7326e-01  ...   3.5232e-02 -1.1465e-01  1.5430e-02\n",
      " -2.9380e-02  4.7170e-02 -2.4687e-01  ...   1.7314e-04 -1.3612e-01  7.9067e-02\n",
      "                 ...                                      ...                \n",
      " -2.3856e-02  1.9599e-02 -1.7244e-02  ...   1.2709e-02  2.7091e-02  1.8410e-02\n",
      "  6.6946e-02  4.4155e-01 -6.8777e-01  ...  -1.1651e-01 -2.7089e-02  2.9243e-02\n",
      "  1.6739e-01  8.1073e-02  1.4128e-02  ...  -4.2097e-02  9.0747e-03  4.0334e-02\n",
      "\n",
      "(52 ,.,.) = \n",
      "  9.7767e-02  3.7568e-02 -1.6339e-01  ...  -2.3873e-01 -5.8774e-02  8.4663e-02\n",
      " -1.4187e-03  5.1984e-03  2.1939e-02  ...  -1.3038e-02 -1.1613e-02  2.3098e-02\n",
      " -3.2826e-03  4.7466e-02 -2.4896e-01  ...   5.3486e-03 -7.6278e-02  1.0245e-01\n",
      "                 ...                                      ...                \n",
      " -1.7315e-02  3.8796e-02 -7.3621e-02  ...   9.6883e-03  4.1882e-02  2.3577e-02\n",
      "  4.0668e-02  3.3753e-01 -5.5308e-01  ...  -1.5308e-01 -1.6753e-02  1.2644e-02\n",
      "  2.9875e-03  2.3282e-01 -1.2525e-02  ...  -1.3006e-01 -7.5359e-03  3.9451e-01\n",
      "[torch.cuda.FloatTensor of size 53x8x200 (GPU 0)]\n",
      "]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.1154 -0.0000  ...  -0.0002 -0.0351 -0.0380\n",
      "  0.0000  0.6630  0.0000  ...  -0.0000 -0.0132 -0.0810\n",
      "  0.0592 -0.0044 -0.0000  ...  -0.0240 -0.0167 -0.0000\n",
      "           ...                          ...          \n",
      "  1.0679  0.1805 -0.0000  ...  -0.0000 -0.0054 -0.0000\n",
      "  0.0000  0.2372  0.0000  ...  -0.0000 -0.0188 -0.0000\n",
      "  0.0000  0.5801  0.4926  ...  -0.0117 -0.0069 -0.0571\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0130  0.1593  ...  -0.0001 -0.0363 -0.0515\n",
      "  0.0000  0.0011  0.0000  ...  -0.0000 -0.0258 -0.0280\n",
      "  0.1891  0.0222  0.2178  ...  -0.1143 -0.0518 -0.0000\n",
      "           ...                          ...          \n",
      "  0.7182  0.0000 -0.0000  ...  -0.0000 -0.0019 -0.0000\n",
      "  0.0000  0.0140  0.0000  ...  -0.0000 -0.0094 -0.0000\n",
      "  0.0000  0.1610  1.0405  ...  -0.0003 -0.0063 -0.0536\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0017  0.0000  ...  -0.0000 -0.0127 -0.0596\n",
      "  0.0000  0.0118  0.0000  ...  -0.0000 -0.0898 -0.0163\n",
      "  0.0005  0.0000  0.0000  ...  -0.2943 -0.0032 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0002  0.0287  0.0000  ...  -0.0000 -0.0254 -0.0000\n",
      "  0.0000  0.0001  0.0000  ...  -0.0000  0.0076 -0.0000\n",
      "  0.0000  0.0028  0.3935  ...  -0.1004  0.0042 -0.0298\n",
      "... \n",
      "\n",
      "(120,.,.) = \n",
      "  0.0067  0.0005  0.0000  ...  -0.0018 -0.0433 -0.0052\n",
      "  0.0000  0.0026  0.1015  ...  -0.0000 -0.0000 -0.0443\n",
      "  0.0009  0.0018 -0.4095  ...  -0.0021 -0.0566 -0.0293\n",
      "           ...                          ...          \n",
      "  0.0000 -0.0620  0.4119  ...  -0.3296 -0.0392  0.0000\n",
      "  0.0002  0.2405  0.0010  ...  -0.0000 -0.0970 -0.0000\n",
      "  0.0053  0.1764 -0.0049  ...  -0.0001 -0.0557  0.0769\n",
      "\n",
      "(121,.,.) = \n",
      "  0.0020  0.0055  0.0000  ...  -0.0231 -0.0303  0.0371\n",
      "  0.0000  0.0094  0.0522  ...  -0.0000 -0.0000  0.0195\n",
      "  0.0139  0.0034  0.1198  ...  -0.0866 -0.0418  0.0225\n",
      "           ...                          ...          \n",
      "  0.0000  0.0038  0.1197  ...  -0.3310 -0.0315  0.0000\n",
      "  0.0001 -0.8008  0.0008  ...  -0.0000 -0.0909 -0.0000\n",
      "  0.0015  0.2328 -0.0000  ...  -0.0026 -0.1001  0.0716\n",
      "\n",
      "(122,.,.) = \n",
      "  0.0249  0.0164  0.0000  ...  -0.0539 -0.0284  0.0492\n",
      "  0.0000  0.0116  0.0495  ...  -0.0000 -0.0000  0.0501\n",
      "  0.0146  0.0033  0.1155  ...  -0.0394 -0.0379  0.0543\n",
      "           ...                          ...          \n",
      "  0.0000  0.0125  0.0816  ...  -0.2469 -0.0239  0.0000\n",
      "  0.0001 -1.0746  0.0009  ...  -0.0000 -0.0926 -0.0000\n",
      "  0.0000  0.1091 -0.0000  ...  -1.4008 -0.0590  0.0173\n",
      "[torch.cuda.FloatTensor of size 123x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0925 -0.0072 -0.0951  ...   0.0146 -0.0229  0.0090\n",
      " -0.0077  0.0240  0.0259  ...  -0.0011  0.0188 -0.0000\n",
      " -0.6367  0.0000 -0.0472  ...   0.0239  0.0011  0.0095\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0020  ...  -0.0058 -0.0195 -0.0371\n",
      " -0.0000  0.0005 -0.0147  ...   0.0030 -0.0000  0.0000\n",
      " -0.1950  0.0000  0.0000  ...   0.0196  0.0487  0.0228\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0013 -0.0116  0.0060  ...   0.0248 -0.0030  0.0065\n",
      " -0.0025  0.0208  0.0010  ...   0.0017 -0.0212  0.0000\n",
      " -0.0005 -0.0000 -0.0576  ...   0.0167  0.0552  0.0134\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000  0.0514  ...  -0.0067 -0.0267  0.0037\n",
      " -0.0000  0.0072 -0.0786  ...   0.0101 -0.0000  0.0000\n",
      " -1.0111  0.0000  0.0000  ...   0.0133  0.0371  0.0283\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000 -0.0009 -0.0119  ...   0.0211 -0.0264 -0.0259\n",
      " -0.0367  0.0138  0.0099  ...   0.0088 -0.0461  0.0000\n",
      " -0.0002 -0.0000 -0.0023  ...  -0.0059  0.0327 -0.0503\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0493  ...   0.0054 -0.0242  0.0083\n",
      " -0.0000  0.0180 -0.0109  ...   0.0027 -0.0000  0.0000\n",
      " -0.0521  0.0000  0.0000  ...   0.0069  0.0327  0.0185\n",
      "... \n",
      "\n",
      "(120,.,.) = \n",
      " -0.0014 -0.0123  0.0000  ...  -0.0004 -0.0000  0.0025\n",
      " -0.0244 -0.0000  0.0000  ...   0.0181 -0.0000 -0.0268\n",
      " -0.0000 -0.0000 -0.0000  ...   0.0003 -0.0000  0.0212\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0230  ...  -0.0068 -0.0227 -0.0556\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0349 -0.0756 -0.0042\n",
      " -0.0345 -0.0126  0.0000  ...  -0.0027 -0.0000  0.0000\n",
      "\n",
      "(121,.,.) = \n",
      " -0.0039 -0.0025 -0.0000  ...   0.0057 -0.0000 -0.0134\n",
      " -0.0016  0.0134  0.0000  ...   0.0227 -0.0000 -0.0574\n",
      " -0.0000  0.0000 -0.0000  ...   0.0019 -0.0000  0.0157\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000  0.0168  ...  -0.0016 -0.0410 -0.0232\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0368 -0.0907 -0.0311\n",
      " -0.2541 -0.0040  0.0000  ...  -0.0125 -0.0000  0.0000\n",
      "\n",
      "(122,.,.) = \n",
      " -0.0011  0.0036 -0.0000  ...   0.0017 -0.0000 -0.0254\n",
      " -0.0010  0.0174  0.0000  ...   0.0170 -0.0000 -0.0610\n",
      " -0.0000  0.0000 -0.0000  ...  -0.0001 -0.0000  0.0113\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000 -0.0031  ...   0.0000 -0.0402 -0.0227\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0332 -0.0992 -0.0362\n",
      " -0.0000  0.0070  0.0000  ...  -0.0090 -0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 123x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -4.7130e-02  7.6495e-03  3.4440e-01  ...  -8.6015e-03 -2.1469e-02  1.2772e-02\n",
      "  4.9896e-02  2.5079e-02  3.6242e-02  ...  -1.7408e-02 -4.2284e-02  2.5083e-02\n",
      " -2.6490e-02 -1.3894e-02 -2.0574e-01  ...   5.9881e-03 -2.0463e-03  1.5789e-02\n",
      "                 ...                                      ...                \n",
      " -6.4389e-02  1.2812e-02  3.6798e-01  ...  -3.1750e-02 -2.7685e-02  1.3369e-02\n",
      "  1.1106e-02  2.0994e-02  1.5227e-01  ...  -1.9703e-02 -3.1593e-02  1.7055e-02\n",
      "  3.9244e-02 -1.4883e-02 -3.1155e-02  ...  -5.7892e-02 -1.1694e-01  1.9630e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -7.3588e-03  7.6363e-03  3.1937e-01  ...  -8.7965e-02 -1.0669e-02  6.3286e-04\n",
      "  7.2618e-03  5.3340e-02 -7.4752e-02  ...   5.1524e-03 -8.5941e-03  1.0037e-02\n",
      " -2.4331e-02 -4.5868e-04  5.4834e-01  ...   4.7788e-03 -2.4916e-02  1.0824e-01\n",
      "                 ...                                      ...                \n",
      "  8.1282e-03  2.3748e-02  3.3760e-01  ...  -9.6264e-02  1.4723e-03  1.1695e-03\n",
      "  2.5974e-02  2.9105e-02  8.1543e-02  ...  -4.5413e-02 -1.0559e-01  2.4144e-02\n",
      " -1.8482e-01 -4.2590e-02 -2.2680e-01  ...   2.6223e-02 -9.0137e-04  4.3236e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.0464e-02  8.5339e-02 -1.8439e-01  ...   7.0022e-02  1.5047e-02  4.4520e-03\n",
      "  5.5412e-02 -3.1817e-03 -1.6770e-02  ...  -3.3937e-02 -6.1396e-02  4.7629e-02\n",
      " -4.2940e-03 -6.0790e-02 -3.9003e-02  ...   1.2304e-02 -1.3251e-03  8.5977e-02\n",
      "                 ...                                      ...                \n",
      "  1.2929e-01  5.0029e-02 -9.0560e-02  ...  -1.4822e-01 -3.8158e-03  3.1432e-03\n",
      "  6.1758e-02  1.5410e-01  1.7956e-03  ...   1.6223e-01 -2.8349e-03  6.3202e-03\n",
      " -1.2682e-01 -3.7134e-02 -1.2325e-01  ...   5.9541e-03 -9.6914e-02  2.0954e-01\n",
      "... \n",
      "\n",
      "(120,.,.) = \n",
      "  2.9462e-01  1.6518e-02 -3.1330e-01  ...  -3.3996e-01 -6.1980e-02  6.5375e-03\n",
      "  1.1191e-04  2.1459e-04  3.2474e-01  ...   6.3240e-02 -1.1798e-01  8.4504e-02\n",
      " -6.5016e-02  3.6008e-02 -3.4959e-01  ...  -5.2115e-02 -1.5164e-01  7.9019e-02\n",
      "                 ...                                      ...                \n",
      " -5.4421e-02  1.3944e-03  2.4005e-01  ...  -1.9442e-03  1.1325e-03  9.1100e-03\n",
      " -1.6833e-03  2.8447e-01 -7.8331e-01  ...  -8.1151e-02 -6.9435e-02  9.0659e-03\n",
      "  9.1380e-03  8.4537e-02 -1.0456e-02  ...  -2.0906e-01 -2.5955e-03  2.1223e-01\n",
      "\n",
      "(121,.,.) = \n",
      "  1.8880e-01  3.3783e-02 -3.4724e-01  ...  -1.8795e-01 -5.7978e-02  4.0972e-02\n",
      " -2.0436e-02  6.9170e-04  1.7326e-01  ...   3.5232e-02 -1.1465e-01  1.5430e-02\n",
      " -2.9380e-02  4.7170e-02 -2.4687e-01  ...   1.7314e-04 -1.3612e-01  7.9067e-02\n",
      "                 ...                                      ...                \n",
      " -2.3856e-02  1.9599e-02 -1.7244e-02  ...   1.2709e-02  2.7091e-02  1.8410e-02\n",
      "  6.6946e-02  4.4155e-01 -6.8777e-01  ...  -1.1651e-01 -2.7089e-02  2.9243e-02\n",
      "  1.6739e-01  8.1073e-02  1.4128e-02  ...  -4.2097e-02  9.0747e-03  4.0334e-02\n",
      "\n",
      "(122,.,.) = \n",
      "  9.7767e-02  3.7568e-02 -1.6339e-01  ...  -2.3873e-01 -5.8774e-02  8.4663e-02\n",
      " -1.4187e-03  5.1984e-03  2.1939e-02  ...  -1.3038e-02 -1.1613e-02  2.3098e-02\n",
      " -3.2826e-03  4.7466e-02 -2.4896e-01  ...   5.3486e-03 -7.6278e-02  1.0245e-01\n",
      "                 ...                                      ...                \n",
      " -1.7315e-02  3.8796e-02 -7.3621e-02  ...   9.6883e-03  4.1882e-02  2.3577e-02\n",
      "  4.0668e-02  3.3753e-01 -5.5308e-01  ...  -1.5308e-01 -1.6753e-02  1.2644e-02\n",
      "  2.9875e-03  2.3282e-01 -1.2525e-02  ...  -1.3006e-01 -7.5359e-03  3.9451e-01\n",
      "[torch.cuda.FloatTensor of size 123x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "  0%|          | 3/3124 [10:21<179:34:27, 207.13s/it, loss=1.13]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "[[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  1.0279  1.0879  ...  -0.0000 -0.0000  0.0068\n",
      "  1.0755  0.1046 -0.0000  ...  -0.0004 -0.0045 -0.0518\n",
      "  0.0000 -0.1226 -0.0000  ...  -0.2664  0.0000 -0.0004\n",
      "           ...                          ...          \n",
      "  0.3793 -0.0160 -0.0000  ...  -0.0423  0.0143 -0.0488\n",
      "  0.4796 -0.0000  0.0003  ...  -0.0000 -0.0349 -0.0404\n",
      "  0.0000  0.0264 -0.0000  ...  -0.0101  0.0186 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0006  0.0154 -0.0122  ...  -0.0000 -0.0000  0.0262\n",
      "  0.0036  0.2028  0.0040  ...  -0.0009  0.0217 -0.1038\n",
      "  0.0000 -0.0005 -0.0000  ...  -0.0002  0.0000 -0.0337\n",
      "           ...                          ...          \n",
      "  0.0699  0.0000  0.0229  ...  -0.2609 -0.0085 -0.1458\n",
      "  0.0001  0.0000  0.0003  ...  -0.0000 -0.0238  0.0342\n",
      "  0.0000  0.0000  0.0000  ...  -0.1542  0.0494 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.1526  0.0294 -0.0000  ...  -0.0000 -0.0000  0.0136\n",
      "  0.0002  0.0073  0.0842  ...  -0.0000  0.0078 -0.1066\n",
      " -0.0000  0.0001  0.0044  ...  -0.3641 -0.0000 -0.1478\n",
      "           ...                          ...          \n",
      "  0.0044  0.0000  0.0030  ...  -0.0003  0.0053 -0.1268\n",
      "  0.0029  0.0000  0.0333  ...  -0.0000  0.0101 -0.0839\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0297 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0001  0.7835  ...  -0.0000 -0.0000 -0.0405\n",
      "  0.0000  0.0003  1.0034  ...  -0.0200  0.0316 -0.0943\n",
      "  0.0000  0.0000  0.0019  ...  -0.0000 -0.0000 -0.0830\n",
      "           ...                          ...          \n",
      "  0.0000  0.0010  0.2550  ...  -0.0316 -0.0499 -0.1215\n",
      "  0.0003  0.0000  0.0008  ...  -0.0000 -0.0176 -0.0534\n",
      "  0.0000  0.0001  0.0000  ...  -0.0050 -0.0196 -0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0005 -0.0000  0.0681  ...  -0.0000 -0.0000  0.0097\n",
      "  0.0000  0.0204  0.4216  ...  -0.2124  0.0348 -0.0453\n",
      "  0.0000  0.0000  0.1036  ...  -0.8361  0.0000 -0.0043\n",
      "           ...                          ...          \n",
      "  0.0000  0.0001  0.2673  ...  -0.0235 -0.0328 -0.0646\n",
      "  0.0000  0.0000  0.5893  ...  -0.0000  0.0190 -0.1479\n",
      "  0.0000  0.0029  0.0000  ...  -0.0182  0.0187 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0075  0.6443  ...  -0.0000 -0.0000  0.0174\n",
      "  0.0000  0.0000  0.0000  ...  -1.1997  0.0123 -0.0266\n",
      "  0.0000  0.0000  0.0000  ...  -0.0015  0.0000 -0.0349\n",
      "           ...                          ...          \n",
      "  0.0012  0.0000  0.0009  ...  -0.0000 -0.0385 -0.0336\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0077 -0.0444\n",
      "  0.0000  0.6405  0.0000  ...  -0.0283 -0.0383 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0000  0.0354  0.0773  ...   0.0251  0.0360 -0.0058\n",
      " -0.0209  0.0023  0.0025  ...   0.0016 -0.0000  0.0000\n",
      " -0.0000  0.0313 -0.0065  ...   0.0156  0.0075 -0.0019\n",
      "           ...                          ...          \n",
      " -0.6277  0.0291 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.1252 -0.0169  0.0895  ...   0.0087  0.0011  0.0095\n",
      " -0.0000  0.0204 -0.0000  ...   0.0063  0.0000  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0019  0.0843  ...  -0.0103 -0.0033 -0.0132\n",
      " -0.1143 -0.0122  0.0452  ...   0.0138  0.0000 -0.0000\n",
      " -0.0000  0.0262 -0.0471  ...  -0.0061  0.0229  0.0360\n",
      "           ...                          ...          \n",
      " -0.0884  0.0082 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.0448  0.0289  0.1652  ...  -0.0077  0.0582 -0.0444\n",
      " -0.0000  0.0035 -0.0000  ...  -0.0022  0.0000 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000 -0.0190  0.2087  ...  -0.0448  0.0122  0.0400\n",
      " -0.0001  0.0029 -0.0259  ...   0.0180  0.0000 -0.0000\n",
      " -0.0000 -0.0165 -0.0836  ...   0.0275  0.0155 -0.0384\n",
      "           ...                          ...          \n",
      " -0.0007 -0.0056 -0.0000  ...  -0.0000 -0.0000  0.0000\n",
      " -0.0154  0.0078  0.1028  ...  -0.0161  0.0292  0.0204\n",
      " -0.0000  0.0046 -0.0000  ...  -0.0189  0.0000  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0055 -0.0858  ...   0.0305  0.0354  0.0577\n",
      " -0.0650 -0.0194 -0.1110  ...   0.0078 -0.0000 -0.0000\n",
      " -0.0000 -0.0025 -0.1716  ...   0.0192  0.0322  0.0239\n",
      "           ...                          ...          \n",
      " -1.1661  0.0011 -0.0000  ...   0.0000  0.0000 -0.0000\n",
      " -0.0005 -0.0067 -0.0345  ...   0.0008  0.0172 -0.0008\n",
      " -0.0000 -0.0048 -0.0000  ...   0.0178  0.0000 -0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000 -0.0003 -0.0341  ...   0.0168  0.0007  0.0094\n",
      " -0.0097 -0.0207 -0.0107  ...   0.0101 -0.0000  0.0000\n",
      " -0.0000 -0.0121 -0.1093  ...   0.0214 -0.0045  0.0093\n",
      "           ...                          ...          \n",
      " -0.0035  0.0093 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.0005 -0.0026  0.0551  ...   0.0078  0.0230  0.0041\n",
      " -0.0000 -0.0172 -0.0000  ...   0.0308  0.0000 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000  0.0139  0.0303  ...   0.0063  0.0113  0.0221\n",
      " -0.0001  0.0010  0.0313  ...  -0.0063  0.0000  0.0000\n",
      " -0.0000  0.0013 -0.3799  ...   0.0193  0.0293  0.0184\n",
      "           ...                          ...          \n",
      " -0.0015 -0.0066 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.0005 -0.0152  0.0381  ...  -0.0059  0.0052 -0.0074\n",
      " -0.0000 -0.0023 -0.0000  ...   0.0178  0.0000 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  9.0547e-02 -1.6053e-02 -2.0524e-01  ...  -5.0069e-02 -2.6807e-02  6.4216e-02\n",
      "  1.8703e-02 -5.4080e-03  3.8728e-01  ...  -2.2465e-02 -5.0862e-02  7.7274e-02\n",
      "  1.1821e-01  3.9652e-02 -1.0448e-02  ...   9.4909e-02 -1.2077e-01  7.0657e-03\n",
      "                 ...                                      ...                \n",
      " -2.3282e-02 -4.1533e-02 -2.5343e-01  ...   2.4174e-02  1.0382e-03  7.3963e-03\n",
      "  1.8417e-02 -1.6327e-02  1.8099e-01  ...  -7.6748e-03 -9.2596e-03  3.5740e-02\n",
      " -6.6183e-02 -6.7840e-03 -2.6052e-01  ...   9.3761e-03 -2.5369e-02  9.6120e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.3644e-01 -1.1406e-02  1.3935e-01  ...  -4.1208e-02 -1.0905e-02  2.9066e-03\n",
      " -1.1752e-02  3.6244e-02  4.4647e-01  ...  -3.4705e-04 -1.4615e-01  1.5794e-03\n",
      " -4.8590e-02  8.0235e-05 -4.1436e-02  ...   2.5115e-02 -3.0961e-02  3.2041e-03\n",
      "                 ...                                      ...                \n",
      "  3.5181e-02 -3.1710e-03 -5.3312e-02  ...   1.8668e-02 -1.2576e-01  2.0937e-02\n",
      " -8.4733e-02  6.0892e-02  7.9093e-02  ...  -1.0436e-03 -6.2244e-04  5.5188e-03\n",
      "  5.8936e-03  8.4469e-03 -1.0303e-01  ...  -4.2216e-02 -3.2805e-02  4.6600e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  3.0598e-01 -6.4519e-02 -9.1244e-04  ...   3.2685e-01 -1.0116e-03  5.6556e-04\n",
      "  1.2977e-02  4.2382e-01 -2.4539e-03  ...  -7.6274e-02 -2.9456e-02  2.7899e-02\n",
      " -2.5468e-03  1.0370e-02  5.8431e-03  ...  -9.6991e-02 -1.1994e-01 -5.9386e-02\n",
      "                 ...                                      ...                \n",
      "  4.4425e-02  2.6894e-02  7.8933e-02  ...   1.7190e-02  5.8653e-03  3.5064e-03\n",
      " -2.2963e-02 -3.8927e-03  2.1931e-01  ...   6.7891e-02 -2.1075e-03  1.8736e-03\n",
      " -4.1300e-02  8.1013e-02 -2.0478e-01  ...   3.0819e-02  1.6370e-02  5.1991e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  1.1222e-01 -2.7043e-03 -1.2661e-01  ...   1.9200e-01 -7.8198e-02  1.6878e-02\n",
      "  9.0605e-02 -2.3687e-04  6.3456e-02  ...  -2.6403e-02 -6.3023e-03  5.5556e-02\n",
      " -2.0069e-02  2.0061e-03  2.9154e-01  ...   9.9714e-04 -8.3752e-03  8.4686e-02\n",
      "                 ...                                      ...                \n",
      "  2.4353e-02  2.3057e-03 -2.2560e-01  ...  -1.6216e-01 -4.1293e-02  2.2057e-03\n",
      " -1.4445e-01  4.0398e-03  1.3576e-01  ...  -3.2564e-03  3.5012e-04  5.1810e-04\n",
      "  1.1647e-02  4.9642e-03  5.5398e-01  ...  -2.4325e-02  1.3556e-03  1.5139e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      "  3.0595e-02  3.2785e-02 -3.4583e-01  ...   2.8192e-01 -1.3481e-02  1.1835e-01\n",
      "  2.7394e-02  2.1203e-02 -6.2098e-02  ...  -1.0797e-02 -3.6090e-02  3.8708e-03\n",
      " -4.0917e-01 -1.6617e-01  3.6402e-02  ...  -5.7488e-04  6.1123e-03  8.0604e-02\n",
      "                 ...                                      ...                \n",
      "  1.4232e-02  9.0506e-03 -2.2610e-01  ...  -1.9621e-02 -4.6599e-02  1.4083e-02\n",
      " -2.7462e-01  2.0051e-02  7.0278e-02  ...   4.3204e-02  3.4893e-02  1.1188e-02\n",
      "  1.4771e-02  5.1894e-03  2.2332e-02  ...  -1.6474e-02 -2.7536e-02  1.1759e-01\n",
      "\n",
      "(69 ,.,.) = \n",
      "  2.4822e-01 -4.2827e-03 -3.0597e-02  ...   1.3878e-01 -1.2401e-02  1.5880e-02\n",
      "  7.3208e-04  1.8992e-01 -2.2749e-02  ...  -1.3162e-01 -1.3834e-02  4.1613e-04\n",
      "  4.9321e-01 -1.3524e-01 -2.4362e-02  ...   1.5497e-01  8.9308e-06  4.6960e-04\n",
      "                 ...                                      ...                \n",
      " -1.9929e-03  5.7334e-03 -3.0819e-01  ...  -9.6143e-03 -1.7635e-02  1.9907e-02\n",
      "  3.8812e-02  2.2452e-01 -3.2329e-03  ...  -9.6699e-02  9.8038e-02  2.2678e-02\n",
      "  6.3150e-02  4.1897e-02 -5.4175e-02  ...   2.3456e-01 -9.6071e-03  3.5266e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0014  1.1017  ...  -0.1400 -0.0000  0.0000\n",
      "  0.0000  0.0000 -0.0000  ...  -0.0004  0.0024 -0.0392\n",
      "  0.0000  0.0000  0.0000  ...  -0.4294 -0.0673 -0.0362\n",
      "           ...                          ...          \n",
      "  0.0244  0.0018  0.0000  ...  -0.0000 -0.0643 -0.0526\n",
      "  0.0029  0.0001  0.0456  ...  -0.0000 -0.0830 -0.1227\n",
      "  0.0003  0.0004  0.2206  ...  -0.0100 -0.0414  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.0002 -0.0000  0.0000\n",
      "  0.0000  0.0001  1.0153  ...  -0.0046 -0.0118 -0.1206\n",
      "  0.0000 -0.0000  0.0000  ...  -1.2170 -0.0179 -0.0571\n",
      "           ...                          ...          \n",
      "  0.0008  0.1970  0.0000  ...  -0.0057 -0.1054 -0.0517\n",
      "  0.0186  0.0293  0.0055  ...  -0.0000 -0.0613 -0.0513\n",
      "  0.0112 -0.0223  0.0000  ...  -1.1803 -0.0272  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0202  1.0877  ...  -0.0615 -0.0000 -0.0000\n",
      "  0.0000  0.0002  0.0000  ...  -0.0000 -0.0255 -0.0894\n",
      "  0.0000 -0.0000  0.0000  ...  -1.3004  0.0015 -0.0445\n",
      "           ...                          ...          \n",
      "  0.0076  0.0000  0.0000  ...  -0.0362 -0.0388  0.0434\n",
      "  0.0325  0.0098  0.0000  ...  -0.0000 -0.1104 -0.0543\n",
      "  0.0093  0.0001 -0.0423  ...  -0.4450 -0.0108  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.0004  0.0000 -0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0007  0.0263 -0.1361\n",
      "  0.0000  0.0000  0.0000  ...  -0.7204 -0.0552 -0.1526\n",
      "           ...                          ...          \n",
      "  0.0247  0.0159  0.0000  ...  -0.2613 -0.0270  0.0456\n",
      "  0.0000  0.0000  0.0093  ...  -0.0033 -0.0845  0.0328\n",
      "  0.0001  0.3033  0.8689  ...  -0.1828 -0.0268  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0003  0.0050  ...  -0.0573 -0.0000 -0.0000\n",
      "  0.0000  0.0031  0.0765  ...  -0.5691  0.0253 -0.1601\n",
      "  0.0000  0.0000  0.0000  ...  -0.0095 -0.0195 -0.0757\n",
      "           ...                          ...          \n",
      "  0.0007  0.0001  0.0000  ...  -0.0229 -0.0212 -0.0096\n",
      "  0.0001  0.6317 -0.0026  ...  -0.0012 -0.0763  0.0161\n",
      "  0.0009  0.0010 -0.0459  ...  -0.6984 -0.0249 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0016 -0.0000  ...  -0.0007 -0.0000 -0.0000\n",
      "  0.0000 -0.0005  0.3816  ...  -0.0746  0.0048 -0.0295\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0160 -0.1798\n",
      "           ...                          ...          \n",
      "  1.4135  0.0000  0.0000  ...  -0.0031 -0.0271  0.0494\n",
      "  0.0110  0.1374  0.0000  ...  -0.0000 -0.0576  0.0336\n",
      "  0.0074 -0.0001 -0.0000  ...  -0.0000 -0.0122 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0000  0.0038 -0.0000  ...   0.0053  0.0157  0.0000\n",
      " -0.0004  0.0000  0.0049  ...  -0.0000  0.0084  0.0180\n",
      " -0.7809  0.0176 -0.0000  ...   0.0281  0.1076  0.0187\n",
      "           ...                          ...          \n",
      " -0.8428  0.0068  0.1397  ...   0.0167 -0.0214  0.0764\n",
      " -0.0000 -0.0010  0.0052  ...   0.0000 -0.0058  0.0000\n",
      " -0.0003  0.0051 -0.0011  ...   0.0118 -0.0161 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0134  0.0000  ...  -0.0036  0.0052  0.0000\n",
      " -0.0000  0.0000 -0.0026  ...   0.0000  0.0128  0.0377\n",
      " -0.0028  0.0115 -0.0000  ...   0.0117  0.0778 -0.0057\n",
      "           ...                          ...          \n",
      " -1.3537  0.0181 -0.2707  ...   0.0492  0.0473  0.0663\n",
      " -0.0000 -0.0053  0.0440  ...   0.0000  0.0113  0.0000\n",
      " -0.0001  0.0003 -0.0116  ...   0.0079 -0.0271 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000  0.0014 -0.0000  ...   0.0259 -0.0023 -0.0000\n",
      " -0.0043 -0.0000 -0.0183  ...   0.0000 -0.0052  0.0129\n",
      " -0.0001  0.0174 -0.0000  ...  -0.0027  0.0317 -0.0089\n",
      "           ...                          ...          \n",
      " -0.0113  0.0091 -0.1187  ...   0.0316  0.0382  0.0385\n",
      " -1.3150  0.0050  0.1318  ...   0.0000  0.0285  0.0000\n",
      " -0.0156  0.0020 -0.0249  ...   0.0069 -0.0222 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000 -0.0022 -0.0000  ...   0.0155  0.0550  0.0000\n",
      " -0.9127  0.0000 -0.0857  ...  -0.0000  0.0047  0.0397\n",
      " -0.1443  0.0065  0.0000  ...   0.0092  0.0201  0.0515\n",
      "           ...                          ...          \n",
      " -0.0381 -0.0004 -0.0408  ...  -0.0090 -0.0226  0.0022\n",
      " -0.0000  0.0014  0.0165  ...   0.0000  0.0044 -0.0000\n",
      " -0.0025  0.0069  0.0141  ...   0.0162  0.0174  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000  0.0073 -0.0000  ...   0.0171  0.0459  0.0000\n",
      " -0.2544  0.0000 -0.0981  ...   0.0000  0.0225  0.0538\n",
      " -0.0007  0.0077  0.0000  ...  -0.0019 -0.0140  0.0320\n",
      "           ...                          ...          \n",
      " -0.0001  0.0034  0.0285  ...  -0.0102  0.0058 -0.0056\n",
      " -0.0305 -0.0005  0.0758  ...   0.0000  0.0024 -0.0000\n",
      " -0.0010  0.0037  0.0432  ...   0.0046  0.0030 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000  0.0069 -0.0000  ...   0.0272  0.0265 -0.0000\n",
      " -0.0000 -0.0000  0.0039  ...   0.0000  0.0117  0.0063\n",
      " -0.1151  0.0071  0.0000  ...   0.0010  0.0334  0.0152\n",
      "           ...                          ...          \n",
      " -0.0039  0.0223  0.0230  ...  -0.0157 -0.0149  0.0155\n",
      " -1.3063 -0.0235  0.2018  ...   0.0000 -0.0019 -0.0000\n",
      " -0.0001  0.0085  0.0633  ...  -0.0020 -0.0135 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.4144e-01 -1.0706e-02  1.2199e-02  ...   9.2207e-02 -7.0258e-02  3.0861e-02\n",
      " -2.5928e-02 -1.0010e-04  2.4507e-01  ...  -2.1154e-02 -8.7813e-04  3.0716e-02\n",
      "  4.8812e-01 -5.8435e-03 -9.1608e-03  ...   2.0126e-02 -1.4591e-03  8.0550e-05\n",
      "                 ...                                      ...                \n",
      "  2.1018e-02  1.8992e-03 -1.0009e-01  ...  -1.5150e-02 -1.9987e-03  5.9964e-04\n",
      "  2.8161e-02  1.5844e-04  2.9767e-01  ...  -3.9575e-02 -2.0752e-02  3.2810e-01\n",
      "  6.2295e-02  2.5862e-03  1.3971e-01  ...  -2.3308e-02 -7.3050e-03  2.4817e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.0628e-01 -2.9852e-03  4.9785e-01  ...   6.4124e-03 -1.4431e-02  6.0245e-03\n",
      " -2.5918e-02  4.6612e-02  8.7939e-02  ...  -8.8073e-02  3.6291e-03  2.4461e-02\n",
      "  4.4494e-01 -1.4837e-03 -1.3331e-02  ...   7.8449e-03  1.0205e-02  9.3132e-03\n",
      "                 ...                                      ...                \n",
      "  3.5038e-02 -6.5805e-03 -9.4538e-03  ...  -3.9846e-02 -6.6186e-04 -1.7363e-05\n",
      " -5.9195e-03  1.3487e-01 -3.5856e-01  ...   1.9565e-03 -2.5596e-04  3.6474e-01\n",
      " -4.9603e-02  2.3329e-02 -5.2142e-02  ...  -1.6565e-02 -3.3620e-04  1.7689e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  3.2303e-01 -3.4068e-02  3.5885e-01  ...   2.9349e-02 -2.6242e-02  1.2619e-04\n",
      "  1.3793e-01  1.8809e-01 -5.4657e-02  ...  -1.5421e-01 -4.7132e-05  5.1144e-03\n",
      "  3.0575e-02  5.1024e-02 -4.9472e-02  ...  -3.8408e-01 -3.1536e-03  1.0587e-02\n",
      "                 ...                                      ...                \n",
      "  1.4821e-02 -2.1188e-04 -6.7983e-03  ...  -3.2842e-02 -4.2208e-02  2.4532e-03\n",
      " -5.0138e-01  5.7047e-03 -1.3616e-01  ...   3.5437e-03 -1.6595e-03  1.3553e-02\n",
      " -5.9724e-02  4.6895e-04 -1.1151e-01  ...  -3.3255e-02 -4.8296e-03  3.4432e-02\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -3.8975e-02  2.7669e-02  1.9116e-02  ...  -2.0460e-02  2.3172e-02  9.4391e-02\n",
      " -3.3087e-01 -8.6832e-03 -2.0869e-01  ...   2.3621e-02 -5.5042e-03  1.7369e-04\n",
      "  4.0807e-02 -1.4454e-02  1.4505e-02  ...  -4.0750e-02 -5.4400e-02  5.5655e-02\n",
      "                 ...                                      ...                \n",
      " -7.9910e-02  1.6552e-03 -4.0310e-01  ...  -9.9053e-03 -3.0291e-02  7.1958e-02\n",
      " -2.7016e-03  2.9818e-02 -8.3765e-02  ...   2.2691e-02 -2.1444e-03  2.1406e-02\n",
      " -3.0081e-03  1.5501e-01 -6.8816e-02  ...   1.8018e-01  7.4597e-03  4.8975e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      " -4.4666e-02  4.5106e-02  3.7957e-02  ...  -4.6093e-02  3.1477e-02  8.8443e-02\n",
      " -1.1527e-01 -1.4750e-02 -1.5461e-01  ...   1.3688e-02 -7.1638e-02  4.1269e-02\n",
      "  3.1542e-02  1.2189e-01  2.0659e-01  ...  -4.6240e-02  1.0071e-02  1.3922e-02\n",
      "                 ...                                      ...                \n",
      "  1.5333e-02  1.7244e-02 -2.8721e-01  ...  -1.0186e-01 -1.6434e-01  9.3329e-02\n",
      " -7.3758e-02  4.3740e-03  1.3870e-01  ...   1.2912e-01 -9.1026e-02  7.7659e-02\n",
      " -4.0409e-04  4.3612e-03  4.9465e-02  ...   6.0120e-02 -1.6905e-01  1.7133e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.1298e-01  1.8539e-01 -6.6199e-02  ...   1.5527e-01  3.1542e-02  4.3593e-02\n",
      " -1.0527e-01 -5.4050e-03 -1.1058e-01  ...  -1.1800e-02 -3.2253e-02  1.7618e-01\n",
      "  9.8426e-02  9.9505e-02  2.7765e-01  ...  -1.9451e-02  8.0902e-03  2.3697e-04\n",
      "                 ...                                      ...                \n",
      "  3.1755e-01  1.2387e-03 -3.3249e-01  ...  -5.6998e-02 -3.1371e-02  1.0217e-03\n",
      " -1.2583e-01 -8.4758e-03 -3.8937e-02  ...   2.5344e-02 -9.4757e-05  2.4955e-04\n",
      "  4.0797e-03  2.3987e-01 -3.3415e-02  ...   3.1972e-01 -3.2167e-03  4.0304e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000 -0.0006  ...  -0.0000 -0.0395 -0.0172\n",
      "  0.0000 -0.0000  0.0000  ...  -1.0361 -0.0100  0.0000\n",
      "  0.0000  0.0000  0.2126  ...  -0.0000  0.0000 -0.1421\n",
      "           ...                          ...          \n",
      "  0.0002  0.0018  0.0000  ...  -0.0007 -0.0968  0.0155\n",
      "  0.0000  0.0060  0.0000  ...  -0.0000 -0.0471  0.0000\n",
      "  0.0000  0.0000  0.0003  ...  -0.0007 -0.0833 -0.0955\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0068  1.0335  ...  -0.0000  0.0008 -0.0484\n",
      "  0.0232  0.0000  0.0000  ...  -0.0010  0.0155 -0.0000\n",
      " -0.0000  0.0000  1.0945  ...  -0.8601  0.0000 -0.2317\n",
      "           ...                          ...          \n",
      "  0.0010  0.0002 -0.0000  ...  -0.0000 -0.0617  0.0155\n",
      "  0.0076  0.0000  0.0000  ...  -0.0000 -0.0477  0.0000\n",
      "  0.0000  0.0000  1.0826  ...  -1.1782 -0.0800  0.0137\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.4360  0.0000  ...  -0.0000 -0.0355 -0.0681\n",
      "  0.0096  0.0102  0.0000  ...  -0.2322  0.0240 -0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -1.2892  0.0000 -0.0607\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.0104  ...  -1.3757 -0.0328 -0.0225\n",
      "  0.0214  0.0002  0.0000  ...  -0.0000 -0.0438 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -1.3686 -0.0571 -0.0009\n",
      "... \n",
      "\n",
      "(31 ,.,.) = \n",
      "  0.0000  0.0009  0.0789  ...  -0.0001 -0.0708 -0.0112\n",
      "  0.0005  0.0000  0.0000  ...  -0.0442 -0.0479 -0.0000\n",
      "  0.0000  0.0000 -0.0000  ...  -0.0000 -0.0000 -0.0458\n",
      "           ...                          ...          \n",
      "  0.0001  0.0002  0.0073  ...  -0.0018 -0.0245 -0.1766\n",
      "  0.0000  0.0010  0.0000  ...  -0.0000 -0.0462 -0.0000\n",
      " -0.0000  0.0000  0.0000  ...  -0.1600 -0.1571 -0.0598\n",
      "\n",
      "(32 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -1.4044 -0.0423 -0.0242\n",
      "  0.0000 -0.0006  0.0000  ...  -1.3172 -0.0061 -0.0000\n",
      "  0.0000  0.0000  0.1491  ...  -0.7466 -0.0000 -0.0850\n",
      "           ...                          ...          \n",
      "  0.0003  0.0006 -0.0000  ...  -0.0002 -0.0175 -0.0528\n",
      "  0.0000  0.0002  0.0000  ...  -0.0000 -0.0391 -0.0000\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0594 -0.1134 -0.0445\n",
      "\n",
      "(33 ,.,.) = \n",
      "  0.0000  0.0001  0.1420  ...  -0.0112 -0.1233 -0.0463\n",
      "  0.0002  0.0000 -0.0000  ...  -0.0387 -0.0365 -0.0000\n",
      "  0.0000  0.0000  0.0719  ...  -0.0457 -0.0000 -0.0204\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.0002  ...  -1.3609 -0.0065 -0.0637\n",
      "  0.0026  0.0000  0.0000  ...  -0.0000 -0.0124 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -1.3914 -0.0381 -0.0566\n",
      "[torch.cuda.FloatTensor of size 34x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.2542  0.0029 -0.0713  ...   0.0231  0.0328  0.0166\n",
      " -0.0227 -0.0000 -0.0363  ...   0.0199  0.0264 -0.0068\n",
      " -0.9419 -0.0000 -0.1603  ...   0.0201  0.0500 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0201  0.0085  0.0439  ...   0.0093  0.0015  0.0110\n",
      " -0.0000 -0.0000  0.0045  ...   0.0294  0.0669  0.0000\n",
      " -0.7757  0.0049 -0.0000  ...  -0.0000 -0.0139 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0010 -0.0634  ...   0.0042  0.0268  0.0175\n",
      " -0.9935 -0.0000 -0.2218  ...   0.0170  0.0535 -0.0229\n",
      " -0.0677 -0.0000 -0.1209  ...   0.0115  0.0575 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0029  0.0096  0.0599  ...  -0.0067 -0.0114  0.0180\n",
      " -0.0000 -0.0000 -0.0247  ...   0.0075  0.1075  0.0000\n",
      " -0.0000 -0.0010 -0.0000  ...  -0.0000 -0.0024  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.3096  0.0148 -0.2289  ...   0.0082  0.0611  0.0062\n",
      " -0.0056  0.0000 -0.1996  ...   0.0207  0.0409  0.0089\n",
      " -0.0000 -0.0000 -0.0288  ...   0.0023  0.0227 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0028  0.0129  ...  -0.0063 -0.0073  0.0096\n",
      " -0.0000 -0.0000 -0.0172  ...  -0.0154  0.0521  0.0000\n",
      " -0.0000 -0.0027 -0.0000  ...  -0.0000  0.0062  0.0000\n",
      "... \n",
      "\n",
      "(31 ,.,.) = \n",
      " -0.0034 -0.0034 -0.0300  ...   0.0000  0.0085  0.0330\n",
      " -0.0001  0.0000 -0.0108  ...  -0.0046  0.0244  0.0343\n",
      " -0.0010  0.0000  0.0235  ...  -0.0094 -0.0257 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0363  0.0065  0.0674  ...  -0.0033 -0.0117  0.0632\n",
      " -0.0000  0.0000  0.0029  ...   0.0033 -0.0041  0.0000\n",
      " -0.0009 -0.0086 -0.0000  ...   0.0000  0.0003  0.0000\n",
      "\n",
      "(32 ,.,.) = \n",
      " -0.0000 -0.0034  0.0068  ...  -0.0035 -0.0012 -0.0014\n",
      " -0.0000 -0.0000  0.0677  ...  -0.0056  0.0275 -0.0010\n",
      " -0.0012  0.0000 -0.0058  ...  -0.0052  0.0023 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0007  0.0067  0.0555  ...  -0.0181 -0.0205  0.0375\n",
      " -0.0000  0.0000 -0.0162  ...   0.0208 -0.0042 -0.0000\n",
      " -1.3390  0.0014 -0.0000  ...   0.0000  0.0681 -0.0000\n",
      "\n",
      "(33 ,.,.) = \n",
      " -0.0083 -0.0023 -0.0307  ...   0.0063 -0.0076  0.0187\n",
      " -0.0418 -0.0000 -0.0033  ...   0.0093 -0.0032  0.0310\n",
      " -0.0009 -0.0000 -0.0654  ...   0.0085  0.0128 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0017  0.0146  ...  -0.0092 -0.0111  0.0161\n",
      " -0.0000 -0.0000  0.0179  ...  -0.0050 -0.0219  0.0000\n",
      " -0.0000 -0.0013 -0.0000  ...   0.0000  0.0220 -0.0000\n",
      "[torch.cuda.FloatTensor of size 34x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.3172e-02 -5.8121e-02 -1.5386e-01  ...   4.9738e-03  2.0184e-03  5.9897e-03\n",
      " -6.1923e-01 -1.7171e-04 -1.4172e-01  ...  -3.3259e-03 -1.1009e-01  5.4783e-03\n",
      "  4.3283e-01 -7.6620e-02 -2.6092e-01  ...   1.4883e-01  1.0860e-03  2.4829e-04\n",
      "                 ...                                      ...                \n",
      "  2.3968e-01  3.8293e-02 -2.2121e-01  ...  -3.6213e-02 -7.1465e-02  1.6939e-03\n",
      "  4.7820e-03 -1.8917e-02 -4.6485e-02  ...  -1.3825e-02 -1.1562e-02  1.1573e-02\n",
      "  1.0673e-01  3.8021e-02 -1.8499e-03  ...   4.5558e-01 -4.3675e-05  1.0779e-05\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  3.2717e-02  1.0575e-01 -1.0086e-01  ...  -2.7735e-02  5.6001e-03  3.6023e-02\n",
      " -2.7141e-01 -1.8058e-02 -2.1632e-01  ...  -4.0746e-04 -3.0804e-04  6.8015e-05\n",
      "  1.9882e-01 -2.4179e-03 -2.2834e-01  ...  -6.1312e-02  1.2206e-02  2.8685e-02\n",
      "                 ...                                      ...                \n",
      "  2.8205e-02 -1.8164e-03  3.1635e-03  ...  -4.1072e-01 -3.1950e-02  4.5674e-02\n",
      "  4.8364e-05 -2.0810e-03  1.4605e-01  ...  -1.5950e-02 -2.4565e-02  1.3020e-02\n",
      "  1.1690e-01 -5.9496e-04 -5.1298e-02  ...   2.9779e-03  6.2466e-02  3.0039e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  3.2701e-01 -3.6393e-02 -3.9263e-02  ...  -1.7911e-01  2.5249e-04  6.6220e-04\n",
      " -7.3816e-02 -3.4210e-02 -4.7293e-02  ...  -4.9770e-02 -9.1066e-02  1.2248e-02\n",
      " -1.8295e-02  9.4666e-02 -1.9780e-01  ...  -1.1817e-01  6.2942e-03  1.0454e-02\n",
      "                 ...                                      ...                \n",
      "  1.4339e-02  1.5562e-01 -2.5281e-02  ...  -2.5088e-01 -3.1926e-02  8.1422e-03\n",
      "  3.2823e-02  2.1801e-02  5.1091e-01  ...  -1.0841e-02  1.2311e-02  3.6368e-03\n",
      "  3.3597e-02  1.1631e-02 -5.7602e-03  ...   3.2636e-02 -1.7977e-02  3.2373e-03\n",
      "... \n",
      "\n",
      "(31 ,.,.) = \n",
      "  4.4159e-02 -5.9593e-03 -9.8241e-03  ...  -2.4052e-01 -8.8644e-02  6.9446e-03\n",
      "  5.1910e-02 -1.1769e-02 -2.1300e-01  ...  -1.7661e-02 -1.3639e-02  7.1745e-03\n",
      "  9.0522e-03  5.2586e-02 -3.2545e-01  ...  -4.2842e-01  9.0310e-05  2.6579e-02\n",
      "                 ...                                      ...                \n",
      "  6.4813e-02  1.1201e-01 -8.5627e-02  ...  -2.7818e-01 -4.1579e-03  1.0640e-03\n",
      "  4.3895e-01  6.3065e-03  7.6125e-01  ...  -1.5249e-02 -6.7929e-03  5.8607e-03\n",
      " -1.0609e-02  1.3955e-01 -1.0406e-01  ...   1.3818e-01  1.9347e-01  9.0453e-03\n",
      "\n",
      "(32 ,.,.) = \n",
      "  9.9339e-03  6.6378e-02 -6.9819e-02  ...  -3.8188e-02 -8.8700e-02  1.7714e-03\n",
      "  5.3542e-02  1.4566e-01 -1.6365e-02  ...  -2.2848e-01 -1.5664e-02  9.4833e-03\n",
      "  1.2023e-02  5.6675e-04 -3.8980e-01  ...  -2.4319e-02 -4.8625e-03  1.8529e-01\n",
      "                 ...                                      ...                \n",
      "  2.7742e-02  9.7893e-03 -3.4462e-02  ...  -4.9815e-01 -5.5022e-03  2.8757e-02\n",
      " -1.2073e-01  1.2068e-02 -1.3942e-01  ...  -8.4616e-03 -8.0581e-02  5.1018e-02\n",
      " -1.2504e-02 -9.8580e-03 -1.1022e-01  ...   8.0981e-03  5.4365e-03  8.9168e-05\n",
      "\n",
      "(33 ,.,.) = \n",
      "  2.1396e-03  7.9393e-03 -1.8243e-02  ...  -1.0562e-01 -2.8212e-01  9.7555e-03\n",
      "  1.3765e-02  2.2509e-03 -3.0105e-01  ...  -5.3605e-02 -4.8097e-02  6.3061e-03\n",
      "  2.5308e-04  4.3010e-02 -3.5503e-01  ...  -4.1923e-02  3.5372e-03  6.4495e-02\n",
      "                 ...                                      ...                \n",
      "  1.5294e-02  1.5659e-01 -4.3767e-02  ...  -2.4194e-01 -1.2337e-02  1.1381e-03\n",
      "  3.8028e-02  1.5347e-01 -4.1073e-02  ...  -7.4117e-02 -4.5599e-02  1.6813e-03\n",
      " -2.2948e-01  1.7029e-01 -1.8818e-02  ...  -8.3916e-02  9.7576e-02  5.6416e-02\n",
      "[torch.cuda.FloatTensor of size 34x8x200 (GPU 0)]\n",
      "]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  1.0279  1.0879  ...  -0.0000 -0.0000  0.0068\n",
      "  1.0755  0.1046 -0.0000  ...  -0.0004 -0.0045 -0.0518\n",
      "  0.0000 -0.1226 -0.0000  ...  -0.2664  0.0000 -0.0004\n",
      "           ...                          ...          \n",
      "  0.3793 -0.0160 -0.0000  ...  -0.0423  0.0143 -0.0488\n",
      "  0.4796 -0.0000  0.0003  ...  -0.0000 -0.0349 -0.0404\n",
      "  0.0000  0.0264 -0.0000  ...  -0.0101  0.0186 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0006  0.0154 -0.0122  ...  -0.0000 -0.0000  0.0262\n",
      "  0.0036  0.2028  0.0040  ...  -0.0009  0.0217 -0.1038\n",
      "  0.0000 -0.0005 -0.0000  ...  -0.0002  0.0000 -0.0337\n",
      "           ...                          ...          \n",
      "  0.0699  0.0000  0.0229  ...  -0.2609 -0.0085 -0.1458\n",
      "  0.0001  0.0000  0.0003  ...  -0.0000 -0.0238  0.0342\n",
      "  0.0000  0.0000  0.0000  ...  -0.1542  0.0494 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.1526  0.0294 -0.0000  ...  -0.0000 -0.0000  0.0136\n",
      "  0.0002  0.0073  0.0842  ...  -0.0000  0.0078 -0.1066\n",
      " -0.0000  0.0001  0.0044  ...  -0.3641 -0.0000 -0.1478\n",
      "           ...                          ...          \n",
      "  0.0044  0.0000  0.0030  ...  -0.0003  0.0053 -0.1268\n",
      "  0.0029  0.0000  0.0333  ...  -0.0000  0.0101 -0.0839\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0297 -0.0000\n",
      "... \n",
      "\n",
      "(171,.,.) = \n",
      "  0.0000  0.0009  0.0789  ...  -0.0001 -0.0708 -0.0112\n",
      "  0.0005  0.0000  0.0000  ...  -0.0442 -0.0479 -0.0000\n",
      "  0.0000  0.0000 -0.0000  ...  -0.0000 -0.0000 -0.0458\n",
      "           ...                          ...          \n",
      "  0.0001  0.0002  0.0073  ...  -0.0018 -0.0245 -0.1766\n",
      "  0.0000  0.0010  0.0000  ...  -0.0000 -0.0462 -0.0000\n",
      " -0.0000  0.0000  0.0000  ...  -0.1600 -0.1571 -0.0598\n",
      "\n",
      "(172,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -1.4044 -0.0423 -0.0242\n",
      "  0.0000 -0.0006  0.0000  ...  -1.3172 -0.0061 -0.0000\n",
      "  0.0000  0.0000  0.1491  ...  -0.7466 -0.0000 -0.0850\n",
      "           ...                          ...          \n",
      "  0.0003  0.0006 -0.0000  ...  -0.0002 -0.0175 -0.0528\n",
      "  0.0000  0.0002  0.0000  ...  -0.0000 -0.0391 -0.0000\n",
      " -0.0000 -0.0000  0.0000  ...  -0.0594 -0.1134 -0.0445\n",
      "\n",
      "(173,.,.) = \n",
      "  0.0000  0.0001  0.1420  ...  -0.0112 -0.1233 -0.0463\n",
      "  0.0002  0.0000 -0.0000  ...  -0.0387 -0.0365 -0.0000\n",
      "  0.0000  0.0000  0.0719  ...  -0.0457 -0.0000 -0.0204\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.0002  ...  -1.3609 -0.0065 -0.0637\n",
      "  0.0026  0.0000  0.0000  ...  -0.0000 -0.0124 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -1.3914 -0.0381 -0.0566\n",
      "[torch.cuda.FloatTensor of size 174x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0000  0.0354  0.0773  ...   0.0251  0.0360 -0.0058\n",
      " -0.0209  0.0023  0.0025  ...   0.0016 -0.0000  0.0000\n",
      " -0.0000  0.0313 -0.0065  ...   0.0156  0.0075 -0.0019\n",
      "           ...                          ...          \n",
      " -0.6277  0.0291 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.1252 -0.0169  0.0895  ...   0.0087  0.0011  0.0095\n",
      " -0.0000  0.0204 -0.0000  ...   0.0063  0.0000  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0019  0.0843  ...  -0.0103 -0.0033 -0.0132\n",
      " -0.1143 -0.0122  0.0452  ...   0.0138  0.0000 -0.0000\n",
      " -0.0000  0.0262 -0.0471  ...  -0.0061  0.0229  0.0360\n",
      "           ...                          ...          \n",
      " -0.0884  0.0082 -0.0000  ...   0.0000  0.0000  0.0000\n",
      " -0.0448  0.0289  0.1652  ...  -0.0077  0.0582 -0.0444\n",
      " -0.0000  0.0035 -0.0000  ...  -0.0022  0.0000 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000 -0.0190  0.2087  ...  -0.0448  0.0122  0.0400\n",
      " -0.0001  0.0029 -0.0259  ...   0.0180  0.0000 -0.0000\n",
      " -0.0000 -0.0165 -0.0836  ...   0.0275  0.0155 -0.0384\n",
      "           ...                          ...          \n",
      " -0.0007 -0.0056 -0.0000  ...  -0.0000 -0.0000  0.0000\n",
      " -0.0154  0.0078  0.1028  ...  -0.0161  0.0292  0.0204\n",
      " -0.0000  0.0046 -0.0000  ...  -0.0189  0.0000  0.0000\n",
      "... \n",
      "\n",
      "(171,.,.) = \n",
      " -0.0034 -0.0034 -0.0300  ...   0.0000  0.0085  0.0330\n",
      " -0.0001  0.0000 -0.0108  ...  -0.0046  0.0244  0.0343\n",
      " -0.0010  0.0000  0.0235  ...  -0.0094 -0.0257 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0363  0.0065  0.0674  ...  -0.0033 -0.0117  0.0632\n",
      " -0.0000  0.0000  0.0029  ...   0.0033 -0.0041  0.0000\n",
      " -0.0009 -0.0086 -0.0000  ...   0.0000  0.0003  0.0000\n",
      "\n",
      "(172,.,.) = \n",
      " -0.0000 -0.0034  0.0068  ...  -0.0035 -0.0012 -0.0014\n",
      " -0.0000 -0.0000  0.0677  ...  -0.0056  0.0275 -0.0010\n",
      " -0.0012  0.0000 -0.0058  ...  -0.0052  0.0023 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0007  0.0067  0.0555  ...  -0.0181 -0.0205  0.0375\n",
      " -0.0000  0.0000 -0.0162  ...   0.0208 -0.0042 -0.0000\n",
      " -1.3390  0.0014 -0.0000  ...   0.0000  0.0681 -0.0000\n",
      "\n",
      "(173,.,.) = \n",
      " -0.0083 -0.0023 -0.0307  ...   0.0063 -0.0076  0.0187\n",
      " -0.0418 -0.0000 -0.0033  ...   0.0093 -0.0032  0.0310\n",
      " -0.0009 -0.0000 -0.0654  ...   0.0085  0.0128 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0017  0.0146  ...  -0.0092 -0.0111  0.0161\n",
      " -0.0000 -0.0000  0.0179  ...  -0.0050 -0.0219  0.0000\n",
      " -0.0000 -0.0013 -0.0000  ...   0.0000  0.0220 -0.0000\n",
      "[torch.cuda.FloatTensor of size 174x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  9.0547e-02 -1.6053e-02 -2.0524e-01  ...  -5.0069e-02 -2.6807e-02  6.4216e-02\n",
      "  1.8703e-02 -5.4080e-03  3.8728e-01  ...  -2.2465e-02 -5.0862e-02  7.7274e-02\n",
      "  1.1821e-01  3.9652e-02 -1.0448e-02  ...   9.4909e-02 -1.2077e-01  7.0657e-03\n",
      "                 ...                                      ...                \n",
      " -2.3282e-02 -4.1533e-02 -2.5343e-01  ...   2.4174e-02  1.0382e-03  7.3963e-03\n",
      "  1.8417e-02 -1.6327e-02  1.8099e-01  ...  -7.6748e-03 -9.2596e-03  3.5740e-02\n",
      " -6.6183e-02 -6.7840e-03 -2.6052e-01  ...   9.3761e-03 -2.5369e-02  9.6120e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.3644e-01 -1.1406e-02  1.3935e-01  ...  -4.1208e-02 -1.0905e-02  2.9066e-03\n",
      " -1.1752e-02  3.6244e-02  4.4647e-01  ...  -3.4705e-04 -1.4615e-01  1.5794e-03\n",
      " -4.8590e-02  8.0235e-05 -4.1436e-02  ...   2.5115e-02 -3.0961e-02  3.2041e-03\n",
      "                 ...                                      ...                \n",
      "  3.5181e-02 -3.1710e-03 -5.3312e-02  ...   1.8668e-02 -1.2576e-01  2.0937e-02\n",
      " -8.4733e-02  6.0892e-02  7.9093e-02  ...  -1.0436e-03 -6.2244e-04  5.5188e-03\n",
      "  5.8936e-03  8.4469e-03 -1.0303e-01  ...  -4.2216e-02 -3.2805e-02  4.6600e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  3.0598e-01 -6.4519e-02 -9.1244e-04  ...   3.2685e-01 -1.0116e-03  5.6556e-04\n",
      "  1.2977e-02  4.2382e-01 -2.4539e-03  ...  -7.6274e-02 -2.9456e-02  2.7899e-02\n",
      " -2.5468e-03  1.0370e-02  5.8431e-03  ...  -9.6991e-02 -1.1994e-01 -5.9386e-02\n",
      "                 ...                                      ...                \n",
      "  4.4425e-02  2.6894e-02  7.8933e-02  ...   1.7190e-02  5.8653e-03  3.5064e-03\n",
      " -2.2963e-02 -3.8927e-03  2.1931e-01  ...   6.7891e-02 -2.1075e-03  1.8736e-03\n",
      " -4.1300e-02  8.1013e-02 -2.0478e-01  ...   3.0819e-02  1.6370e-02  5.1991e-03\n",
      "... \n",
      "\n",
      "(171,.,.) = \n",
      "  4.4159e-02 -5.9593e-03 -9.8241e-03  ...  -2.4052e-01 -8.8644e-02  6.9446e-03\n",
      "  5.1910e-02 -1.1769e-02 -2.1300e-01  ...  -1.7661e-02 -1.3639e-02  7.1745e-03\n",
      "  9.0522e-03  5.2586e-02 -3.2545e-01  ...  -4.2842e-01  9.0310e-05  2.6579e-02\n",
      "                 ...                                      ...                \n",
      "  6.4813e-02  1.1201e-01 -8.5627e-02  ...  -2.7818e-01 -4.1579e-03  1.0640e-03\n",
      "  4.3895e-01  6.3065e-03  7.6125e-01  ...  -1.5249e-02 -6.7929e-03  5.8607e-03\n",
      " -1.0609e-02  1.3955e-01 -1.0406e-01  ...   1.3818e-01  1.9347e-01  9.0453e-03\n",
      "\n",
      "(172,.,.) = \n",
      "  9.9339e-03  6.6378e-02 -6.9819e-02  ...  -3.8188e-02 -8.8700e-02  1.7714e-03\n",
      "  5.3542e-02  1.4566e-01 -1.6365e-02  ...  -2.2848e-01 -1.5664e-02  9.4833e-03\n",
      "  1.2023e-02  5.6675e-04 -3.8980e-01  ...  -2.4319e-02 -4.8625e-03  1.8529e-01\n",
      "                 ...                                      ...                \n",
      "  2.7742e-02  9.7893e-03 -3.4462e-02  ...  -4.9815e-01 -5.5022e-03  2.8757e-02\n",
      " -1.2073e-01  1.2068e-02 -1.3942e-01  ...  -8.4616e-03 -8.0581e-02  5.1018e-02\n",
      " -1.2504e-02 -9.8580e-03 -1.1022e-01  ...   8.0981e-03  5.4365e-03  8.9168e-05\n",
      "\n",
      "(173,.,.) = \n",
      "  2.1396e-03  7.9393e-03 -1.8243e-02  ...  -1.0562e-01 -2.8212e-01  9.7555e-03\n",
      "  1.3765e-02  2.2509e-03 -3.0105e-01  ...  -5.3605e-02 -4.8097e-02  6.3061e-03\n",
      "  2.5308e-04  4.3010e-02 -3.5503e-01  ...  -4.1923e-02  3.5372e-03  6.4495e-02\n",
      "                 ...                                      ...                \n",
      "  1.5294e-02  1.5659e-01 -4.3767e-02  ...  -2.4194e-01 -1.2337e-02  1.1381e-03\n",
      "  3.8028e-02  1.5347e-01 -4.1073e-02  ...  -7.4117e-02 -4.5599e-02  1.6813e-03\n",
      " -2.2948e-01  1.7029e-01 -1.8818e-02  ...  -8.3916e-02  9.7576e-02  5.6416e-02\n",
      "[torch.cuda.FloatTensor of size 174x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "  0%|          | 4/3124 [10:48<140:33:01, 162.17s/it, loss=1.11]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "  0%|          | 5/3124 [11:50<123:02:14, 142.01s/it, loss=1.11]> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(135)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    133 \u001b[0;31m                \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    134 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 135 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m\u001b[0;32mclass\u001b[0m \u001b[0mLinearDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs[-1].size()\n",
      "*** AttributeError: 'list' object has no attribute 'size'\n",
      "ipdb> outputs\n",
      "[[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.1203  0.2014  0.2670  ...  -0.0057 -0.0407  0.0000\n",
      "  1.0623  0.1507 -0.0000  ...  -0.0000  0.0116 -0.0721\n",
      "  0.0000  1.0544  0.0168  ...  -0.0525 -0.0607 -0.0401\n",
      "           ...                          ...          \n",
      "  0.2327  0.0000 -0.0000  ...  -0.0100  0.0287 -0.0689\n",
      "  0.0008  0.8196  0.0000  ...  -0.0021 -0.0668  0.0000\n",
      "  0.0000  0.4915  0.0000  ...  -0.1868  0.0423 -0.0307\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0002  0.0067  0.0000  ...  -0.4284 -0.0087 -0.0000\n",
      "  0.0002  0.0027  1.0748  ...  -0.0000 -0.0297 -0.0385\n",
      "  0.0000  1.0362  0.0001  ...  -0.0000 -0.0725 -0.0041\n",
      "           ...                          ...          \n",
      "  0.0001  0.0000  1.0776  ...  -0.0064 -0.0414 -0.1351\n",
      "  0.0035 -0.0076  0.0000  ...  -0.6488 -0.0027 -0.0000\n",
      "  0.0000  0.0000 -0.0715  ...  -0.2579  0.0367 -0.1724\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0010  0.0007  0.0173  ...  -0.0055 -0.0225 -0.0000\n",
      "  0.0002  0.0005  0.0023  ...  -0.0000 -0.0115 -0.0390\n",
      "  0.0000  0.0868  0.0003  ...  -0.0000 -0.0698  0.0169\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  1.2294  ...  -0.0567 -0.0380 -0.0761\n",
      "  0.0003  0.2049  0.0000  ...  -0.0000 -0.0559 -0.0000\n",
      "  0.0000  0.0000 -0.0020  ...  -0.6266  0.0525 -0.0907\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0004  0.0011  0.0000  ...  -0.0003 -0.0268  0.0000\n",
      "  0.0091  0.0390  0.0036  ...  -0.0000 -0.0556 -0.0751\n",
      "  0.0000  0.0142  0.0017  ...  -0.0086 -0.1063  0.0828\n",
      "           ...                          ...          \n",
      "  0.0555  0.0000  0.9235  ...  -0.0106 -0.0128 -0.0640\n",
      "  0.1170  0.0000  0.0000  ...  -1.3546 -0.0130 -0.0000\n",
      "  0.0000  0.0007  0.9719  ...  -0.0022 -0.0105 -0.1135\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0011  0.0569  ...  -0.1307 -0.0079  0.0000\n",
      "  0.0006  0.0883  0.2702  ...  -0.0000 -0.0152 -0.0690\n",
      "  0.0000  0.0002  0.9754  ...  -1.3145 -0.0362 -0.0853\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  1.1122  ...  -0.1111 -0.0179 -0.0953\n",
      "  0.0001  0.0013  0.0000  ...  -0.0023 -0.0426 -0.0000\n",
      "  0.0000  0.0011  0.0528  ...  -0.2586  0.0364 -0.1753\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0630  0.0000  0.0360  ...  -0.0001  0.0033  0.0000\n",
      "  0.0009  0.0000  0.1215  ...  -0.0000 -0.0036 -0.0068\n",
      "  0.0000  0.0000  1.1079  ...  -0.0010 -0.0221 -0.0854\n",
      "           ...                          ...          \n",
      "  0.0008  0.0000  0.0004  ...  -0.2399  0.0054 -0.1178\n",
      "  0.0115  0.1159  0.0000  ...  -0.0000 -0.0037 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0649  0.0086 -0.0347\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0118  0.0002  0.0000  ...  -0.0000  0.0271  0.0172\n",
      " -0.0000 -0.0086 -0.0509  ...   0.0013 -0.0097 -0.0097\n",
      " -0.3010  0.0274  0.0000  ...   0.0000  0.0913  0.0654\n",
      "           ...                          ...          \n",
      " -0.7039  0.0088 -0.0438  ...   0.0227  0.0000  0.0076\n",
      " -0.0213  0.0257  0.2721  ...  -0.0000  0.0216  0.0427\n",
      " -0.5866 -0.0000  0.0109  ...   0.0159  0.0124  0.0073\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0066  0.0197 -0.0000  ...   0.0100 -0.0289  0.0092\n",
      " -0.0000 -0.0069 -0.0513  ...   0.0097 -0.0171 -0.0138\n",
      " -0.0000 -0.0031  0.0000  ...   0.0000  0.0134  0.0339\n",
      "           ...                          ...          \n",
      " -0.4064 -0.0010  0.0601  ...   0.0018  0.0000 -0.0202\n",
      " -0.0000  0.0018  0.0522  ...  -0.0000 -0.0378  0.0140\n",
      " -0.0003  0.0000  0.0046  ...   0.0015 -0.0149 -0.0102\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0026  0.0177 -0.0000  ...   0.0080 -0.0294  0.0511\n",
      " -0.0000 -0.0013 -0.0688  ...   0.0066  0.0047 -0.0008\n",
      " -0.0620  0.0080  0.0000  ...  -0.0000  0.0098  0.0262\n",
      "           ...                          ...          \n",
      " -0.0002 -0.0124  0.0057  ...  -0.0085  0.0000  0.0135\n",
      " -0.0120  0.0062  0.0619  ...  -0.0000 -0.0080 -0.0078\n",
      " -0.0000  0.0000 -0.0075  ...   0.0013 -0.0165 -0.0145\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -1.3429 -0.0085  0.0000  ...  -0.0186  0.0299 -0.0098\n",
      " -0.0000  0.0181  0.1530  ...   0.0100  0.0255  0.0144\n",
      " -0.9666  0.0161  0.0000  ...   0.0000  0.0331  0.0439\n",
      "           ...                          ...          \n",
      " -0.0094  0.0148 -0.0055  ...   0.0161  0.0000  0.0468\n",
      " -0.0003  0.0011  0.0362  ...   0.0000 -0.0281 -0.0157\n",
      " -0.0004 -0.0000 -0.0333  ...   0.0114 -0.0081  0.0263\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0345  0.0024  0.0000  ...   0.0041  0.0208 -0.0096\n",
      " -0.0000  0.0057 -0.0487  ...   0.0026  0.0274  0.0514\n",
      " -0.0005  0.0173 -0.0000  ...   0.0000  0.0097  0.0252\n",
      "           ...                          ...          \n",
      " -0.0000  0.0052 -0.0256  ...   0.0125  0.0000  0.0763\n",
      " -0.1631  0.0111  0.0014  ...   0.0000 -0.0053 -0.0025\n",
      " -0.0002  0.0000  0.0025  ...   0.0041 -0.0053  0.0162\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0074  0.0034  0.0000  ...  -0.0003 -0.0000  0.0023\n",
      " -0.0000  0.0086 -0.0621  ...   0.0136  0.0144  0.0415\n",
      " -0.0000  0.0131 -0.0000  ...  -0.0000  0.0345  0.0512\n",
      "           ...                          ...          \n",
      " -1.3134  0.0345  0.1339  ...   0.0164  0.0000  0.0505\n",
      " -0.0002  0.0081 -0.0071  ...   0.0000  0.0175 -0.0026\n",
      " -0.0001 -0.0000 -0.0048  ...   0.0095 -0.0131  0.0134\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -5.1802e-03  1.3690e-02  4.2789e-02  ...  -5.7836e-02 -6.7825e-02  1.4687e-02\n",
      " -5.7780e-02  6.6521e-03  3.7108e-01  ...  -2.3029e-02 -2.8528e-02  6.2480e-02\n",
      " -3.3851e-02  3.3785e-02 -1.4701e-01  ...   3.7199e-02 -5.2373e-03  1.9855e-02\n",
      "                 ...                                      ...                \n",
      "  1.3672e-02 -3.7273e-02 -1.2874e-01  ...   3.6899e-02  2.8976e-03  4.6424e-03\n",
      " -3.8872e-02  1.1902e-02  2.2493e-01  ...  -1.3780e-01 -1.8635e-02  7.7463e-02\n",
      "  1.0265e-02  3.9806e-03 -1.2600e-01  ...   1.3483e-02 -2.1334e-03  6.6054e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  4.4655e-02  3.6596e-02 -3.8554e-03  ...   4.4402e-02 -4.0145e-02  2.6596e-03\n",
      "  3.9205e-03 -9.1737e-02 -2.3739e-01  ...   5.6661e-02  5.1622e-03  5.8671e-03\n",
      " -1.7147e-01  1.5610e-01 -1.4801e-01  ...   1.6742e-02  1.3414e-02  5.5239e-03\n",
      "                 ...                                      ...                \n",
      "  1.3196e-01 -7.1455e-05 -1.4382e-01  ...  -4.5849e-02 -1.2068e-02  1.8030e-02\n",
      "  4.2198e-02  8.3415e-02 -2.7305e-02  ...  -8.4920e-02 -1.3645e-02  1.2678e-02\n",
      "  3.7452e-02  1.4637e-02  3.4703e-02  ...  -6.8702e-03 -8.9994e-02  7.1971e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  1.1459e-02  1.1481e-02 -8.2179e-02  ...   3.6689e-02 -1.1950e-01  3.5259e-02\n",
      "  3.6867e-02  8.8298e-03 -4.3731e-02  ...   1.0142e-01  1.6975e-01  1.7540e-02\n",
      " -1.0857e-01 -3.2389e-03  5.4021e-01  ...  -3.5778e-04 -8.6116e-03  9.1528e-03\n",
      "                 ...                                      ...                \n",
      "  1.4409e-01  2.2776e-02 -2.8356e-02  ...  -5.4030e-03 -2.7029e-02  2.4835e-02\n",
      " -1.2766e-02  1.0539e-02 -4.2866e-01  ...  -1.8772e-03 -1.7710e-03  2.3454e-03\n",
      "  2.1759e-02  2.2187e-01 -6.2478e-02  ...   6.0411e-03 -3.5166e-02  7.2553e-04\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  3.4813e-03 -1.7801e-03 -1.7217e-03  ...   6.5254e-02 -5.0624e-03  3.2242e-03\n",
      "  1.6632e-01 -1.2653e-02 -6.6108e-03  ...   6.0406e-01 -1.7636e-03  1.4221e-03\n",
      "  5.1955e-02 -3.5170e-02 -6.3347e-03  ...   1.6949e-01 -2.1810e-03  5.0595e-05\n",
      "                 ...                                      ...                \n",
      "  5.8264e-02  1.2172e-01 -9.3772e-02  ...  -1.7130e-01 -4.8604e-02 -5.0204e-03\n",
      " -7.2940e-02 -5.4800e-03 -1.5778e-01  ...   1.1486e-01 -3.9192e-03  1.0775e-02\n",
      "  1.0381e-01  1.1697e-01 -1.4641e-01  ...   5.2717e-02 -1.3308e-01  7.2949e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      "  1.1766e-02  1.5707e-02 -1.4027e-01  ...   1.5794e-02 -9.7747e-02  3.0519e-01\n",
      "  2.8717e-02 -7.0867e-03 -2.2007e-02  ...   6.3698e-02 -2.8336e-01  1.5248e-02\n",
      "  9.6469e-02  8.0781e-04 -2.8157e-01  ...   1.7609e-01 -1.7054e-01  1.0665e-02\n",
      "                 ...                                      ...                \n",
      " -7.9437e-02 -5.0533e-03 -4.1199e-01  ...  -8.2352e-02  2.1114e-02 -2.1362e-03\n",
      "  1.9570e-01  5.0641e-02 -1.2475e-01  ...   2.5784e-01 -1.5552e-01  1.3207e-03\n",
      "  2.6758e-02  1.3101e-02 -2.4581e-02  ...   8.9018e-02 -3.1405e-01  6.7643e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      "  3.4412e-02  3.3922e-02 -8.8498e-03  ...   2.0389e-02 -2.3633e-04  1.7321e-02\n",
      "  4.5343e-02  4.8673e-03  5.9566e-02  ...   8.4885e-02 -4.1322e-01  1.0508e-02\n",
      " -6.9942e-04  4.6980e-02 -9.0802e-03  ...   2.0727e-01 -3.5130e-02  2.7655e-03\n",
      "                 ...                                      ...                \n",
      " -7.0240e-03 -1.8745e-01 -9.8549e-03  ...   5.4805e-02  6.3519e-03  5.3632e-04\n",
      "  3.2351e-02  1.4943e-01 -5.9125e-02  ...   2.6231e-01 -2.9795e-02  2.0682e-02\n",
      "  1.5211e-02  3.0852e-02 -5.8484e-02  ...   4.6600e-01 -3.3472e-02  5.3961e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0267 -0.0000  ...  -0.0000  0.0000 -0.0000\n",
      "  0.0000  0.0000  1.0128  ...  -0.0002 -0.0260 -0.0435\n",
      "  0.0000  0.0020  0.0000  ...  -0.0000 -0.0452 -0.0499\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0003 -0.0233 -0.1403\n",
      "  0.0070  0.0000  0.0008  ...  -0.0000  0.0124  0.0123\n",
      "  0.0000  0.0005 -0.0000  ...  -0.0001 -0.0000 -0.0150\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.1295  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.1931  ...  -0.0000  0.0320 -0.1282\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0606 -0.1169\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0394 -0.0367\n",
      "  0.0000  0.0000  0.0011  ...  -0.0000 -0.0103 -0.0270\n",
      "  0.0000  0.0124  1.0349  ...  -0.9286 -0.0000 -0.0360\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000 -0.0002  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.0001  ...  -0.0000  0.0479 -0.0994\n",
      "  0.0000  0.0226 -0.0000  ...  -0.0000 -0.0317 -0.1365\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0001 -0.1095  0.0286\n",
      "  0.0001  0.0000 -0.0450  ...  -0.0000 -0.0413 -0.0411\n",
      "  0.0000 -0.0000  0.2391  ...  -0.0023 -0.0000  0.0539\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0971  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  1.0859  ...  -0.0824 -0.0622 -0.0229\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0527 -0.0163\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.0000  ...  -0.0000 -0.0723  0.0320\n",
      "  0.0293  0.0000  0.0000  ...  -0.0000  0.0095 -0.0281\n",
      "  0.0000  0.0008  0.7541  ...  -0.0005 -0.0000 -0.0834\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0001 -0.0138 -0.0406\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0449 -0.0176\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0003 -0.1174  0.0589\n",
      "  0.0313  0.0000  0.0557  ...  -0.0000  0.0022 -0.0765\n",
      "  0.0000  0.0000  0.0048  ...  -0.0000 -0.0000 -0.0558\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.9492  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.3586  ...  -0.1955 -0.0581 -0.0087\n",
      "  0.0000  0.0419  0.0000  ...  -0.0000 -0.0840  0.0159\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0794  0.0060\n",
      "  0.0000  0.0000  0.0011  ...  -0.0000 -0.0696 -0.0449\n",
      "  0.0000 -0.0322  0.0162  ...  -0.0031 -0.0000 -0.0018\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.3007  0.0293 -0.0000  ...  -0.0000  0.0711  0.0509\n",
      " -0.0000 -0.0007 -0.0000  ...  -0.0032  0.0178  0.0503\n",
      " -0.0000  0.0028 -0.0216  ...  -0.0000  0.0092  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0056 -0.0188  ...   0.0000  0.0525  0.0453\n",
      " -0.0000  0.0000 -0.0000  ...   0.0170 -0.0041  0.0005\n",
      " -0.0000 -0.0168  0.1189  ...  -0.0071  0.0029  0.0388\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0102  0.0093 -0.0000  ...   0.0000  0.0459  0.0737\n",
      " -0.0611  0.0008  0.0000  ...  -0.0002  0.0194  0.0285\n",
      " -0.0000  0.0111 -0.1466  ...   0.0000  0.0078  0.0000\n",
      "           ...                          ...          \n",
      " -0.0143 -0.0001 -0.0184  ...   0.0000  0.0137  0.0184\n",
      " -0.0000  0.0000 -0.0000  ...  -0.0069 -0.0074  0.0277\n",
      " -0.0000  0.0020 -0.0342  ...   0.0123  0.0063  0.0236\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000  0.0027 -0.0000  ...  -0.0000  0.0232  0.0441\n",
      " -0.0035 -0.0038 -0.0000  ...   0.0131  0.0032  0.0150\n",
      " -0.0000 -0.0067 -0.0194  ...   0.0000  0.0020  0.0000\n",
      "           ...                          ...          \n",
      " -0.0102 -0.0046 -0.0955  ...   0.0000 -0.0342  0.0176\n",
      " -0.0000  0.0000  0.0000  ...  -0.0064  0.0234  0.0409\n",
      " -0.0000  0.0132 -0.0424  ...  -0.0002  0.0242  0.0601\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0465  0.0021 -0.0000  ...   0.0000 -0.0085  0.0516\n",
      " -0.0000  0.0081 -0.0000  ...  -0.0092  0.0372  0.0496\n",
      " -0.0000 -0.0175 -0.0077  ...  -0.0000 -0.0333  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0029 -0.0010  ...   0.0000  0.0113  0.0193\n",
      " -0.0000 -0.0000 -0.0000  ...   0.0060  0.0210  0.0253\n",
      " -0.0000  0.0120 -0.0261  ...   0.0129  0.0296  0.0486\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000  0.0059 -0.0000  ...   0.0000 -0.0095  0.0446\n",
      " -1.2731  0.0226  0.0000  ...  -0.0425  0.0638  0.0090\n",
      " -0.0000 -0.0120  0.0373  ...  -0.0000 -0.0395  0.0000\n",
      "           ...                          ...          \n",
      " -0.1202  0.0078  0.0259  ...   0.0000  0.0517  0.0441\n",
      " -0.0000  0.0000 -0.0000  ...  -0.0076  0.0258  0.0308\n",
      " -0.0000  0.0101 -0.0545  ...   0.0046  0.0332  0.0404\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0703 -0.0067 -0.0000  ...   0.0000 -0.0001  0.0309\n",
      " -0.0109  0.0045 -0.0000  ...  -0.0158  0.0391  0.0564\n",
      " -0.0000 -0.0011  0.0567  ...   0.0000  0.0087  0.0000\n",
      "           ...                          ...          \n",
      " -1.0325  0.0177  0.0170  ...   0.0000  0.1242  0.0312\n",
      " -0.0000  0.0000  0.0000  ...   0.0282  0.0457  0.0086\n",
      " -0.0000  0.0020 -0.0344  ...   0.0023  0.0142  0.0250\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.7388e-01  1.2994e-01 -5.4149e-02  ...  -2.9881e-02  4.5081e-04  2.0077e-03\n",
      "  2.7116e-02  9.8098e-02 -8.5039e-03  ...   5.1957e-03 -1.0744e-03  1.0699e-02\n",
      "  8.4492e-02 -4.9012e-03  5.1821e-01  ...   1.5255e-01 -1.2598e-02  1.2681e-03\n",
      "                 ...                                      ...                \n",
      "  1.4740e-02 -8.4350e-02 -2.5300e-02  ...   1.2821e-02  7.1321e-03  2.5126e-01\n",
      " -3.8037e-02  1.1654e-02  4.8306e-02  ...  -2.1862e-02 -2.7421e-02  1.6258e-02\n",
      "  3.0175e-01 -1.4768e-02 -4.0016e-02  ...   7.3197e-02 -5.5459e-04  4.1668e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  7.4243e-02  2.3415e-02 -1.2776e-01  ...  -6.1638e-02  4.4828e-02  9.9127e-02\n",
      "  2.2664e-01  1.9093e-02  3.2367e-01  ...   3.7384e-03 -6.0339e-03  1.9728e-04\n",
      "  1.4410e-01 -1.7767e-02  6.8877e-01  ...   5.3177e-02 -7.5169e-03  1.4685e-03\n",
      "                 ...                                      ...                \n",
      "  1.0265e-01 -7.2403e-03 -1.2720e-01  ...   1.3021e-01 -3.3159e-05  6.6843e-04\n",
      " -1.8273e-03  2.1251e-01 -4.7810e-02  ...  -3.5169e-02  1.2425e-03  1.8031e-02\n",
      "  2.0368e-01 -2.4945e-03 -4.3046e-02  ...   1.2051e-02 -3.6486e-02  2.6731e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  7.9515e-02  7.4681e-03 -4.4642e-02  ...   3.6231e-03 -9.3835e-03  1.7948e-01\n",
      "  1.7691e-01  8.6150e-02  2.4171e-01  ...  -1.3446e-02 -3.1242e-01  1.7563e-04\n",
      "  2.8585e-02 -7.5298e-03  6.7196e-02  ...   3.1988e-02 -2.5716e-01  4.9125e-02\n",
      "                 ...                                      ...                \n",
      "  2.7105e-01 -1.0831e-01  2.9067e-01  ...  -5.6128e-02 -1.1233e-01  1.7732e-02\n",
      " -2.3998e-02  1.7471e-03 -8.0171e-02  ...   4.8095e-02 -1.3718e-01  6.4633e-02\n",
      " -6.5642e-03  4.8014e-05  2.3760e-01  ...  -6.0320e-04 -1.9916e-02  1.2974e-02\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  1.7360e-01  5.3242e-02 -1.1316e-01  ...  -9.2861e-02 -2.3233e-02  4.4366e-02\n",
      " -4.7260e-02  8.8299e-03 -3.3452e-01  ...   1.2545e-03  4.9226e-02  2.1256e-02\n",
      " -5.0465e-02  2.2155e-02 -6.9420e-02  ...   4.3097e-02 -3.9540e-02  5.0725e-03\n",
      "                 ...                                      ...                \n",
      "  1.9328e-01  1.2442e-02  4.3948e-02  ...  -1.4937e-01  1.6718e-02  1.7284e-03\n",
      " -1.1527e-02  2.0131e-02 -7.4309e-02  ...   2.9515e-02 -3.2144e-03  8.3130e-03\n",
      "  8.1142e-03 -7.9294e-03 -9.5823e-02  ...  -5.6235e-03 -6.6916e-02 -1.2509e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      "  1.4300e-01  3.5000e-02 -1.7146e-03  ...  -2.1254e-01 -3.5533e-03  2.9521e-02\n",
      "  2.1891e-02 -2.0972e-02 -1.2969e-02  ...   1.7185e-02  7.3765e-04  5.8692e-05\n",
      " -2.4815e-01  5.2776e-02 -1.5268e-01  ...  -8.6884e-02  1.4438e-03  5.5467e-04\n",
      "                 ...                                      ...                \n",
      "  3.6106e-01 -3.8846e-03  1.3078e-01  ...  -1.1064e-01 -6.5017e-03  2.4102e-04\n",
      " -4.9341e-02  5.8681e-02  8.7371e-02  ...  -1.0566e-01  2.3009e-02  7.3757e-03\n",
      "  3.8315e-02  7.8749e-04 -1.6612e-01  ...   6.7360e-03 -5.0302e-02  7.4408e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.8654e-01  4.4167e-02 -7.0806e-02  ...  -1.6018e-02 -3.8873e-03  1.1661e-02\n",
      "  2.6244e-02  1.5356e-03 -1.5731e-01  ...  -8.9323e-03  1.8196e-02  2.2854e-01\n",
      " -3.4726e-02  8.0267e-03  3.1070e-01  ...  -1.4766e-02 -4.7688e-02  4.6098e-02\n",
      "                 ...                                      ...                \n",
      "  5.5789e-01 -1.8797e-02 -3.6046e-03  ...   4.6707e-03  1.4038e-04  1.1348e-03\n",
      " -1.7618e-02  7.6341e-04  6.9924e-01  ...   3.3499e-01 -9.8378e-03  3.5296e-04\n",
      " -6.4508e-02  1.3623e-01 -2.7978e-01  ...   2.0529e-02 -7.1114e-03  5.6234e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0019  0.0229  0.0000  ...  -0.0000 -0.0557 -0.0000\n",
      "  0.0047  0.0000  0.0254  ...  -0.1992 -0.0220  0.0209\n",
      "  0.0015  0.0010  0.0000  ...  -0.0003 -0.0979  0.0730\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  1.0457  ...  -1.3784 -0.0903 -0.0607\n",
      "  0.0000  0.0010  0.0107  ...  -0.0605 -0.0576 -0.0143\n",
      "  0.6633  0.0015  0.0274  ...  -0.0000 -0.0000 -0.0154\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0358  0.7798  ...  -0.4901 -0.1349 -0.0000\n",
      "  0.0004  0.0248  0.3763  ...  -0.0013 -0.0098  0.0098\n",
      "  0.0000  0.0001  0.0000  ...  -0.0002 -0.0870  0.0649\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0005 -0.0477 -0.0018\n",
      "  0.0000  0.0066  1.0694  ...  -0.6171 -0.0370 -0.0412\n",
      "  0.0008  1.0109  0.0041  ...  -0.0000 -0.0000 -0.0208\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.1403  0.0000  0.0004  ...  -0.0000 -0.0869 -0.0000\n",
      "  0.0001  0.0363  0.4217  ...  -0.3626 -0.0265  0.0242\n",
      "  0.0009  0.0000  0.0000  ...  -0.0006 -0.0988  0.1206\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0352  ...  -0.0025 -0.0967  0.0580\n",
      "  0.0000  0.0001  0.0015  ...  -1.2680 -0.0275 -0.0450\n",
      "  0.0078  0.0570  1.0912  ...  -0.0000 -0.0000 -0.0404\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0005  0.0081  0.0354  ...  -0.0000  0.0007 -0.0000\n",
      "  0.0016  0.0001  0.0346  ...  -0.7957  0.0058 -0.0290\n",
      "  0.0006  0.0142  0.0000  ...  -0.0004 -0.1395  0.0402\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.3557  ...  -0.0003 -0.0382  0.0855\n",
      "  0.0000 -0.0015  0.0000  ...  -0.0355 -0.0239 -0.0542\n",
      "  1.3679  0.0000  0.0109  ...  -0.0000 -0.0000  0.0004\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0014  0.0001  0.0305  ...  -0.0003  0.0260 -0.0000\n",
      "  0.0386  0.0124  0.0098  ...  -0.7276  0.0260 -0.0816\n",
      "  0.0008 -0.0000  0.0000  ...  -0.0041 -0.0622  0.0398\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0359  0.1207\n",
      "  0.0000  0.3348  0.9016  ...  -0.0000 -0.0420 -0.0664\n",
      "  0.0002  0.2387  0.0000  ...  -0.0000 -0.0000 -0.0266\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.3744  0.0000  0.0000  ...  -0.0000 -0.0240 -0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -1.3461  0.0172 -0.0366\n",
      "  0.0001  0.0003  0.0000  ...  -0.0986 -0.0638  0.0144\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0004 -0.0639  0.0826\n",
      "  0.0000  0.0099  0.0195  ...  -1.1016 -0.1073 -0.1443\n",
      "  0.0001  0.0091  0.0085  ...  -0.0000 -0.0000  0.0084\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.2827  0.0047 -0.0000  ...   0.0107  0.0000  0.0226\n",
      " -0.0632  0.0090 -0.0162  ...  -0.0000  0.0193  0.0110\n",
      " -0.0021 -0.0053 -0.0271  ...   0.0151  0.0358  0.0000\n",
      "           ...                          ...          \n",
      " -0.0002  0.0121 -0.0139  ...   0.0079  0.0393  0.0000\n",
      " -0.0000  0.0048  0.0318  ...   0.0083  0.0000  0.0000\n",
      " -0.0018  0.0121  0.0000  ...   0.0000 -0.0000  0.0495\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0018 -0.0031 -0.0000  ...   0.0112  0.0000  0.0623\n",
      " -0.6762  0.0136  0.0500  ...  -0.0000  0.0099  0.0104\n",
      " -0.0001  0.0069 -0.0074  ...   0.0184  0.0110  0.0000\n",
      "           ...                          ...          \n",
      " -0.0092  0.0107 -0.0419  ...   0.0068 -0.0082  0.0000\n",
      " -0.0000  0.0106 -0.0174  ...   0.0203  0.0000 -0.0000\n",
      " -1.1804 -0.0022 -0.0000  ...   0.0000  0.0000  0.0007\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0002 -0.0033 -0.0000  ...   0.0018  0.0000  0.0435\n",
      " -0.0018  0.0035  0.0034  ...  -0.0000  0.0184  0.0434\n",
      " -0.0009  0.0016  0.0268  ...   0.0048 -0.0422  0.0000\n",
      "           ...                          ...          \n",
      " -0.0123 -0.0037 -0.0865  ...   0.0055 -0.0291  0.0000\n",
      " -0.0000  0.0036  0.0016  ...  -0.0026 -0.0000 -0.0000\n",
      " -0.0000 -0.0012  0.0000  ...   0.0000  0.0000  0.0292\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0008  0.0000  ...  -0.0015  0.0000 -0.0022\n",
      " -0.0415  0.0087 -0.0080  ...   0.0000  0.0290 -0.0094\n",
      " -1.4128 -0.0074 -0.0079  ...   0.0032  0.0588  0.0000\n",
      "           ...                          ...          \n",
      " -0.0049  0.0052  0.1332  ...  -0.0068 -0.0050  0.0000\n",
      " -0.0000  0.0089 -0.0162  ...  -0.0032  0.0000  0.0000\n",
      " -0.0074  0.0007  0.0000  ...   0.0000 -0.0000  0.0669\n",
      "\n",
      "(68 ,.,.) = \n",
      " -1.1596  0.0038 -0.0000  ...   0.0090 -0.0000 -0.0030\n",
      " -0.0006  0.0051  0.0140  ...  -0.0000  0.0105 -0.0165\n",
      " -0.0005  0.0000 -0.0068  ...  -0.0009  0.0519  0.0000\n",
      "           ...                          ...          \n",
      " -1.2347 -0.0084  0.3450  ...  -0.0167 -0.0321  0.0000\n",
      " -0.0000 -0.0016  0.1258  ...  -0.0146 -0.0000  0.0000\n",
      " -0.0258 -0.0004  0.0000  ...  -0.0000 -0.0000  0.0462\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0001 -0.0034 -0.0000  ...   0.0009 -0.0000  0.0081\n",
      " -0.0000  0.0070  0.0011  ...   0.0000  0.0019 -0.0113\n",
      " -0.0196  0.0103 -0.0938  ...   0.0193  0.0594  0.0000\n",
      "           ...                          ...          \n",
      " -0.0261 -0.0042 -0.0271  ...   0.0149 -0.0080  0.0000\n",
      " -0.0000  0.0010 -0.0225  ...   0.0002  0.0000  0.0000\n",
      " -0.0003 -0.0069  0.0000  ...   0.0000 -0.0000  0.0146\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  3.3326e-01 -2.1125e-02 -1.5370e-03  ...   6.7297e-02 -5.5764e-04  6.5478e-04\n",
      " -3.8903e-02  2.9800e-03 -5.0229e-02  ...   2.4918e-03  1.2016e-03  1.5100e-01\n",
      " -9.9674e-03  6.4069e-04  4.4821e-01  ...  -8.8438e-02 -1.0577e-01  2.5167e-03\n",
      "                 ...                                      ...                \n",
      "  2.7983e-01 -3.4891e-03 -8.2780e-03  ...  -6.6877e-02  1.1649e-01  3.0953e-02\n",
      "  3.1879e-03  2.1441e-03  1.9221e-01  ...   1.0500e-01  2.9798e-02  1.8881e-01\n",
      " -9.8062e-02  4.7430e-03  2.8116e-01  ...   1.5963e-03 -1.4043e-02  6.6068e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  4.6035e-02  4.4953e-03 -6.6627e-02  ...  -1.0129e-01  2.6083e-02  1.2608e-02\n",
      "  2.1276e-01 -1.4314e-02 -3.8982e-02  ...   1.2819e-02  1.4754e-04  1.5032e-02\n",
      " -8.6171e-03  6.3393e-03 -5.6591e-01  ...  -4.4337e-02  1.9228e-03  2.1608e-03\n",
      "                 ...                                      ...                \n",
      "  1.5506e-01  8.0063e-03  1.1155e-01  ...  -1.5116e-01  5.8428e-03  8.0122e-03\n",
      "  6.1582e-03  1.0144e-02 -1.5324e-01  ...   1.5124e-01  1.3151e-02  4.6962e-02\n",
      " -1.9983e-01 -1.3993e-01 -1.5298e-01  ...   2.2688e-03 -1.2873e-03  4.0493e-05\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -2.4874e-03  4.4925e-02 -5.0493e-02  ...   6.9394e-02  7.9095e-03  9.0226e-03\n",
      "  4.5611e-02  3.5106e-03 -3.0068e-02  ...   1.5652e-03 -7.3690e-02  8.0240e-02\n",
      "  9.0392e-02  2.2132e-02 -8.7070e-02  ...  -8.4926e-02 -9.5905e-02  9.1274e-03\n",
      "                 ...                                      ...                \n",
      "  5.9225e-02  9.5306e-03 -1.8715e-01  ...  -3.5561e-03 -1.4661e-01  3.8869e-02\n",
      "  2.1240e-02  2.8684e-01 -1.2641e-01  ...   1.8736e-01  1.6662e-03  6.7950e-03\n",
      " -3.8370e-03  4.6018e-02 -5.4298e-01  ...   1.7981e-02  3.2452e-03  2.9660e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  9.0905e-02  6.0826e-02  4.1391e-01  ...   4.0547e-02  1.1334e-03  2.1517e-02\n",
      "  3.6595e-02  6.3945e-03 -3.3320e-02  ...   3.6541e-02  3.4818e-03  1.9694e-01\n",
      " -9.1403e-02 -1.8151e-02 -1.3453e-02  ...  -2.1807e-03 -9.1323e-03 -8.4509e-04\n",
      "                 ...                                      ...                \n",
      " -6.6695e-03  3.3595e-02 -2.7731e-01  ...  -4.7269e-02 -2.6826e-01  3.6553e-03\n",
      "  2.1326e-02  3.7519e-01 -1.9032e-01  ...   1.6916e-01 -7.3956e-02  1.0594e-02\n",
      " -2.4757e-02  3.9820e-02 -1.1723e-01  ...  -1.1288e-01 -2.2142e-04  1.8268e-04\n",
      "\n",
      "(68 ,.,.) = \n",
      "  5.6549e-02 -1.6479e-02 -3.1591e-01  ...  -2.6582e-03 -2.7974e-03  5.8108e-03\n",
      "  5.4618e-02  6.2795e-03  4.4116e-02  ...   3.1844e-02 -1.8931e-02  8.6198e-02\n",
      " -8.0053e-02 -5.2997e-05 -1.9121e-02  ...  -1.0417e-02 -1.6020e-01  9.7229e-03\n",
      "                 ...                                      ...                \n",
      " -1.1253e-01  1.2439e-02 -9.1929e-02  ...  -4.7706e-02 -5.9819e-03  3.9192e-05\n",
      "  5.5502e-02 -1.0333e-02 -4.8622e-03  ...   7.4289e-02 -1.2740e-03  7.1431e-04\n",
      "  4.7244e-02  5.7538e-02 -3.7376e-01  ...  -5.4097e-02 -7.0691e-03  3.6305e-04\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.8463e-01  1.9169e-04 -2.0740e-01  ...  -3.6295e-03 -3.7270e-04  1.0480e-02\n",
      "  2.5863e-02  1.4715e-01 -2.3517e-02  ...  -3.7499e-02  4.5949e-02  3.2116e-02\n",
      " -4.4951e-02  2.0350e-02 -1.1970e-01  ...   9.5192e-02 -3.3232e-02  3.7168e-03\n",
      "                 ...                                      ...                \n",
      " -1.8438e-01 -1.0919e-03 -2.4856e-01  ...  -1.6269e-02 -2.4745e-04  1.1165e-01\n",
      "  3.8497e-02  2.2358e-03 -3.3682e-03  ...   4.4153e-02 -5.7426e-02  1.4470e-01\n",
      "  6.5800e-03  6.3289e-02 -2.4820e-01  ...   6.9904e-03 -5.8623e-02  3.2326e-04\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0323  1.0370  ...  -0.0237 -0.0790 -0.0799\n",
      "  0.0000  0.0146  0.0385  ...  -0.0026 -0.0600 -0.0426\n",
      "  0.1651  0.0000  0.0000  ...  -0.0012 -0.0492  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0012  0.0004  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0112 -0.1985  0.0000  ...  -1.1582 -0.0392 -0.0000\n",
      "  0.0131  0.0076  0.0005  ...  -0.0320 -0.0535 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.4056  0.0000  ...  -0.0008 -0.0282 -0.0906\n",
      "  0.0000  0.0561  0.0000  ...  -0.0561 -0.0525 -0.0192\n",
      "  0.0001  0.0097  0.0000  ...  -0.3662 -0.1120  0.0000\n",
      "           ...                          ...          \n",
      "  0.1390  0.6687 -0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      " -0.0001  0.0000  0.5865  ...  -1.0611 -0.0614 -0.0000\n",
      "  0.0000  0.1700  0.7862  ...  -1.3815 -0.0616 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.1033  0.0003  ...  -1.2225 -0.1048 -0.2127\n",
      "  0.0000  1.0672  0.0001  ...  -0.0017 -0.0360 -0.0165\n",
      "  0.0001  0.0004  0.0000  ...  -0.8718 -0.0513  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0004  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.4190  0.0000  0.0048  ...  -0.0001 -0.0502 -0.0000\n",
      "  0.0093  0.0001  0.0231  ...  -1.0960  0.0019 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000 -0.0010  0.0000  ...  -1.2856 -0.0084  0.0067\n",
      "  0.0000  0.7909  0.0000  ...  -1.3900 -0.0184 -0.0532\n",
      "  0.0062  0.8785  0.0000  ...  -0.0000 -0.0965 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0010  0.0080  0.1061  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0001  0.0010  0.8971  ...  -1.1521 -0.0141 -0.0000\n",
      "  0.0004  0.0162  0.0001  ...  -0.0342 -0.0369 -0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0816  0.0000  ...  -0.0033 -0.0527 -0.0083\n",
      "  0.0000 -0.0473  0.0003  ...  -0.0906 -0.0271 -0.0369\n",
      "  0.0001  0.0001  0.0000  ...  -0.0010 -0.0469 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0094  0.0386  0.0051  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0101  0.0000  0.0040  ...  -0.8759  0.0177 -0.0000\n",
      "  0.0000  0.0071 -0.0000  ...  -1.3204 -0.0216 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.9740  0.0000  ...  -0.0010 -0.0180 -0.0019\n",
      "  0.0000  0.0320  0.0322  ...  -0.0382 -0.0440 -0.0414\n",
      "  0.0469  0.0009  0.0000  ...  -0.0003 -0.0799 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0019  0.0375  0.1834  ...  -0.0000  0.0000 -0.0000\n",
      "  0.0005  0.0000  0.0015  ...  -0.0001 -0.0178 -0.0000\n",
      "  0.0092  0.0001 -0.0000  ...  -0.0243  0.0033 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0015 -0.0000 -0.0779  ...   0.0000  0.0046  0.0375\n",
      " -0.0000  0.0000  0.0196  ...   0.0019 -0.0000  0.0089\n",
      " -0.0163 -0.0015 -0.0345  ...  -0.0399 -0.0161  0.0273\n",
      "           ...                          ...          \n",
      " -0.0001 -0.0029  0.0000  ...  -0.0053 -0.0000  0.0076\n",
      " -0.0276 -0.0021 -0.0000  ...   0.0304  0.0000 -0.0000\n",
      " -1.3573  0.0251 -0.4523  ...  -0.0028 -0.0466  0.0234\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.1119 -0.0000 -0.0137  ...   0.0000  0.0498  0.0259\n",
      " -0.0000  0.0000  0.1240  ...  -0.0123 -0.0000  0.0131\n",
      " -0.0015  0.0019 -0.0460  ...  -0.0056  0.0203  0.0287\n",
      "           ...                          ...          \n",
      " -0.0433  0.0012  0.0000  ...  -0.0081 -0.0000  0.0212\n",
      " -0.0016  0.0021 -0.0000  ...   0.0136  0.0000 -0.0000\n",
      " -0.0008  0.0114 -0.0755  ...  -0.0028 -0.0303  0.0172\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0010 -0.0000  0.0099  ...   0.0000  0.0813  0.0828\n",
      " -0.0000 -0.0000  0.1727  ...   0.0116 -0.0000  0.0016\n",
      " -0.0000  0.0022 -0.0403  ...   0.0011  0.0160  0.0506\n",
      "           ...                          ...          \n",
      " -0.0001  0.0017  0.0000  ...  -0.0120  0.0000  0.0344\n",
      " -0.0045 -0.0056 -0.0000  ...   0.0103  0.0000  0.0000\n",
      " -0.0030  0.0241  0.0558  ...  -0.0225 -0.0232 -0.0099\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0005 -0.0000 -0.0313  ...   0.0000 -0.0062  0.0261\n",
      " -0.0000 -0.0000  0.0252  ...  -0.0011 -0.0000 -0.0087\n",
      " -0.1085 -0.0072  0.0094  ...   0.0096  0.0095  0.0034\n",
      "           ...                          ...          \n",
      " -0.1136  0.0009  0.0000  ...  -0.0128 -0.0000 -0.0235\n",
      " -0.0015  0.0008 -0.0000  ...   0.0192  0.0000 -0.0000\n",
      " -0.0013  0.0188 -0.0165  ...   0.0084  0.0337  0.0268\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0001 -0.0000  0.0031  ...  -0.0000 -0.0155 -0.0171\n",
      " -0.0000 -0.0000  0.0259  ...  -0.0058 -0.0000 -0.0089\n",
      " -0.0064 -0.0085 -0.0068  ...   0.0185 -0.0239  0.0120\n",
      "           ...                          ...          \n",
      " -0.0733  0.0024 -0.0000  ...   0.0136  0.0000  0.0449\n",
      " -0.0099  0.0078 -0.0000  ...   0.0097  0.0000 -0.0000\n",
      " -0.0396  0.0081  0.0274  ...   0.0104  0.0007  0.0020\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.2804 -0.0000 -0.0356  ...   0.0000 -0.0113 -0.0086\n",
      " -0.0000  0.0000  0.0556  ...  -0.0070 -0.0000  0.0186\n",
      " -1.3070 -0.0021  0.0014  ...  -0.0042  0.0224  0.0578\n",
      "           ...                          ...          \n",
      " -0.0467 -0.0017 -0.0000  ...   0.0085  0.0000  0.0215\n",
      " -0.0107  0.0017 -0.0000  ...   0.0099  0.0000 -0.0000\n",
      " -1.1341  0.0150 -0.0021  ...  -0.0327 -0.0150  0.0518\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -2.5928e-02  1.8797e-02  2.5004e-01  ...   3.7102e-02 -1.1081e-02  1.8945e-04\n",
      "  5.9728e-03  2.7600e-02 -2.9268e-01  ...  -5.9673e-02 -2.2697e-02  1.7806e-02\n",
      " -9.5210e-03  4.8012e-03 -4.0900e-02  ...   3.1515e-01 -1.3143e-02  1.2039e-03\n",
      "                 ...                                      ...                \n",
      "  2.4381e-01  1.0247e-01 -6.1249e-02  ...  -9.7509e-02 -1.3454e-02  1.4671e-01\n",
      " -2.3620e-02 -2.8376e-03 -3.7323e-01  ...   6.0552e-02 -1.3818e-01  5.8492e-02\n",
      "  6.8744e-02 -1.1278e-02 -2.2645e-01  ...   2.9029e-03 -2.5724e-04  1.0230e-04\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.5982e-01 -3.8738e-02 -1.0968e-01  ...   1.3458e-01 -9.2079e-04  2.2792e-03\n",
      "  6.8236e-03 -4.0033e-03 -9.5826e-02  ...  -6.8876e-02  3.8151e-04  5.5744e-04\n",
      " -1.4973e-02  2.8390e-03  7.4247e-02  ...   2.8472e-02 -9.2102e-03  6.0894e-04\n",
      "                 ...                                      ...                \n",
      "  8.2757e-02  9.0200e-02 -3.9774e-02  ...  -3.4447e-01 -2.5845e-03  1.6412e-02\n",
      "  4.9037e-02  4.2921e-03 -1.2087e-01  ...   1.2397e-02 -1.3473e-01  3.6236e-02\n",
      "  1.1013e-01 -1.4470e-03 -9.6820e-03  ...   4.0378e-03 -1.6853e-02  1.1764e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  4.8077e-02  1.0971e-02 -1.0444e-01  ...   1.4646e-02 -5.7335e-02 -1.0555e-02\n",
      " -1.4605e-01 -5.1997e-03 -8.9281e-04  ...   2.1308e-03 -3.5546e-04  1.6500e-02\n",
      " -1.2234e-02  1.3313e-03 -1.5242e-03  ...   9.6301e-03 -1.6545e-01  3.0903e-02\n",
      "                 ...                                      ...                \n",
      "  7.7501e-02  1.2519e-02  1.5564e-02  ...  -2.3931e-01  5.5001e-02 -2.6051e-02\n",
      " -1.9323e-02  4.8970e-03  3.7339e-01  ...   6.8788e-03 -6.7227e-04  1.8039e-03\n",
      "  4.1512e-02  3.1811e-04  2.1996e-02  ...  -9.5715e-03 -3.6762e-02  4.3093e-02\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -1.3275e-01 -1.5322e-03 -1.5867e-01  ...   1.3002e-01 -1.0740e-01  5.1194e-03\n",
      "  6.1739e-02  1.2006e-01 -6.1496e-02  ...  -5.3638e-01 -2.1214e-03  3.6737e-03\n",
      "  5.7592e-03  3.1510e-02 -1.9934e-01  ...   5.4161e-02 -5.7475e-02  7.2401e-02\n",
      "                 ...                                      ...                \n",
      "  2.5733e-01  9.1686e-07 -2.6834e-02  ...  -2.4031e-01 -4.5069e-02  1.9500e-01\n",
      " -5.2834e-02  7.7722e-05 -8.4594e-02  ...  -3.4006e-03 -5.1074e-02  6.9721e-02\n",
      " -4.0472e-02  3.6204e-03 -1.1342e-01  ...   6.3465e-02  4.3222e-04  2.2637e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      " -8.8814e-02 -5.5161e-03 -6.0707e-01  ...   9.7228e-04 -3.5829e-04  7.8356e-03\n",
      " -3.6111e-01  3.4982e-02 -8.9131e-02  ...  -1.0837e-01  4.0778e-03  4.5976e-02\n",
      " -6.1863e-03  5.2874e-02 -1.1002e-01  ...   7.1547e-02 -1.5456e-04  7.3471e-02\n",
      "                 ...                                      ...                \n",
      "  5.1654e-02  6.3188e-04  9.8902e-02  ...  -1.8030e-01 -9.4467e-02  7.9643e-02\n",
      " -1.0995e-04  9.1596e-03 -1.2781e-01  ...  -2.5773e-02 -1.2352e-01  1.8822e-02\n",
      "  1.0312e-01  3.5995e-03 -1.8147e-02  ...   2.2202e-01 -1.2895e-02  2.1127e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.5935e-01 -3.0415e-03 -2.9293e-01  ...   3.2409e-04 -3.7230e-03  4.0146e-03\n",
      " -1.0623e-01  6.3204e-04 -3.7167e-01  ...   2.2165e-02 -2.6088e-01  2.2069e-01\n",
      " -2.6155e-01 -2.0586e-03 -2.1172e-02  ...  -3.1055e-02 -3.4133e-03  6.2587e-04\n",
      "                 ...                                      ...                \n",
      "  1.5398e-02 -1.8815e-03 -1.4665e-01  ...   9.0605e-02 -1.9459e-01  1.8803e-02\n",
      "  5.8612e-02  1.8932e-02 -3.3944e-01  ...   4.2658e-02 -2.9257e-03  1.9918e-03\n",
      " -1.8114e-01 -7.8722e-03 -1.0612e-01  ...   4.3218e-03 -5.6835e-04  1.0507e-04\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0267  ...  -0.0000 -0.0000 -0.0681\n",
      "  0.0002  0.0000 -0.0000  ...  -0.0010 -0.0240 -0.0606\n",
      "  0.0002  0.0047  0.6541  ...  -0.6710 -0.0578 -0.0132\n",
      "           ...                          ...          \n",
      "  0.0269  0.0000  0.0000  ...  -0.0000  0.0136 -0.0000\n",
      "  0.0053  0.0628  0.0000  ...  -0.0001 -0.0568 -0.0000\n",
      "  0.0000  0.0102  0.0300  ...  -0.0000 -0.0487 -0.0740\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0000  1.0740  ...  -0.0000 -0.0000 -0.0909\n",
      "  0.0000  0.0288  0.0000  ...  -1.3177 -0.0160 -0.0770\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0030 -0.0522  0.0479\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  1.0312  ...  -0.0000 -0.0111 -0.0000\n",
      "  0.0014  0.0027  0.5554  ...  -1.0992 -0.0263 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0486 -0.0134\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0000  0.0618  ...  -0.0000 -0.0000 -0.0485\n",
      "  0.0000  0.0000  0.0000  ...  -0.0160 -0.0135 -0.0306\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0598  0.0734\n",
      "           ...                          ...          \n",
      "  0.0004  0.0000  0.0005  ...  -0.0000 -0.0175 -0.0000\n",
      "  0.0054  0.0014  0.0567  ...  -0.0228  0.0102 -0.0000\n",
      "  0.0267  0.0862 -0.0000  ...  -0.0000 -0.0914  0.0394\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0000  0.0393  ...  -0.0000 -0.0000 -0.0591\n",
      "  0.0001  0.0016  0.0000  ...  -0.0874  0.0303 -0.0620\n",
      "  0.0000  0.0059  1.0686  ...  -0.2394  0.0309 -0.1255\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0157 -0.0000\n",
      "  0.0007  0.0022  0.0004  ...  -0.0000 -0.0123  0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000  0.0305 -0.0505\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0000  0.2346  ...  -0.0000  0.0000 -0.0600\n",
      "  0.0000  0.0017  0.0000  ...  -0.0050 -0.0351  0.0375\n",
      "  0.0000  0.0000  0.0002  ...  -1.3331  0.0193 -0.0524\n",
      "           ...                          ...          \n",
      "  0.0019  0.0000 -0.0430  ...  -0.0000 -0.0334 -0.0000\n",
      "  0.0013  0.0003  0.0012  ...  -1.2403 -0.0299 -0.0000\n",
      "  0.0000  0.0009  1.0895  ...  -0.0000 -0.0154 -0.0519\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0000  0.2205  ...  -0.0000  0.0000 -0.0158\n",
      "  0.0001  0.0121  0.0000  ...  -0.1642 -0.0407  0.1545\n",
      "  0.0000  0.0000  1.0656  ...  -0.0232 -0.0337 -0.1114\n",
      "           ...                          ...          \n",
      " -0.0279  0.0000 -0.0000  ...  -0.0000 -0.0319 -0.0000\n",
      "  0.0095  0.0067  0.0551  ...  -0.0001 -0.0463 -0.0000\n",
      "  0.0006  0.3275  0.0002  ...  -0.0000 -0.0246 -0.0695\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0001 -0.0060 -0.0036  ...   0.0092  0.0087  0.0445\n",
      " -0.0034  0.0029  0.0387  ...  -0.0000 -0.0232  0.0000\n",
      " -0.0047  0.0000 -0.0389  ...  -0.0015  0.0182  0.0542\n",
      "           ...                          ...          \n",
      " -0.8565 -0.0037 -0.0000  ...   0.0027  0.0000  0.0145\n",
      " -1.3298  0.0000 -0.0896  ...  -0.0134  0.0458  0.0456\n",
      " -0.0047  0.0063  0.0245  ...   0.0030  0.0000  0.0319\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0037 -0.0115  0.0083  ...   0.0125 -0.0294  0.0855\n",
      " -0.0038  0.0027  0.0085  ...  -0.0000  0.0098  0.0000\n",
      " -0.0000  0.0000  0.0092  ...  -0.0249  0.0079  0.0288\n",
      "           ...                          ...          \n",
      " -0.0023  0.0089  0.0000  ...   0.0165  0.0000  0.0095\n",
      " -0.0020  0.0000 -0.0032  ...  -0.0059 -0.0018  0.0309\n",
      " -0.0004  0.0087  0.0057  ...   0.0241  0.0000  0.0230\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0032 -0.0046 -0.0062  ...  -0.0074 -0.0150  0.0704\n",
      " -0.0045  0.0020 -0.0013  ...  -0.0000  0.0187  0.0000\n",
      " -0.0006  0.0000  0.0227  ...   0.0093  0.0205  0.0339\n",
      "           ...                          ...          \n",
      " -0.0001  0.0182  0.0000  ...   0.0182 -0.0000  0.0238\n",
      " -0.0086  0.0000  0.0023  ...   0.0038  0.0072  0.0320\n",
      " -1.3029  0.0107  0.2497  ...  -0.0084 -0.0000  0.0557\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0003  0.0031 -0.0225  ...   0.0446  0.0638 -0.0105\n",
      " -0.0002 -0.0018 -0.0084  ...  -0.0000  0.0078  0.0000\n",
      " -0.0033 -0.0000 -0.0542  ...   0.0161 -0.0251  0.0114\n",
      "           ...                          ...          \n",
      " -0.0620  0.0068  0.0000  ...   0.0090 -0.0000  0.0095\n",
      " -0.0670  0.0000 -0.0721  ...   0.0085 -0.0213  0.0304\n",
      " -0.0011  0.0101 -0.0065  ...  -0.0003  0.0000  0.0152\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0005 -0.0012 -0.0349  ...   0.0277  0.0183  0.0350\n",
      " -0.0351  0.0061  0.0175  ...  -0.0000 -0.0146  0.0000\n",
      " -0.0000 -0.0000  0.0018  ...   0.0032 -0.0159  0.0040\n",
      "           ...                          ...          \n",
      " -0.0095 -0.0015 -0.0000  ...   0.0001 -0.0000 -0.0342\n",
      " -0.0003 -0.0000 -0.0270  ...   0.0106 -0.0568 -0.0008\n",
      " -0.0016  0.0278  0.0196  ...  -0.0132  0.0000  0.0540\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0248  0.0040 -0.0417  ...   0.0116 -0.0111  0.0603\n",
      " -0.0010  0.0025  0.0540  ...  -0.0000 -0.0295  0.0000\n",
      " -0.0002  0.0000  0.0032  ...  -0.0037 -0.0532  0.0300\n",
      "           ...                          ...          \n",
      " -0.9085 -0.0277 -0.0000  ...   0.0017 -0.0000  0.0031\n",
      " -1.4073  0.0000 -0.5077  ...   0.0253 -0.0828  0.0096\n",
      " -1.2384  0.0116 -0.1526  ...   0.0066  0.0000  0.0603\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.0178e-01  2.2716e-02 -5.1899e-01  ...   4.4482e-03 -3.5647e-04  1.0753e-02\n",
      " -5.2877e-02  2.4967e-02 -1.1922e-01  ...   2.4105e-02 -5.0808e-03  2.0300e-03\n",
      " -8.7306e-02  1.3625e-02  3.7753e-02  ...  -3.6912e-02 -1.9624e-01  6.9333e-03\n",
      "                 ...                                      ...                \n",
      " -4.8360e-02 -1.9000e-02 -1.7482e-01  ...   3.2051e-03 -1.2535e-03  5.1207e-04\n",
      "  9.9009e-02 -7.0576e-02 -5.7657e-03  ...   1.0592e-01 -2.6954e-04  1.0859e-03\n",
      " -6.0973e-02 -9.5644e-03 -2.7915e-01  ...   3.3538e-02 -6.1252e-02 -2.4492e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.7759e-04 -1.0208e-02 -5.8120e-01  ...   8.6827e-02 -5.8699e-01  7.4990e-03\n",
      " -4.2999e-03  5.0489e-02  2.0131e-01  ...   2.1210e-02  2.5652e-02  2.0019e-01\n",
      " -1.3569e-02  1.8598e-02  2.6466e-01  ...  -7.3388e-02 -5.5636e-02  2.7982e-01\n",
      "                 ...                                      ...                \n",
      " -2.4234e-03  1.4621e-02 -4.0048e-02  ...  -2.2983e-02 -9.4962e-02  2.6448e-02\n",
      "  6.8526e-02 -1.0185e-02  7.2492e-02  ...  -2.9005e-02 -2.9369e-02  9.5812e-02\n",
      " -2.4911e-02 -3.6560e-02 -1.1181e-01  ...   1.1342e-01 -1.0373e-02 -2.5952e-04\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  1.0735e-03 -1.4722e-02 -2.6916e-01  ...  -2.9916e-02 -1.6823e-01  9.6061e-03\n",
      " -9.8611e-02  9.9585e-02  2.0667e-01  ...  -1.8135e-02  1.8541e-02  1.3308e-02\n",
      " -1.4071e-02  2.4900e-02  8.9194e-02  ...   2.6760e-03 -5.2359e-03  1.7980e-01\n",
      "                 ...                                      ...                \n",
      " -1.1267e-03  1.6400e-01 -1.2720e-01  ...   2.8105e-03 -3.2778e-03  2.9396e-03\n",
      "  1.2253e-03 -2.2355e-02  2.6291e-01  ...  -7.7655e-02 -1.1803e-02  9.9424e-04\n",
      " -5.1868e-01 -1.1607e-01 -1.0088e-02  ...   2.0878e-02 -5.6850e-03 -6.2485e-06\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -8.4599e-03  2.6244e-02  1.4428e-01  ...   4.7087e-02 -1.0811e-01  3.4249e-03\n",
      " -5.2135e-02 -9.3739e-02 -7.7608e-02  ...   4.8981e-02 -7.6407e-02  1.6652e-01\n",
      "  9.4915e-02  4.2384e-04 -2.2094e-01  ...   2.2935e-01 -1.9215e-01  7.9978e-02\n",
      "                 ...                                      ...                \n",
      "  1.6941e-01  1.7027e-01 -3.5848e-02  ...  -6.1156e-01  3.1343e-02  7.4916e-03\n",
      " -6.2069e-03 -3.7335e-04 -4.1868e-02  ...   3.7934e-02 -2.1588e-03  1.2366e-02\n",
      "  4.2796e-02  2.1983e-01 -1.8563e-02  ...   2.7557e-02 -2.6909e-02  2.6713e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      " -7.8758e-03 -5.5316e-03 -2.9627e-01  ...   6.5392e-02 -2.9860e-01  1.9297e-02\n",
      " -2.5010e-02 -1.9433e-02 -2.1214e-01  ...   3.4548e-02 -1.4072e-02  4.4624e-02\n",
      "  2.3952e-02  1.0782e-01 -3.4746e-02  ...  -2.4295e-01 -5.0497e-02  5.0543e-03\n",
      "                 ...                                      ...                \n",
      "  2.8772e-01  3.1324e-03 -5.2249e-01  ...  -4.6535e-01 -5.3979e-03  5.9888e-04\n",
      " -9.4352e-02  3.6193e-01 -1.2173e-01  ...  -6.4535e-03  2.6021e-04  3.2616e-02\n",
      "  8.8091e-02 -3.5383e-05 -6.1626e-01  ...   9.6616e-02 -3.8833e-02  4.5032e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.3728e-03 -1.2653e-02 -2.9603e-01  ...   4.8410e-02 -2.6260e-01  1.1196e-02\n",
      "  6.4973e-04 -6.3935e-04 -1.5500e-01  ...   5.6310e-03 -1.8004e-01  5.1820e-02\n",
      "  8.2729e-02  2.1633e-04  1.2801e-01  ...  -4.9491e-01 -7.2340e-02  2.1808e-02\n",
      "                 ...                                      ...                \n",
      "  6.6101e-01 -2.3855e-02 -1.5357e-01  ...  -2.2935e-01 -1.4001e-03  1.1890e-03\n",
      "  4.1758e-02 -6.5117e-02 -1.5272e-02  ...   1.8482e-02 -1.6363e-05  3.9507e-04\n",
      "  1.9595e-01 -1.6986e-01 -6.0592e-02  ...   3.7673e-01 -1.7492e-03  1.2137e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.1296  0.0048 -0.0000\n",
      "  0.0000 -0.0000  0.0003  ...  -1.3788 -0.0125  0.0091\n",
      "  0.0000  0.0000  0.0000  ...  -1.3739 -0.0000 -0.0399\n",
      "           ...                          ...          \n",
      "  0.0006  0.0042  0.2743  ...  -0.0001 -0.0163 -0.0455\n",
      "  0.0001  0.0010  0.2687  ...  -1.1660 -0.0431 -0.1193\n",
      "  0.0010  0.0000  0.0022  ...  -0.0077  0.0473 -0.1007\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0043  0.0000  0.1710  ...  -0.2549 -0.0220  0.0000\n",
      "  0.0018  0.0000 -0.0185  ...  -0.0118 -0.0731  0.0163\n",
      "  0.0000  0.0002 -0.0000  ...  -0.0016 -0.0000 -0.0696\n",
      "           ...                          ...          \n",
      "  0.0974  0.0000  0.0062  ...  -0.0001 -0.0504 -0.0049\n",
      "  0.0042  0.0000  0.9071  ...  -0.3200 -0.0155 -0.1148\n",
      "  0.0038 -0.0000  0.0254  ...  -1.3830  0.0359 -0.0310\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0092 -0.0000  0.0014  ...  -0.5913 -0.0345  0.0000\n",
      "  0.0003  0.0088 -0.0002  ...  -0.0001 -0.0751  0.0362\n",
      "  0.0000  0.0000 -0.0009  ...  -0.0000  0.0000 -0.0742\n",
      "           ...                          ...          \n",
      "  0.0005  0.0256  0.5044  ...  -0.0001 -0.0483 -0.0577\n",
      "  0.0005 -0.0000  0.0001  ...  -1.2145 -0.0026 -0.0450\n",
      "  0.0010  0.0000  0.0000  ...  -0.0005  0.0145 -0.0448\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000 -0.0000  0.0000  ...  -1.1642 -0.0005 -0.0000\n",
      "  0.0000  0.0000  1.0850  ...  -1.3774 -0.0584  0.0256\n",
      "  0.0000  0.0000  1.1069  ...  -0.7719 -0.0000 -0.1161\n",
      "           ...                          ...          \n",
      "  0.0003  0.0000  1.0361  ...  -0.3596 -0.0391  0.0223\n",
      "  0.9576  0.0000  0.0000  ...  -0.2657 -0.0214 -0.0212\n",
      "  0.0016 -0.0000  0.0080  ...  -0.1564 -0.0587  0.0506\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0002  0.0000  0.1478  ...  -0.0155 -0.0788 -0.0000\n",
      "  0.0049  0.0000  0.0216  ...  -0.2199 -0.0581  0.0275\n",
      "  0.0000 -0.0000  0.0000  ...  -1.3940 -0.0000 -0.0403\n",
      "           ...                          ...          \n",
      "  0.0000  0.0001  0.0154  ...  -0.0026 -0.0419 -0.0070\n",
      "  0.0003  0.0001  0.0305  ...  -0.2914 -0.0977 -0.0722\n",
      "  0.0002 -0.0000  0.1474  ...  -0.0008 -0.0207  0.0084\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0001  0.0000  0.0003  ...  -1.2619  0.0044 -0.0000\n",
      "  0.0001  0.0003  1.0658  ...  -0.7620 -0.1126  0.0558\n",
      "  0.0000 -0.0000  0.0080  ...  -0.0027 -0.0000 -0.0673\n",
      "           ...                          ...          \n",
      "  0.0083  0.0000 -0.0000  ...  -0.0000 -0.0613 -0.0128\n",
      "  0.0183  0.2143  0.0000  ...  -0.0040 -0.0258 -0.0155\n",
      "  0.0012 -0.0000  0.3566  ...  -1.4009 -0.0147 -0.0057\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0033  0.0045  0.0190  ...  -0.0096  0.0626  0.0215\n",
      " -0.0000  0.0000  0.0000  ...  -0.0067 -0.0092  0.0000\n",
      " -0.0000  0.0031  0.0000  ...  -0.0099 -0.0386  0.0000\n",
      "           ...                          ...          \n",
      " -0.0008  0.0000 -0.0437  ...   0.0065 -0.0017 -0.0275\n",
      " -0.0000 -0.0000 -0.2126  ...   0.0085  0.0000  0.0000\n",
      " -0.0000  0.0042 -0.0958  ...   0.0105  0.0550  0.0357\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0188  0.0090 -0.0579  ...  -0.0105  0.0456  0.0031\n",
      " -0.0000  0.0000  0.0000  ...  -0.0045 -0.0406  0.0000\n",
      " -1.2071  0.0067 -0.0000  ...   0.0095 -0.0242  0.0000\n",
      "           ...                          ...          \n",
      " -0.0001 -0.0000 -0.0954  ...  -0.0055 -0.0002 -0.0005\n",
      " -0.0000  0.0000 -0.0146  ...  -0.0058  0.0000  0.0000\n",
      " -0.0000 -0.0036 -0.0008  ...  -0.0017  0.0036  0.0094\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0003  0.0057 -0.0620  ...  -0.0005  0.0092 -0.0020\n",
      " -0.0000  0.0000  0.0000  ...   0.0287  0.0197  0.0000\n",
      " -0.0000  0.0068 -0.0000  ...  -0.0075 -0.0043  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000 -0.0236  ...   0.0004  0.0013 -0.0165\n",
      " -0.0000  0.0000  0.0279  ...  -0.0048  0.0000 -0.0000\n",
      " -0.0000  0.0025 -0.0018  ...  -0.0015 -0.0057  0.0123\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0014 -0.0097  ...  -0.0015  0.0155  0.0142\n",
      " -0.0000  0.0000 -0.0000  ...   0.0048  0.0133  0.0000\n",
      " -0.0004  0.0030 -0.0000  ...   0.0406  0.0815 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000 -0.0189  ...   0.0102 -0.0029 -0.0055\n",
      " -0.0000 -0.0000  0.0045  ...   0.0059 -0.0000  0.0000\n",
      " -0.0000  0.0020 -0.1103  ...   0.0124  0.0678  0.0029\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0026 -0.0031 -0.0760  ...   0.0273  0.0007  0.0347\n",
      " -0.0000  0.0000 -0.0000  ...   0.0185  0.0224  0.0000\n",
      " -0.0000  0.0015 -0.0000  ...   0.0330  0.0413 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0003  0.0000 -0.0237  ...   0.0071  0.0036 -0.0048\n",
      " -0.0000 -0.0000  0.0079  ...   0.0058 -0.0000  0.0000\n",
      " -0.0000 -0.0040 -0.0419  ...   0.0186  0.0551 -0.0185\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000 -0.0042 -0.0179  ...   0.0048 -0.0191  0.0130\n",
      " -0.0000 -0.0000  0.0000  ...   0.0087  0.0029  0.0000\n",
      " -0.9445  0.0138 -0.0000  ...   0.0299  0.0691 -0.0000\n",
      "           ...                          ...          \n",
      " -0.9258  0.0000 -0.0270  ...   0.0091  0.0059 -0.0054\n",
      " -0.0000 -0.0000 -0.0107  ...   0.0052 -0.0000  0.0000\n",
      " -0.0000  0.0016 -0.0092  ...   0.0030  0.0255 -0.0054\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.8793e-02  5.3317e-02 -1.5837e-01  ...  -1.9407e-02 -7.1206e-02  3.4269e-02\n",
      "  6.2179e-04  2.4636e-01 -6.2287e-02  ...  -2.8451e-02 -4.4073e-02  1.1244e-01\n",
      "  2.9225e-02  2.2584e-01 -2.6467e-02  ...  -2.2321e-01 -4.1540e-02  1.5586e-02\n",
      "                 ...                                      ...                \n",
      "  4.0106e-01 -3.5948e-02  1.3906e-04  ...  -7.4372e-02 -1.1668e-01  1.7352e-02\n",
      "  2.9425e-02 -2.3634e-03 -5.0547e-02  ...   9.5828e-02 -4.8746e-02  4.5637e-02\n",
      " -2.2550e-01 -8.0263e-03 -1.8341e-02  ...   1.6648e-01 -2.1966e-02  2.5970e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  4.6790e-02  4.2731e-02 -2.5744e-01  ...  -2.5697e-02 -8.0831e-02  6.6432e-02\n",
      " -2.2267e-02  2.2569e-03 -2.8048e-01  ...   1.1470e-01 -1.6362e-04  2.7318e-02\n",
      " -2.1802e-01 -6.0659e-04 -2.2049e-01  ...  -1.0124e-03 -6.6249e-03  1.6902e-03\n",
      "                 ...                                      ...                \n",
      " -4.4748e-02 -1.4251e-03  1.7630e-01  ...  -3.9443e-02 -1.5384e-03  1.2970e-02\n",
      "  2.2805e-02  1.9216e-03 -1.0255e-01  ...  -1.6899e-02 -9.0464e-02  1.4287e-01\n",
      " -1.2057e-01  4.3739e-02 -6.8669e-03  ...   1.0833e-01 -4.2691e-03  1.1667e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  3.0118e-02  1.2437e-01 -1.8670e-01  ...   5.9514e-03 -1.5328e-02  3.4186e-02\n",
      "  2.4515e-01 -2.3523e-02 -1.8272e-02  ...   2.7734e-01 -1.1851e-03  5.7730e-03\n",
      " -1.2966e-01 -2.1845e-02 -1.6623e-01  ...   3.1433e-02  1.8557e-02  3.5156e-02\n",
      "                 ...                                      ...                \n",
      " -1.8538e-01  2.9523e-03 -1.3294e-01  ...   2.8312e-02  4.3024e-02  7.4362e-03\n",
      "  7.8296e-03 -2.7155e-02 -5.8921e-02  ...   3.8837e-02 -5.6018e-04  4.4528e-04\n",
      " -3.3395e-02 -6.3064e-02 -8.9806e-02  ...   3.1437e-01 -3.2864e-02  3.4043e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  9.8965e-03  2.2978e-01 -4.9513e-02  ...  -2.7463e-01 -1.0737e-01  5.4322e-03\n",
      "  1.0933e-01 -3.7980e-04 -9.0583e-03  ...   1.7843e-02 -3.3839e-02  7.0683e-03\n",
      "  3.8365e-01 -2.4349e-05 -5.1102e-02  ...  -2.1182e-02  7.8843e-03  4.5804e-03\n",
      "                 ...                                      ...                \n",
      "  7.5189e-03  3.5652e-02 -7.3138e-02  ...   1.1001e-01 -9.2156e-02  1.6280e-02\n",
      " -1.2386e-02  4.6403e-02 -2.8936e-01  ...   1.9942e-02 -2.3272e-02  8.0651e-03\n",
      "  6.6717e-02  3.2730e-03 -7.5940e-03  ...   1.0030e-02 -5.2312e-02  3.5793e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      "  6.5999e-02  4.8675e-03 -1.3935e-01  ...  -5.0358e-01 -1.1460e-01  3.7372e-02\n",
      "  1.1610e-02  5.6449e-02 -1.4307e-01  ...   7.6549e-02 -1.1529e-03  8.6225e-03\n",
      " -3.5582e-01  2.8152e-03 -2.9312e-01  ...   4.6812e-02  7.0692e-03  2.1913e-02\n",
      "                 ...                                      ...                \n",
      " -3.1449e-02  1.2432e-01 -9.0923e-02  ...   1.9024e-01 -1.9792e-03  1.3717e-03\n",
      " -3.6288e-03  1.4046e-01 -5.0462e-01  ...   3.3509e-02 -1.3581e-01  1.4942e-02\n",
      "  1.3604e-02  1.7176e-03 -3.1737e-02  ...   7.9577e-03 -4.2770e-02  8.3498e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      "  2.6969e-02  4.3506e-02 -1.8844e-02  ...  -2.2067e-01 -1.2530e-01  3.3323e-02\n",
      "  2.3796e-02  6.1676e-03 -1.8157e-02  ...   3.8580e-02  2.1103e-01  9.7582e-02\n",
      "  2.9095e-01 -8.1577e-02 -3.8786e-03  ...   2.4726e-01 -7.2069e-05  1.1171e-04\n",
      "                 ...                                      ...                \n",
      " -2.5087e-01 -4.4204e-02 -4.4242e-02  ...   4.3244e-02 -7.9180e-03  7.8898e-03\n",
      " -1.3355e-02  7.7878e-02 -5.0875e-01  ...   3.7351e-03 -1.0758e-02  2.2533e-02\n",
      "  8.0474e-04  1.5590e-02 -1.5383e-02  ...   2.6145e-02 -1.3798e-01 -2.8396e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0002  0.0007  0.0000  ...  -0.0000  0.0020 -0.0450\n",
      "  0.0252  0.0000  0.0094  ...  -0.0000 -0.0299  0.0099\n",
      "  0.1188  0.0005  0.0001  ...  -0.0000 -0.0000 -0.1025\n",
      "           ...                          ...          \n",
      "  0.0003  0.0005  0.0613  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0001  0.0538  0.0000  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -1.4143  0.0238 -0.0292\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0361  0.5992 -0.0000  ...  -0.0000  0.0212 -0.0479\n",
      "  0.0000  0.0000  0.0004  ...  -0.0000  0.0143 -0.1614\n",
      "  0.0010  0.0003  0.3056  ...  -0.0259 -0.0000 -0.0122\n",
      "           ...                          ...          \n",
      "  0.0102  0.0011  0.0014  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0021  0.0002 -0.0010  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0017  0.3434  0.0000  ...  -1.1524 -0.0100 -0.0286\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0005  0.1679  0.6182  ...  -0.3218 -0.0072 -0.1421\n",
      "  0.0014  0.0000  0.8799  ...  -0.0000 -0.0196 -0.0189\n",
      "  0.0307  0.0000  0.0021  ...  -1.4035 -0.0000 -0.0388\n",
      "           ...                          ...          \n",
      "  0.1640  0.0006  0.0000  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0001  0.0596  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0001 -0.6751  0.0000  ...  -0.0001 -0.0552 -0.0118\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  1.3189  0.0006  0.0000  ...  -0.0000 -0.0498  0.0375\n",
      "  0.0062  0.0000  0.0000  ...  -0.0000 -0.0958  0.1098\n",
      "  0.0015  0.1447  0.6598  ...  -0.4240 -0.0000 -0.0254\n",
      "           ...                          ...          \n",
      "  0.0003 -0.0000  0.0022  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0011  0.0000  0.0515  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0000  0.0064  0.0000  ...  -0.0012  0.0019 -0.1828\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0072  1.0881  ...  -0.0001 -0.1143  0.0504\n",
      "  0.0073  0.0000  0.0002  ...  -0.0000 -0.0616  0.0395\n",
      "  0.0319  0.0017  0.0522  ...  -0.1923 -0.0000  0.0655\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.1888  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0006  0.8977  0.0000  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0001  0.0001  0.0000  ...  -0.0014 -0.0077 -0.1248\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0015  0.0083  ...  -0.1597 -0.1130  0.1006\n",
      "  0.0146  0.0000  0.0378  ...  -0.0000 -0.0380  0.0415\n",
      "  0.1340  0.0001  0.0000  ...  -0.0002  0.0000  0.0289\n",
      "           ...                          ...          \n",
      "  0.0001  0.0000  0.2843  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0013  0.0994  0.0000  ...  -0.0001 -0.0000 -0.0000\n",
      "  0.0016  0.0000  0.0000  ...  -1.1751  0.0092 -0.0448\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0002 -0.0121 -0.0117  ...  -0.0166 -0.0581 -0.0062\n",
      " -0.0001  0.0048 -0.0036  ...  -0.0000  0.0050  0.0190\n",
      " -0.0000 -0.0000 -0.4081  ...   0.0290  0.0859  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0040 -0.0000  ...   0.0000  0.0321 -0.0000\n",
      " -0.0000 -0.0047 -0.0995  ...   0.0000  0.0256  0.0091\n",
      " -0.0000  0.0012 -0.0033  ...  -0.0000  0.0067  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.1427 -0.0069 -0.0135  ...  -0.0107 -0.0207  0.0331\n",
      " -0.0601  0.0003 -0.0427  ...   0.0000  0.0288  0.0389\n",
      " -0.0000 -0.0000 -0.0970  ...   0.0316  0.0859  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0068 -0.0000  ...   0.0000  0.0393  0.0000\n",
      " -0.0000  0.0022 -0.0261  ...  -0.0000  0.0313  0.0042\n",
      " -0.0000 -0.0029 -0.0127  ...   0.0000 -0.0028  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0262 -0.0003  0.0209  ...   0.0112 -0.0015  0.0336\n",
      " -0.0003  0.0005 -0.0999  ...   0.0000  0.0220  0.0318\n",
      " -0.0000 -0.0000  0.0176  ...   0.0235 -0.0015 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0127  0.0000  ...   0.0000  0.0025  0.0000\n",
      " -0.8056  0.0054  0.1923  ...  -0.0000  0.0294  0.0140\n",
      " -0.0000 -0.0028 -0.0067  ...   0.0000  0.0083  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0015  0.0157  0.0021  ...  -0.0015  0.0348  0.0290\n",
      " -0.5543  0.0041  0.1059  ...  -0.0000 -0.0136  0.0468\n",
      " -0.0000  0.0000  0.0288  ...   0.0018  0.0701  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0066 -0.0000  ...  -0.0000 -0.0016  0.0000\n",
      " -0.0000  0.0043  0.0182  ...  -0.0000 -0.0068  0.0233\n",
      " -0.0000 -0.0027  0.0153  ...   0.0000  0.0399  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000  0.0018 -0.0071  ...  -0.0033 -0.0080  0.0295\n",
      " -1.3781  0.0096  0.0581  ...   0.0000 -0.0007  0.0182\n",
      " -0.0000  0.0000  0.0625  ...   0.0040  0.0399  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0112  0.0000  ...  -0.0000  0.0078  0.0000\n",
      " -1.2564 -0.0150 -0.0451  ...   0.0000  0.0117  0.0222\n",
      " -0.0000  0.0026 -0.0292  ...   0.0000  0.0107  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0439  0.0097  0.0626  ...  -0.0032  0.0080  0.0363\n",
      " -0.0025 -0.0011  0.0089  ...   0.0000  0.0002 -0.0078\n",
      " -0.0000  0.0000  0.0360  ...   0.0076  0.0354  0.0000\n",
      "           ...                          ...          \n",
      " -0.0000  0.0077  0.0000  ...  -0.0000  0.0155  0.0000\n",
      " -0.0087 -0.0049 -0.1741  ...  -0.0000  0.0320  0.0959\n",
      " -0.0000  0.0026  0.0047  ...   0.0000 -0.0215  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -7.9203e-02  8.4920e-03 -1.0611e-01  ...  -3.4446e-01 -6.6023e-03  1.8718e-02\n",
      " -1.5959e-01  2.3285e-01 -8.3706e-02  ...   1.5109e-01  6.7442e-03  2.3833e-03\n",
      "  3.1007e-02  1.0613e-04 -3.0645e-03  ...   1.6252e-03 -1.2804e-03  3.5929e-02\n",
      "                 ...                                      ...                \n",
      " -9.8502e-02 -2.8754e-03 -3.3212e-02  ...  -5.8685e-03 -5.7425e-02  7.6345e-02\n",
      " -2.6452e-02  1.1081e-02  7.2390e-02  ...   6.4073e-04 -1.1730e-02  1.3660e-03\n",
      "  1.4338e-02  4.6846e-02 -6.3414e-03  ...  -1.9506e-02 -1.8924e-01  6.0336e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.4779e-01 -4.1869e-02 -1.3288e-01  ...  -3.4553e-01 -9.1495e-04  1.5281e-04\n",
      "  2.0408e-02 -5.6289e-03  7.4858e-02  ...  -4.1172e-02 -1.7068e-02  1.7385e-01\n",
      " -1.8305e-01  1.0476e-02 -7.5510e-02  ...   7.8837e-02 -1.1547e-02  3.9559e-03\n",
      "                 ...                                      ...                \n",
      " -5.3550e-02  1.0707e-04 -2.8354e-02  ...   2.8664e-02 -8.4406e-03  1.4795e-03\n",
      " -2.6083e-01  1.4656e-01  3.4491e-01  ...  -1.6328e-02  3.0811e-03  8.9962e-04\n",
      " -1.2860e-01  4.8260e-02 -8.9845e-03  ...   1.1776e-01 -1.6955e-01  2.6332e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.1917e-01 -4.6839e-03 -2.4238e-02  ...  -3.8427e-01 -1.6131e-02  5.7272e-02\n",
      "  1.3784e-02 -1.7906e-02 -7.1111e-02  ...   5.7522e-03 -1.7436e-01  3.2361e-02\n",
      " -8.1223e-02 -1.0055e-03 -2.2531e-03  ...   3.4522e-01 -1.5025e-03  3.6472e-02\n",
      "                 ...                                      ...                \n",
      "  1.6162e-01 -2.2298e-02 -1.7083e-02  ...   7.5338e-03 -3.5236e-03  9.8249e-05\n",
      "  9.3409e-02  1.1223e-02 -1.6439e-01  ...  -7.9965e-04 -3.2869e-03  2.1394e-03\n",
      " -1.0678e-01  5.7853e-03 -7.9940e-02  ...  -4.0118e-03 -1.4092e-01  2.2799e-02\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -9.3126e-02 -1.6903e-01  1.1770e-01  ...   1.2602e-01 -1.2351e-03  9.7698e-03\n",
      "  2.3892e-01 -1.0041e-02 -1.7936e-01  ...  -3.6570e-02 -1.4308e-03  3.1692e-03\n",
      "  1.4752e-01 -1.6663e-04 -9.7470e-03  ...  -8.3875e-02 -1.8407e-02  1.3311e-02\n",
      "                 ...                                      ...                \n",
      " -5.7420e-02  1.0081e-01 -5.6374e-02  ...   1.2547e-01 -2.2959e-02  2.3233e-02\n",
      " -3.2791e-01  1.4413e-02  5.3829e-01  ...   5.7559e-02  1.5247e-03  7.8668e-04\n",
      " -2.8478e-02  8.5682e-02  4.8572e-02  ...  -2.7206e-02  1.5264e-01  1.9019e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      "  6.3853e-02 -6.9228e-02  2.3378e-01  ...  -8.6947e-04 -1.3032e-02  2.7934e-02\n",
      "  8.4413e-02 -5.8798e-03 -7.1789e-03  ...  -2.1519e-02 -7.1087e-04  9.5512e-03\n",
      "  1.0466e-01  5.4740e-03 -1.0113e-01  ...   8.5395e-02 -1.1408e-01  1.0346e-01\n",
      "                 ...                                      ...                \n",
      "  3.8113e-02  1.0902e-03 -7.7886e-02  ...   6.5811e-02 -8.4428e-02  2.1537e-01\n",
      "  4.9359e-01 -2.2337e-03 -1.1113e-02  ...   1.7753e-01  4.4834e-05  2.3013e-04\n",
      " -2.3213e-02 -4.9137e-04 -1.4357e-02  ...   7.4201e-02  4.3373e-02  1.0418e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      "  2.8049e-02 -5.6834e-03  3.5331e-02  ...  -1.6551e-02 -1.1132e-02  1.1938e-01\n",
      "  1.5740e-01  5.5585e-02 -1.8915e-02  ...  -6.4381e-02 -3.3269e-02  3.8172e-02\n",
      "  1.2711e-02  1.4512e-01 -1.2982e-01  ...   2.9587e-01 -1.8604e-02  5.6328e-02\n",
      "                 ...                                      ...                \n",
      "  6.5111e-03  3.0796e-03 -5.2014e-02  ...   3.1501e-02 -2.1760e-02  1.5275e-01\n",
      "  6.5937e-01  2.4720e-03  2.4607e-01  ...   2.4177e-01 -1.6947e-03  3.4112e-03\n",
      " -2.2694e-02  1.1672e-01 -5.6995e-03  ...   6.8815e-02 -4.6139e-02  1.0704e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -0.0002 -0.0533  0.0000\n",
      "  0.0000 -0.0000  0.0000  ...  -1.4035 -0.0000  0.0208\n",
      "  0.0003  0.0123  0.0592  ...  -0.1366 -0.0678  0.0000\n",
      "           ...                          ...          \n",
      "  0.0002  0.0000  0.0001  ...  -0.0335  0.0000  0.0320\n",
      "  0.0000  0.0000  0.2741  ...  -0.0007 -0.0949  0.0209\n",
      "  0.0000  0.0000  0.0028  ...  -0.0000 -0.0325 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0003  0.6317  ...  -0.0208 -0.1220  0.0000\n",
      "  0.0001  0.0000  0.0001  ...  -1.4086 -0.0000  0.0217\n",
      "  0.0002  0.0001  0.1946  ...  -0.3620 -0.0321  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.1092  ...  -0.4640 -0.0000  0.0525\n",
      "  0.0000 -0.0000  0.5505  ...  -0.0002 -0.0816  0.0705\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000 -0.0008 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0020  0.0003  ...  -0.0000 -0.0653  0.0000\n",
      "  0.0001  0.0209  0.0000  ...  -0.0024 -0.0000  0.0110\n",
      "  0.0000 -0.0000  0.0491  ...  -1.3022 -0.0120 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0032  0.0000 -0.0009  ...  -0.0698 -0.0000 -0.0257\n",
      "  0.0108 -0.0000  0.0014  ...  -0.0128 -0.0625  0.0429\n",
      "  0.0004  0.0000  0.8358  ...  -0.0000 -0.0282 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0541  0.6613  ...  -0.0001  0.0260 -0.0000\n",
      "  0.0000  0.0000 -0.0000  ...  -1.3695 -0.0000  0.0245\n",
      "  0.0004  0.0044  0.8318  ...  -0.0001 -0.0131 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0000  ...  -1.3038  0.0000 -0.0758\n",
      "  0.0000  0.0000  0.2347  ...  -0.0227 -0.0667  0.0922\n",
      "  0.0001 -0.0000  0.0004  ...  -0.0000  0.0218 -0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0390  0.0000  ...  -1.0084  0.0148 -0.0000\n",
      "  0.0003  0.0000  0.0103  ...  -0.0011 -0.0000  0.0328\n",
      "  0.0000  0.0000  0.0081  ...  -1.2890 -0.0068 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0107  0.0000 -0.0000  ...  -0.0000  0.0000 -0.1556\n",
      "  0.0001  0.0000  0.0011  ...  -1.3289 -0.0313  0.0303\n",
      "  0.0000  0.0000  0.0468  ...  -0.0000  0.0059 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0000  0.7342  ...  -0.0000 -0.0074 -0.0000\n",
      "  0.0000  0.0001  0.0001  ...  -0.0000 -0.0000  0.0078\n",
      "  0.0136  0.0000 -0.0003  ...  -0.0001 -0.0196 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0117  0.0000  0.0001  ...  -0.1272  0.0000 -0.1734\n",
      "  0.0000  0.0000  0.9230  ...  -0.2747 -0.0620  0.1029\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000 -0.0003 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0133  0.0091 -0.0433  ...  -0.0123 -0.0235  0.0224\n",
      " -0.0000 -0.0072 -0.0000  ...  -0.0005 -0.0070 -0.0046\n",
      " -0.0000  0.0029  0.1061  ...  -0.0174  0.0180  0.0000\n",
      "           ...                          ...          \n",
      " -0.0004 -0.0014 -0.0139  ...  -0.0377 -0.0611 -0.0230\n",
      " -0.0000  0.0000 -0.1850  ...   0.0012  0.0000  0.0857\n",
      " -0.0001 -0.0146  0.0284  ...  -0.0008 -0.0345  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0067 -0.0173  ...   0.0060 -0.0445  0.0237\n",
      " -0.0000 -0.0135 -0.0000  ...  -0.0005 -0.0298 -0.0050\n",
      " -0.0000  0.0141  0.0081  ...   0.0001 -0.0360  0.0000\n",
      "           ...                          ...          \n",
      " -0.0017  0.0049 -0.0273  ...  -0.0153 -0.0344 -0.0011\n",
      " -0.0000 -0.0000 -0.0445  ...   0.0191 -0.0000  0.0751\n",
      " -0.0042 -0.0196 -0.0099  ...   0.0004 -0.0059  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0046  0.0155 -0.0221  ...  -0.0174 -0.0252  0.0372\n",
      " -0.0000 -0.0055  0.0000  ...  -0.0035 -0.0307 -0.0184\n",
      " -0.0000  0.0058 -0.0038  ...   0.0038 -0.0151  0.0000\n",
      "           ...                          ...          \n",
      " -0.0053  0.0094  0.0057  ...  -0.0059 -0.0138 -0.0172\n",
      " -0.0000 -0.0000 -0.0352  ...  -0.0117 -0.0000  0.0800\n",
      " -0.0000  0.0092 -0.0404  ...  -0.0036  0.0408  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000 -0.0079 -0.0439  ...   0.0034 -0.0455  0.0540\n",
      " -0.0000 -0.0017  0.0000  ...   0.0012 -0.0154  0.0044\n",
      " -0.0000  0.0051  0.0058  ...  -0.0109  0.0375  0.0000\n",
      "           ...                          ...          \n",
      " -0.0001 -0.0089 -0.0214  ...   0.0059 -0.0376  0.0152\n",
      " -0.0000  0.0000 -0.0475  ...   0.0236  0.0000  0.0434\n",
      " -0.0002 -0.0041 -0.0325  ...  -0.0050 -0.0203  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000 -0.0129 -0.0201  ...   0.0026 -0.0513  0.0247\n",
      " -0.0001 -0.0033 -0.0000  ...   0.0014 -0.0218  0.0067\n",
      " -0.0000 -0.0062  0.0110  ...  -0.0110  0.0111  0.0000\n",
      "           ...                          ...          \n",
      " -0.8227 -0.0057 -0.1721  ...   0.0089 -0.0263  0.0233\n",
      " -0.0000  0.0000  0.0273  ...   0.0422 -0.0000 -0.0446\n",
      " -1.0566  0.0154 -0.0969  ...   0.0215  0.0369  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000 -0.0168 -0.0301  ...  -0.0028 -0.0594  0.0944\n",
      " -0.0042 -0.0000 -0.0000  ...   0.0091  0.0146 -0.0239\n",
      " -0.0000 -0.0202 -0.0958  ...  -0.0130  0.0458  0.0000\n",
      "           ...                          ...          \n",
      " -0.0239  0.0060 -0.1097  ...   0.0060  0.0071 -0.0035\n",
      " -0.0000  0.0000 -0.1212  ...   0.0497  0.0000 -0.0026\n",
      " -0.0001  0.0071 -0.0108  ...   0.0170  0.0117  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  7.7502e-02  2.8761e-03 -2.5543e-02  ...  -6.8843e-03 -8.2554e-04  6.3811e-04\n",
      "  1.6028e-02  1.6087e-01 -2.8222e-02  ...  -3.8326e-02 -2.8240e-02  5.3788e-02\n",
      "  3.5666e-02 -9.8682e-03 -9.9388e-02  ...   1.7076e-01 -5.3719e-02  4.1039e-02\n",
      "                 ...                                      ...                \n",
      " -2.0153e-02  1.9181e-03 -5.5466e-02  ...   1.1530e-01 -1.1482e-02  5.8064e-03\n",
      "  5.1959e-01 -2.1524e-03  2.0750e-04  ...   9.4491e-02  1.5172e-02  4.3557e-02\n",
      " -2.7958e-01  9.8822e-02 -6.3758e-02  ...  -3.7233e-02 -9.8311e-03 -1.0683e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  1.2883e-01  7.1665e-02 -2.6458e-01  ...  -2.6427e-02 -3.9963e-01  6.0380e-03\n",
      "  1.7080e-01 -1.9765e-02 -8.7845e-02  ...  -1.0979e-01 -1.8157e-02  3.1026e-02\n",
      "  3.0606e-02 -4.8234e-04 -2.4721e-02  ...   3.8752e-02 -1.7531e-01  4.1926e-02\n",
      "                 ...                                      ...                \n",
      " -6.0588e-03 -1.9324e-04  1.7386e-01  ...   3.0221e-02 -9.8629e-02  7.1143e-03\n",
      "  3.9687e-01  1.5120e-03  7.6549e-02  ...  -1.7128e-02  2.2056e-02  2.9004e-02\n",
      " -6.8528e-02  5.5801e-04  2.5524e-01  ...  -2.3758e-03 -1.2426e-01 -3.4985e-04\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  5.0380e-02  1.4558e-02 -1.4100e-01  ...   3.4400e-03 -1.5387e-02  8.8729e-03\n",
      " -5.8258e-03 -4.2183e-02 -1.1913e-01  ...   4.3597e-02 -5.3788e-04  2.8815e-02\n",
      "  4.5434e-02  1.0422e-01 -2.0656e-02  ...  -3.6930e-02 -1.8437e-01  1.8276e-02\n",
      "                 ...                                      ...                \n",
      " -1.3018e-02 -2.8674e-03  6.5064e-02  ...   9.1345e-03 -4.1407e-02  1.0830e-01\n",
      "  2.4253e-02  7.1478e-03 -5.6125e-02  ...  -8.8313e-02  3.7455e-03  3.0565e-03\n",
      " -1.0617e-01  2.0787e-02 -4.1774e-01  ...  -2.0128e-01  1.9014e-02  2.3317e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  3.4715e-02  1.5994e-02  1.1057e-01  ...   3.7351e-03  1.1830e-02  1.2242e-03\n",
      "  6.8671e-03  9.8647e-02 -6.4788e-02  ...  -1.6601e-01 -3.3816e-02  3.4195e-02\n",
      " -1.0446e-03  1.0733e-02 -1.2065e-02  ...   9.6888e-03  1.3540e-02  8.2672e-02\n",
      "                 ...                                      ...                \n",
      " -8.3464e-02 -5.5459e-02 -1.1289e-01  ...   3.3079e-01 -8.2255e-03  8.1455e-02\n",
      " -7.6012e-02 -4.7976e-02 -1.4826e-01  ...   2.1489e-01  8.0439e-03  6.5347e-01\n",
      "  4.4535e-02  1.2094e-01 -3.8772e-02  ...  -2.0422e-02  1.1176e-02  8.9370e-04\n",
      "\n",
      "(68 ,.,.) = \n",
      " -1.5130e-02  4.6565e-02 -3.4782e-02  ...  -3.0873e-02  4.5094e-04  9.6507e-03\n",
      " -8.6647e-02 -1.4579e-04  2.5406e-01  ...  -3.6984e-02 -2.3711e-02  2.1050e-02\n",
      " -2.9411e-02  8.3138e-02 -1.2635e-02  ...  -7.5062e-02  3.1331e-02  4.3934e-02\n",
      "                 ...                                      ...                \n",
      " -5.0701e-01 -8.3007e-02 -2.5517e-01  ...   4.4274e-02 -1.0230e-03  1.1059e-03\n",
      " -8.6175e-03 -6.7053e-02 -1.1900e-02  ...   2.5111e-01  1.7411e-05  2.3547e-02\n",
      "  4.4762e-02  1.7158e-03 -9.1204e-02  ...  -6.5243e-02 -1.2796e-02  1.2542e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      " -3.2016e-01  1.2175e-01 -2.0934e-02  ...  -7.6451e-02 -2.3769e-04  1.0426e-04\n",
      " -1.3138e-02 -3.1534e-02  6.9717e-01  ...  -4.4788e-02  1.1708e-03  1.2162e-02\n",
      " -3.5665e-01 -7.1366e-04  3.9422e-03  ...   1.9987e-01 -5.1440e-04  1.0956e-03\n",
      "                 ...                                      ...                \n",
      " -2.4608e-01 -1.4826e-02 -3.0568e-02  ...   9.1250e-02 -1.6108e-01  2.8251e-02\n",
      "  7.6020e-02 -8.0115e-02 -2.4429e-02  ...   7.4891e-02  4.6976e-03  1.0579e-01\n",
      " -6.4518e-03  1.4975e-01 -5.6521e-02  ...  -1.4247e-01 -1.6490e-02  1.1045e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.5626  0.0214  ...  -0.0017  0.0007 -0.0000\n",
      "  0.0000  0.0030  0.0000  ...  -0.0009 -0.0000  0.0324\n",
      "  0.0000  0.0030  0.0000  ...  -0.0664 -0.0497 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0026  0.0013  0.3435  ...  -0.2069  0.0243 -0.0332\n",
      "  0.0000  0.0000  0.0089  ...  -1.3044 -0.0095 -0.0108\n",
      "  0.0000  0.0008 -0.0000  ...  -0.0012 -0.0106 -0.0252\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0003  0.0004  0.0004  ...  -0.0000 -0.0030 -0.0000\n",
      "  0.0012  0.0141  0.0000  ...  -0.0000 -0.0000  0.0680\n",
      "  0.0000  0.0010  0.1194  ...  -0.0004 -0.0129  0.0000\n",
      "           ...                          ...          \n",
      "  0.0001  0.0017  1.0510  ...  -0.3631 -0.0224 -0.0382\n",
      "  0.2324  0.0001 -0.0072  ...  -0.0073 -0.0677  0.0003\n",
      "  0.0000  0.0011  1.0548  ...  -0.0000 -0.0552  0.0107\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0048  0.0176  ...  -0.0324  0.0099 -0.0000\n",
      "  0.0314  0.0059  0.0000  ...  -0.0000  0.0000  0.0844\n",
      "  0.0000  0.0005  0.4142  ...  -0.0003 -0.0176  0.0000\n",
      "           ...                          ...          \n",
      "  0.0026 -0.0218  0.0044  ...  -0.0486 -0.0360 -0.0038\n",
      "  0.0000  0.0004  1.0849  ...  -0.0003 -0.0745 -0.0845\n",
      "  0.0001  0.0337  0.0014  ...  -0.0000 -0.0193  0.0134\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.2879  0.0000  ...  -0.0000 -0.0535 -0.0000\n",
      "  0.0243  0.0000  0.0000  ...  -0.0000 -0.0000  0.0094\n",
      "  0.0000  0.0016  0.3197  ...  -0.0005 -0.0354  0.0000\n",
      "           ...                          ...          \n",
      "  0.0122  0.0001  0.0000  ...  -0.3856 -0.0268 -0.0167\n",
      "  0.0000  0.0911  0.4308  ...  -0.0000  0.0130 -0.0394\n",
      "  0.0000 -0.0000 -0.0000  ...  -1.2788 -0.0138 -0.0101\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0022  0.0014  0.0002  ...  -0.0000 -0.0543  0.0000\n",
      "  0.0031  0.0140  0.0000  ...  -0.0161 -0.0000  0.0720\n",
      "  0.0007  0.0044 -0.0372  ...  -0.0635 -0.0259  0.0000\n",
      "           ...                          ...          \n",
      "  0.0001  0.0145  0.0003  ...  -0.0001 -0.0869  0.0062\n",
      "  0.0035  0.0035 -1.0139  ...  -0.0100 -0.0053 -0.1195\n",
      "  0.0002  0.4402  0.0000  ...  -1.2737 -0.0626 -0.0829\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0083  0.0024  0.0000  ...  -0.0000 -0.0678  0.0000\n",
      "  0.0165  0.0011  0.0000  ...  -0.7857 -0.0000  0.0329\n",
      "  0.0449  0.0035  0.0022  ...  -0.0003 -0.0213  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000 -0.4355  0.0123  ...  -1.0274 -0.1094 -0.0719\n",
      "  0.9808  0.0126 -0.0000  ...  -0.0001 -0.0000 -0.1264\n",
      "  0.0361  0.0011 -0.0000  ...  -0.0002 -0.0115 -0.0886\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0000 -0.0012 -0.0456  ...   0.0000  0.0048  0.0000\n",
      " -0.0001 -0.0000 -0.0651  ...   0.0356  0.0212  0.0496\n",
      " -1.3957  0.0000  0.0193  ...  -0.0063  0.0486  0.0000\n",
      "           ...                          ...          \n",
      " -0.0012 -0.0072 -0.0484  ...   0.0049  0.0042  0.0000\n",
      " -0.0000 -0.0078 -0.0000  ...   0.0000 -0.0000  0.0000\n",
      " -0.0000 -0.0035  0.0013  ...   0.0000 -0.0000  0.0070\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000  0.0015 -0.0245  ...   0.0000  0.0081  0.0000\n",
      " -0.0625  0.0000  0.1355  ...  -0.0077  0.0360  0.0098\n",
      " -0.0438  0.0000  0.0460  ...   0.0002  0.0979  0.0000\n",
      "           ...                          ...          \n",
      " -0.0010 -0.0118 -0.0072  ...   0.0104  0.0072  0.0000\n",
      " -0.0000 -0.0231 -0.0000  ...   0.0000 -0.0000  0.0000\n",
      " -0.0000 -0.0056 -0.0459  ...   0.0000 -0.0000  0.0763\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000  0.0111  0.0269  ...   0.0000 -0.0146 -0.0000\n",
      " -0.0067  0.0000  0.1151  ...  -0.0131  0.0290  0.0313\n",
      " -0.0015 -0.0000 -0.0113  ...   0.0014  0.0525  0.0000\n",
      "           ...                          ...          \n",
      " -0.0001 -0.0051  0.0762  ...  -0.0248 -0.0179 -0.0000\n",
      " -0.0000 -0.0010 -0.0000  ...  -0.0000 -0.0000  0.0000\n",
      " -0.0000 -0.0120 -0.0029  ...  -0.0000 -0.0000  0.0566\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000 -0.0011  0.1394  ...  -0.0000  0.0296  0.0000\n",
      " -0.0002  0.0000  0.0162  ...   0.0106  0.0565  0.0168\n",
      " -0.0002  0.0000 -0.0146  ...  -0.0007  0.0375  0.0000\n",
      "           ...                          ...          \n",
      " -0.0002  0.0020  0.0115  ...  -0.0381 -0.0159 -0.0000\n",
      " -0.0000  0.0204  0.0000  ...   0.0000 -0.0000 -0.0000\n",
      " -0.0000  0.0023  0.0113  ...   0.0000 -0.0000  0.0009\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000 -0.0034  0.0414  ...  -0.0000 -0.0270  0.0000\n",
      " -0.0020  0.0000  0.0196  ...  -0.0016  0.0238  0.0910\n",
      " -0.0018  0.0000 -0.0283  ...  -0.0052  0.0741  0.0000\n",
      "           ...                          ...          \n",
      " -1.3354 -0.0022  0.2804  ...  -0.0470  0.0165 -0.0000\n",
      " -0.0000  0.0220 -0.0000  ...   0.0000 -0.0000 -0.0000\n",
      " -0.0000  0.0018  0.0525  ...   0.0000 -0.0000 -0.0116\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000  0.0030  0.1649  ...  -0.0000  0.0022  0.0000\n",
      " -0.0030 -0.0000  0.0016  ...   0.0033  0.0223  0.0268\n",
      " -0.2051  0.0000 -0.1321  ...   0.0273  0.0981  0.0000\n",
      "           ...                          ...          \n",
      " -0.0025 -0.0018  0.0455  ...  -0.0126  0.0509 -0.0000\n",
      " -0.0000  0.0034 -0.0000  ...   0.0000 -0.0000 -0.0000\n",
      " -0.0000  0.0095  0.0798  ...  -0.0000 -0.0000 -0.0039\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  3.6139e-01  3.0406e-03  4.8547e-01  ...  -2.6618e-02 -1.8468e-02  1.0570e-03\n",
      " -6.2928e-02 -2.2055e-02 -8.9122e-02  ...   4.9878e-02 -1.1878e-02  1.2191e-02\n",
      " -3.0543e-02 -3.5773e-03 -2.1727e-01  ...   2.7401e-02 -9.6448e-04  1.0263e-03\n",
      "                 ...                                      ...                \n",
      " -8.2715e-02 -2.1635e-03  1.9891e-02  ...   4.0836e-02 -3.4469e-01  7.1262e-03\n",
      " -1.8627e-02  4.5708e-02 -3.0053e-02  ...   6.8428e-02  3.1700e-04  1.4936e-02\n",
      " -2.6108e-02  4.4901e-04  2.8646e-01  ...  -1.3558e-02 -1.8264e-02  2.2083e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.9648e-01  1.5241e-01 -1.8868e-01  ...  -4.6813e-02  1.3974e-01  2.0963e-03\n",
      "  1.9627e-02  1.8839e-02 -7.8337e-04  ...  -5.7728e-02 -2.9231e-02  8.1841e-03\n",
      " -1.4750e-02 -9.1529e-05  6.2452e-01  ...  -7.9018e-03 -9.2101e-03  1.2161e-03\n",
      "                 ...                                      ...                \n",
      " -3.1289e-03  1.8047e-03 -1.4271e-01  ...   5.1212e-02 -2.1103e-01  5.3586e-02\n",
      " -4.6858e-02 -2.6423e-03  4.2859e-01  ...  -3.6742e-03  1.6737e-03  4.1004e-02\n",
      " -4.1780e-02  1.8134e-02 -6.5944e-02  ...  -4.4087e-03  1.3938e-01  2.2132e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  6.3552e-02  3.8932e-03 -3.8422e-02  ...  -8.3899e-04  6.2294e-03  7.5640e-03\n",
      " -2.2398e-02  3.1489e-02 -2.7360e-01  ...   2.2524e-02 -2.5911e-03  1.7986e-02\n",
      " -4.1454e-02  1.4296e-02 -1.4801e-03  ...  -5.0972e-03 -1.8348e-02 -1.0444e-03\n",
      "                 ...                                      ...                \n",
      " -1.6000e-02  5.1063e-02 -9.5335e-02  ...   1.1513e-01 -9.9489e-02  1.2879e-02\n",
      " -2.4179e-01  1.5093e-02 -1.9471e-01  ...   4.6204e-02  1.5053e-01  4.6490e-02\n",
      " -3.6969e-02  1.0194e-01 -5.5893e-02  ...   4.1588e-02  6.0286e-02  7.6631e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -1.4416e-02  1.8000e-01  1.5939e-03  ...   1.0577e-02 -3.5838e-02  2.0622e-02\n",
      " -1.8194e-02  1.4084e-02 -2.3849e-01  ...   9.8683e-02 -4.0307e-03  6.8720e-04\n",
      " -6.5789e-02  1.0123e-02 -1.7445e-02  ...   1.0794e-04  4.3222e-04  4.9226e-02\n",
      "                 ...                                      ...                \n",
      " -1.3827e-02  4.9559e-03 -1.3831e-01  ...   6.8025e-02 -8.3817e-02  1.6668e-02\n",
      " -6.0461e-02  1.9893e-03 -1.5817e-01  ...  -1.1686e-02 -1.8478e-04  7.0340e-04\n",
      "  4.2279e-02  1.2103e-01 -9.4974e-02  ...  -1.8713e-01 -7.8284e-03  1.3370e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      " -3.4643e-02  1.2654e-01 -8.0165e-02  ...   2.0777e-02 -2.5036e-03  9.0203e-03\n",
      "  1.1881e-02  9.5986e-03 -1.4068e-01  ...   1.4285e-01 -7.4989e-02 -1.1960e-01\n",
      " -1.5654e-01 -4.5038e-03 -1.8345e-01  ...   1.0037e-02 -1.6200e-02  1.6544e-02\n",
      "                 ...                                      ...                \n",
      "  1.1300e-01 -3.2493e-03 -4.0551e-03  ...   1.1721e-01 -3.6429e-03  5.0871e-04\n",
      " -7.0821e-01  1.3587e-01 -1.7079e-01  ...  -1.4757e-01  9.8104e-03  2.0653e-02\n",
      "  1.0688e-01  4.9499e-02 -2.5550e-02  ...  -5.4766e-01  1.2243e-03  1.1156e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.1389e-01 -3.5586e-03 -9.3200e-02  ...  -2.6438e-03 -7.6362e-03  1.7036e-03\n",
      " -5.2263e-03  1.9708e-02 -1.2260e-01  ...   1.4477e-01 -1.6670e-01 -1.4843e-02\n",
      " -3.8121e-02 -4.5752e-04  3.8685e-01  ...   1.3709e-02 -5.6548e-03  3.4735e-03\n",
      "                 ...                                      ...                \n",
      "  2.2985e-02  3.3555e-03  1.1581e-05  ...   1.4812e-02 -6.6892e-02  1.6632e-01\n",
      " -3.6140e-01 -6.8610e-04  3.2007e-01  ...  -1.9816e-02 -9.4621e-03  7.7390e-03\n",
      " -5.6534e-01 -8.7051e-05 -2.0320e-01  ...  -2.9728e-01 -1.5671e-04  8.9849e-04\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0015  0.0004  0.8091  ...  -0.0000 -0.0896  0.0182\n",
      "  0.0031  0.0000  0.0000  ...  -0.0000 -0.0322  0.0095\n",
      "  0.0000  0.0002  0.0000  ...  -1.3851 -0.0000  0.0783\n",
      "           ...                          ...          \n",
      "  0.0000 -0.0000  0.0000  ...  -1.3439 -0.0268 -0.0434\n",
      "  0.0072  0.0001 -0.6089  ...  -0.0000 -0.0243 -0.0000\n",
      "  0.0000  0.0370  0.7580  ...  -1.1621 -0.0000 -0.1116\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000 -0.0000  0.0001  ...  -0.0000 -0.0360 -0.0020\n",
      "  0.0002  0.0002  0.0001  ...  -0.0000 -0.0644 -0.0039\n",
      "  0.0000  0.0002 -0.0019  ...  -0.0001 -0.0000  0.0447\n",
      "           ...                          ...          \n",
      "  0.0000  0.0010  0.0000  ...  -1.3469 -0.0358 -0.0347\n",
      "  0.0000 -0.5647  0.5977  ...  -1.2087 -0.0264 -0.0000\n",
      "  0.0000  0.0012  0.5313  ...  -0.7970 -0.0000 -0.0224\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0005  0.0001  0.3932  ...  -0.0000 -0.0419  0.0093\n",
      "  0.0036  0.0045  0.6682  ...  -0.0000 -0.0684  0.0389\n",
      "  0.0000  0.1659  0.0025  ...  -0.0000 -0.0000  0.0634\n",
      "           ...                          ...          \n",
      "  0.0007  0.0001  0.0000  ...  -0.7040 -0.0497 -0.0881\n",
      "  0.0000  0.0011  0.0061  ...  -1.2178  0.0432 -0.0000\n",
      "  0.0000  0.0000  0.0789  ...  -0.0005 -0.0000 -0.0285\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0060  0.0003  0.0000  ...  -0.0000 -0.0563 -0.0716\n",
      "  0.0008  0.0034  1.0824  ...  -0.0000 -0.0513 -0.0015\n",
      "  0.0000  0.0420  0.0001  ...  -0.0000 -0.0000  0.0343\n",
      "           ...                          ...          \n",
      "  0.0293 -0.3438  0.0000  ...  -0.0022 -0.0927 -0.0016\n",
      "  0.0028  0.0027  0.0001  ...  -0.0002 -0.0614  0.0000\n",
      "  0.0000  0.1878  0.0015  ...  -0.0000 -0.0000 -0.0439\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0001  0.0012  0.1171  ...  -0.0000 -0.0652 -0.1376\n",
      "  0.0404  0.0006  0.6808  ...  -0.0000 -0.0459 -0.0072\n",
      "  0.0000  0.0719  1.0712  ...  -0.4582 -0.0000  0.0414\n",
      "           ...                          ...          \n",
      "  0.0478 -0.0004  0.0000  ...  -0.0002 -0.0410 -0.0209\n",
      "  0.0079  0.0000  1.0876  ...  -0.0031 -0.0542  0.0000\n",
      "  0.0000  0.0003  0.0001  ...  -0.0002 -0.0000 -0.0347\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0001  0.0000  1.0780  ...  -0.0000 -0.0493 -0.0459\n",
      "  0.0004  0.0000  0.2933  ...  -0.0000 -0.0583 -0.0015\n",
      "  0.0000 -0.0000  0.0014  ...  -1.3822 -0.0000 -0.0121\n",
      "           ...                          ...          \n",
      "  0.0028  0.1417  0.0000  ...  -0.0058 -0.1069 -0.0364\n",
      "  0.0026  0.0516  0.0000  ...  -0.0000 -0.0723 -0.0000\n",
      "  0.0000  0.0305  0.0996  ...  -0.0037 -0.0000  0.0311\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0006 -0.0059 -0.0273  ...   0.0041 -0.0000 -0.0000\n",
      " -0.0009 -0.0029  0.0000  ...  -0.0506 -0.0211  0.0210\n",
      " -0.0000  0.0012 -0.0000  ...   0.0000  0.0321 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0041 -0.0010  ...  -0.0078  0.0311 -0.0205\n",
      " -0.0000 -0.0000 -0.1329  ...   0.0000  0.0000 -0.0000\n",
      " -0.0005 -0.0121 -0.0279  ...   0.0133 -0.0098 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0001  0.0017 -0.0110  ...  -0.0103 -0.0000 -0.0000\n",
      " -1.1633  0.0016  0.0000  ...  -0.0282  0.0085  0.0309\n",
      " -0.0002  0.0004 -0.0000  ...   0.0000  0.0005 -0.0000\n",
      "           ...                          ...          \n",
      " -0.0004 -0.0034 -0.0031  ...  -0.0100  0.0154 -0.0181\n",
      " -0.0001 -0.0000  0.0060  ...   0.0000 -0.0000 -0.0000\n",
      " -0.0001 -0.0029 -0.0086  ...   0.0117  0.0329 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0237  0.0073 -0.0449  ...   0.0038 -0.0000  0.0000\n",
      " -0.0458  0.0034  0.0000  ...  -0.0021  0.0072  0.0446\n",
      " -0.0009 -0.0017  0.0000  ...  -0.0000  0.0033  0.0000\n",
      "           ...                          ...          \n",
      " -0.6010  0.0053 -0.1406  ...   0.0059  0.0009 -0.0435\n",
      " -0.0006  0.0000  0.0165  ...   0.0000 -0.0000 -0.0000\n",
      " -0.0001 -0.0057  0.0110  ...  -0.0175 -0.0228  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.7458  0.0260  0.1017  ...  -0.0379  0.0000  0.0000\n",
      " -0.0002 -0.0054 -0.0000  ...   0.0044 -0.0036  0.0291\n",
      " -1.3213  0.0102  0.0000  ...  -0.0000  0.0028  0.0000\n",
      "           ...                          ...          \n",
      " -1.3035  0.0310  0.2602  ...  -0.0355  0.0803  0.0119\n",
      " -0.0072  0.0000 -0.0156  ...   0.0000  0.0000  0.0000\n",
      " -0.0000  0.0072 -0.0032  ...  -0.0144  0.0246 -0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0017  0.0153  0.0382  ...  -0.0030  0.0000  0.0000\n",
      " -0.0117 -0.0099 -0.0000  ...   0.0050 -0.0135  0.0414\n",
      " -0.0009  0.0047 -0.0000  ...   0.0000  0.0042  0.0000\n",
      "           ...                          ...          \n",
      " -1.2611  0.0281 -0.0894  ...  -0.0181  0.0709 -0.0127\n",
      " -0.0000 -0.0000 -0.0041  ...   0.0000  0.0000  0.0000\n",
      " -0.0002  0.0092 -0.0354  ...  -0.0206  0.0283 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0006  0.0160  0.0085  ...   0.0034  0.0000  0.0000\n",
      " -0.0553 -0.0072  0.0000  ...   0.0040  0.0156  0.0468\n",
      " -0.0000  0.0034  0.0000  ...  -0.0000 -0.0014  0.0000\n",
      "           ...                          ...          \n",
      " -0.6131  0.0080 -0.1140  ...  -0.0006  0.0768  0.0584\n",
      " -1.3478 -0.0000 -0.1187  ...   0.0000  0.0000  0.0000\n",
      " -0.0029 -0.0009 -0.0732  ...   0.0030 -0.0030 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  6.3634e-02  6.9734e-03 -1.2572e-01  ...  -4.1732e-02 -8.7255e-02 -4.4855e-02\n",
      "  1.2853e-02  8.6750e-02 -1.9583e-01  ...   1.0862e-01 -8.5190e-03  4.0651e-02\n",
      " -2.0109e-01 -3.9865e-02 -5.6583e-02  ...   8.9076e-02 -8.3683e-03  3.6439e-02\n",
      "                 ...                                      ...                \n",
      "  7.7502e-02  7.9787e-02 -4.6166e-02  ...   4.1682e-02 -5.0900e-02  3.0788e-02\n",
      " -1.5225e-01 -1.6042e-01  6.5359e-02  ...  -3.1946e-01  5.2854e-03  1.1390e-02\n",
      " -1.4169e-01  5.2744e-03  1.0032e-01  ...  -1.9977e-01 -1.9639e-01  5.5593e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.7758e-01 -2.0398e-03 -1.4834e-01  ...  -5.3253e-02 -4.2265e-02  2.3287e-02\n",
      "  4.1564e-01 -7.4319e-02  1.1834e-03  ...   7.3625e-02 -1.3324e-03  2.3471e-03\n",
      " -1.2513e-01  5.3534e-02 -2.1243e-02  ...   7.4410e-02  3.4602e-03  2.4685e-02\n",
      "                 ...                                      ...                \n",
      " -5.8353e-02  8.6951e-02 -2.6486e-01  ...   1.3445e-01 -1.3330e-02  2.7057e-02\n",
      "  7.6802e-03  1.7195e-01 -5.7120e-02  ...  -3.9227e-02  1.7869e-01  1.7077e-02\n",
      " -6.9762e-02  3.8752e-02 -2.5844e-01  ...   1.1448e-02  4.0770e-02  2.2393e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.0977e-02 -1.0741e-02 -5.3961e-01  ...  -1.9062e-02 -1.9759e-01  1.0517e-02\n",
      "  1.2122e-01 -4.0190e-03  2.1010e-02  ...  -1.7696e-02 -1.4441e-01  8.0601e-02\n",
      " -4.1263e-01  5.8897e-02 -2.4947e-02  ...   2.2398e-04 -1.4975e-02  3.0212e-02\n",
      "                 ...                                      ...                \n",
      "  5.4150e-03 -3.8292e-03  4.9017e-01  ...   3.2383e-01 -1.4020e-02  2.1246e-03\n",
      "  5.9844e-02  9.4588e-02 -1.7319e-02  ...  -5.8970e-02 -5.8227e-03  4.8534e-03\n",
      " -7.2109e-02  1.0338e-01 -1.9674e-01  ...   2.9737e-02  2.2388e-02  4.1082e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -9.1387e-02 -1.4631e-02 -9.5429e-02  ...   3.7112e-03 -4.6812e-03  1.1503e-03\n",
      " -2.8534e-01  9.8115e-02  1.5990e-01  ...   1.8359e-01  2.9871e-02  1.4249e-03\n",
      "  1.8773e-01 -1.7450e-02 -5.4220e-03  ...   3.6084e-02 -1.7005e-04  3.7892e-03\n",
      "                 ...                                      ...                \n",
      "  8.1771e-02  3.2637e-03 -9.3297e-02  ...   5.7179e-02 -8.7209e-03  4.0001e-03\n",
      " -1.6968e-02  1.2295e-01 -3.8663e-01  ...   3.8513e-02 -4.5720e-04  1.3817e-03\n",
      " -1.9579e-01  1.6535e-01 -3.1110e-01  ...  -1.4874e-02 -2.3507e-03  4.9966e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      " -2.5539e-02 -2.4823e-03 -1.2712e-01  ...   2.2482e-03 -1.4550e-01  1.1867e-01\n",
      " -4.2583e-01  1.9298e-01  1.3913e-01  ...   1.7239e-01  6.5789e-02  1.1562e-02\n",
      "  7.8080e-02  3.0493e-02 -1.9285e-02  ...  -1.1502e-02 -1.2516e-02  5.5047e-02\n",
      "                 ...                                      ...                \n",
      "  5.1789e-01 -6.1604e-03 -1.3188e-02  ...  -7.6453e-02 -1.9870e-04  1.0209e-03\n",
      " -1.2187e-01  7.0450e-03  5.6369e-01  ...   4.1941e-02  6.2392e-03  8.9179e-03\n",
      " -2.2506e-01  1.7795e-02  6.4520e-01  ...  -5.4152e-04 -3.2756e-03  4.3997e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.5573e-03 -2.5938e-04 -4.7335e-01  ...   1.4910e-03 -1.2894e-01  1.5146e-02\n",
      " -2.7687e-01  1.0784e-01 -1.9383e-01  ...   1.6633e-01  6.1455e-02  1.5222e-02\n",
      " -1.1819e-02  1.1329e-01 -3.9281e-03  ...  -3.9317e-03 -3.0441e-03  4.5144e-02\n",
      "                 ...                                      ...                \n",
      "  7.4924e-02 -4.0139e-03  1.6107e-01  ...  -2.5418e-02 -4.9238e-04  2.6785e-02\n",
      " -2.1493e-02 -3.3426e-02 -1.1756e-01  ...   1.5181e-02 -1.2916e-04  2.2829e-03\n",
      " -2.0842e-01  9.3108e-02 -7.3036e-02  ...   4.1282e-01  1.2105e-01  6.1011e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0015  0.0003  ...  -0.0005 -0.0583 -0.0000\n",
      "  0.0012  0.0000  0.0001  ...  -0.0000 -0.0173  0.0028\n",
      "  0.0052  0.0000 -0.0229  ...  -0.0007 -0.0434 -0.0534\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0858  ...  -0.0314 -0.0173 -0.0141\n",
      "  0.0002  0.0186  0.0454  ...  -0.7132 -0.0650  0.0263\n",
      "  0.0000 -0.0000  0.0000  ...  -1.2503  0.0049 -0.0036\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0002  0.0022  ...  -0.1535 -0.0841 -0.0000\n",
      "  0.0042  0.1919  0.0000  ...  -0.0000 -0.0105  0.0337\n",
      "  0.0002  0.0000  0.0000  ...  -0.0001 -0.0824 -0.0531\n",
      "           ...                          ...          \n",
      "  0.0003  0.0000  1.1314  ...  -0.4578 -0.0349 -0.0166\n",
      "  0.0042 -0.0001  0.0013  ...  -0.0001  0.0130 -0.0029\n",
      "  0.0007 -0.0000  0.0000  ...  -1.2423 -0.0003 -0.0066\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.0007  0.0018  ...  -0.0001 -0.0388  0.0000\n",
      "  1.3856  0.0000  0.0026  ...  -0.0000 -0.0464 -0.0216\n",
      "  0.0028  0.0000  0.4936  ...  -0.0000 -0.0813 -0.0443\n",
      "           ...                          ...          \n",
      "  1.3863  0.0000  0.0000  ...  -0.0050 -0.0454 -0.0242\n",
      "  0.0000  1.0799  0.0084  ...  -0.0093 -0.0318  0.0405\n",
      "  0.0012  0.0000 -0.3464  ...  -0.1711  0.0424 -0.0022\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0000  0.0000  ...  -1.3142  0.0198 -0.0000\n",
      "  0.0113  0.0000  0.0299  ...  -0.0000  0.0049 -0.0832\n",
      "  0.0003  0.0000  0.2063  ...  -0.0046 -0.0442  0.0430\n",
      "           ...                          ...          \n",
      "  0.0147  0.0000  0.0001  ...  -0.0266 -0.0797 -0.0892\n",
      "  0.0003  0.0004  0.0005  ...  -1.2851 -0.0041 -0.1093\n",
      "  1.3700  0.0000  0.0000  ...  -0.0007  0.0373 -0.0639\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0093  0.0000  ...  -1.3503 -0.0088 -0.0000\n",
      "  0.0025  0.0572  0.0031  ...  -0.0000  0.0262 -0.1594\n",
      "  0.0004 -0.0000  0.0000  ...  -0.0002 -0.0172  0.0273\n",
      "           ...                          ...          \n",
      "  0.0001 -0.0000  0.0000  ...  -1.3251 -0.0243 -0.0448\n",
      "  0.0001 -0.0000  0.0000  ...  -1.3178  0.0026 -0.0390\n",
      "  0.0022  0.0000  1.0650  ...  -0.0002  0.0440 -0.1731\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0002  0.0031  ...  -0.0004 -0.0567 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0244 -0.0707\n",
      "  0.0000  0.0000  0.9211  ...  -0.1770 -0.0385 -0.0762\n",
      "           ...                          ...          \n",
      "  0.0019  0.0000 -0.3401  ...  -0.0550 -0.0432 -0.1090\n",
      "  0.0026  0.0001  0.2746  ...  -0.1423  0.0075 -0.0785\n",
      "  0.0000  0.0000  1.0211  ...  -0.0003  0.0142 -0.0812\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -1.2205  0.0000  0.0000  ...  -0.0658  0.1346  0.0453\n",
      " -0.0000 -0.0006 -0.0097  ...   0.0000  0.0053  0.0327\n",
      " -0.0000  0.0000  0.0108  ...  -0.0047  0.0004  0.0047\n",
      "           ...                          ...          \n",
      " -0.0111  0.0070 -0.0853  ...  -0.0037  0.0000  0.0322\n",
      " -0.0077  0.0000 -0.0547  ...   0.0188  0.0642  0.0217\n",
      " -0.0000 -0.0059 -0.0000  ...  -0.0142 -0.0251  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0025  0.0000  0.0000  ...  -0.0369  0.1125  0.0182\n",
      " -0.0000  0.0003  0.0261  ...  -0.0000 -0.0066  0.0436\n",
      " -0.0003  0.0000 -0.0225  ...   0.0013  0.0254  0.0020\n",
      "           ...                          ...          \n",
      " -0.0000  0.0057 -0.0153  ...  -0.0051  0.0000  0.0129\n",
      " -0.0001 -0.0000 -0.0090  ...  -0.0133  0.0237  0.0178\n",
      " -0.0000 -0.0134 -0.0000  ...   0.0051 -0.0448 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0003  0.0000  0.0000  ...  -0.0695  0.0319 -0.0385\n",
      " -0.0000  0.0028 -0.0002  ...   0.0000  0.0097  0.0264\n",
      " -0.0000  0.0000 -0.0501  ...   0.0118  0.0352  0.0236\n",
      "           ...                          ...          \n",
      " -0.0000  0.0226 -0.0214  ...   0.0023  0.0000  0.0101\n",
      " -0.0001 -0.0000 -0.0173  ...   0.0124  0.0265  0.0267\n",
      " -0.0450 -0.0072 -0.0000  ...   0.0179 -0.0493 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000 -0.0000  0.0000  ...  -0.0072 -0.0369  0.0105\n",
      " -0.0000  0.0038  0.0071  ...  -0.0000 -0.0358  0.0373\n",
      " -0.0033 -0.0000 -0.0162  ...   0.0191 -0.0393 -0.0058\n",
      "           ...                          ...          \n",
      " -0.0000  0.0064 -0.0231  ...   0.0032  0.0000  0.0089\n",
      " -0.0003 -0.0000  0.0910  ...  -0.0209  0.0489 -0.0001\n",
      " -0.0001  0.0001 -0.0000  ...   0.0164 -0.0194  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0003  0.0000 -0.0000  ...   0.0201 -0.0280 -0.0215\n",
      " -0.0000 -0.0184  0.0040  ...  -0.0000  0.0471  0.0258\n",
      " -1.3149 -0.0000 -0.1838  ...   0.0093 -0.0019  0.0218\n",
      "           ...                          ...          \n",
      " -0.0000  0.0092 -0.0066  ...   0.0036  0.0000 -0.0041\n",
      " -0.0005 -0.0000  0.0334  ...  -0.0188  0.0021 -0.0048\n",
      " -0.0075  0.0009 -0.0000  ...   0.0283 -0.0064  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.0526  0.0000 -0.0000  ...   0.0403 -0.0264  0.0280\n",
      " -0.0000 -0.0069  0.0070  ...  -0.0000  0.0162 -0.0023\n",
      " -1.2706 -0.0000 -0.1939  ...   0.0117  0.0564  0.0381\n",
      "           ...                          ...          \n",
      " -0.0096  0.0101 -0.0169  ...   0.0001  0.0000 -0.0139\n",
      " -0.0029 -0.0000  0.0227  ...   0.0021 -0.0004 -0.0004\n",
      " -0.0035  0.0122  0.0000  ...   0.0155  0.0124  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.7718e-03 -1.1304e-02 -4.8702e-03  ...   6.0166e-03 -1.6885e-04  1.8473e-03\n",
      " -7.8003e-02  1.9728e-01 -3.4525e-02  ...   3.3379e-02  7.3872e-02  1.8386e-02\n",
      " -9.3800e-04 -7.8731e-02 -7.1225e-02  ...   4.6616e-02 -6.6999e-02  2.3474e-02\n",
      "                 ...                                      ...                \n",
      "  8.8719e-02 -6.7625e-03 -5.4081e-02  ...  -3.9106e-02 -3.7493e-03  1.0672e-01\n",
      " -5.6062e-02 -3.2883e-02 -6.6191e-02  ...  -3.5121e-04 -6.8917e-02 -3.7369e-02\n",
      " -1.0680e-02  1.0676e-01 -1.8159e-02  ...   1.3405e-01  5.0336e-02  5.2789e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.3089e-03 -1.9429e-02 -2.3917e-01  ...   1.8102e-03 -1.9453e-02  8.7000e-02\n",
      " -5.1620e-01  6.6418e-02 -1.0755e-01  ...  -3.0137e-02 -6.4645e-03  4.2444e-02\n",
      " -4.4014e-02 -7.5746e-04  6.4197e-01  ...   5.3238e-05 -2.8581e-01  4.9556e-02\n",
      "                 ...                                      ...                \n",
      "  5.8145e-02  7.0643e-04 -2.4648e-02  ...   5.2243e-03 -1.7652e-01  2.6104e-02\n",
      " -4.4322e-02  4.6549e-03 -4.6155e-02  ...   3.3589e-02 -9.4708e-03 -9.5627e-03\n",
      " -4.1175e-01  1.8954e-02 -2.9925e-02  ...  -9.9741e-02  8.0254e-03 -8.4490e-04\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.0469e-03 -8.1849e-02  4.8341e-02  ...  -1.8303e-02 -2.4483e-02  2.2929e-01\n",
      " -4.5102e-01  1.9672e-02 -5.9349e-01  ...  -2.6459e-03 -9.0814e-03  2.6335e-04\n",
      " -2.2044e-01 -6.8045e-03  5.9439e-01  ...  -1.6808e-02  3.0456e-03  8.9086e-03\n",
      "                 ...                                      ...                \n",
      "  2.0730e-01  2.9169e-02  3.0845e-01  ...   6.5465e-03 -2.2752e-02  2.1856e-03\n",
      " -1.2626e-01 -3.1262e-02 -3.9637e-02  ...   6.4396e-02 -3.6457e-03  4.0807e-03\n",
      " -2.3088e-01  3.8580e-03 -8.7307e-02  ...  -2.8013e-02 -1.9784e-02  2.9176e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  1.6644e-03  1.9676e-01 -4.0827e-02  ...   3.6844e-02 -7.1243e-03  1.6938e-02\n",
      " -3.2083e-02  2.6768e-03  3.6687e-01  ...  -2.4195e-02 -3.9272e-03  1.1388e-02\n",
      " -1.2153e-01 -3.4074e-03 -4.4779e-01  ...   8.2886e-03 -1.4223e-01  1.9425e-03\n",
      "                 ...                                      ...                \n",
      " -1.5480e-02  8.8931e-04 -3.5971e-01  ...   1.6052e-01 -2.7229e-01  5.2142e-02\n",
      " -7.3710e-03  8.8260e-03  2.0174e-01  ...   9.3244e-03 -3.5015e-01 -2.0296e-02\n",
      "  1.5246e-01  1.9527e-02  2.6574e-02  ...  -4.1579e-02 -1.4170e-03  1.7216e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      " -6.8097e-02  9.3824e-02 -1.8717e-01  ...   2.7975e-02 -1.2491e-02  2.9067e-03\n",
      "  2.1070e-02 -9.8222e-03  2.2986e-01  ...  -1.3053e-02 -1.2221e-02  2.2936e-01\n",
      " -8.9725e-02 -5.0336e-03 -4.4901e-01  ...   1.3814e-02 -7.6091e-03  1.5960e-04\n",
      "                 ...                                      ...                \n",
      "  2.6267e-03  1.5719e-01 -6.8056e-02  ...  -9.2097e-02 -3.4035e-02  1.2001e-03\n",
      " -2.0264e-01 -7.3789e-03 -2.8288e-01  ...   7.2181e-02 -6.9590e-02  1.7591e-03\n",
      "  2.1860e-01 -1.4963e-02  1.7199e-01  ...  -1.4009e-02  4.4399e-05  9.3875e-04\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.6486e-02 -6.7494e-02 -5.9576e-01  ...   9.5336e-04 -1.5088e-03  6.2296e-03\n",
      "  3.8721e-02  3.9676e-02  2.2617e-02  ...  -1.6412e-01 -2.0060e-01  3.1891e-02\n",
      "  3.0948e-02 -1.8689e-02 -3.0412e-01  ...  -7.0133e-03 -1.1844e-02  2.5071e-03\n",
      "                 ...                                      ...                \n",
      " -6.7359e-02  6.9908e-03 -3.0942e-01  ...  -3.0229e-01 -1.0032e-01  3.6864e-02\n",
      " -6.6081e-02 -1.5438e-03 -4.9378e-01  ...   3.0116e-02 -3.1106e-01  6.5712e-02\n",
      "  1.5251e-01 -5.2163e-03 -6.0258e-01  ...  -2.2092e-02 -2.8292e-02  4.9120e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000  0.8222  ...  -0.0002 -0.0412 -0.0494\n",
      "  0.0003  0.0000  0.0000  ...  -0.0000 -0.0000 -0.1681\n",
      "  0.0067  0.0000  0.6412  ...  -0.0000  0.0000 -0.1970\n",
      "           ...                          ...          \n",
      "  0.0001  0.0007 -0.0137  ...  -0.0000 -0.0460 -0.0000\n",
      "  0.0000  0.0145  1.0155  ...  -0.0003 -0.0073 -0.1149\n",
      "  0.0007  0.0739  0.0074  ...  -0.0019  0.0091 -0.0198\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0001  0.0000  0.0132  ...  -0.0000 -0.0436 -0.0519\n",
      "  0.0004 -0.0000  0.0180  ...  -0.0000  0.0000 -0.1478\n",
      "  0.0000  0.0000  0.0000  ...  -0.0000  0.0000 -0.0907\n",
      "           ...                          ...          \n",
      "  1.0718  0.0000 -0.0001  ...  -0.0000 -0.0645 -0.0000\n",
      "  0.0000  0.3688  0.4177  ...  -0.0001 -0.0750 -0.1580\n",
      "  0.0002  0.0143  0.4141  ...  -0.0124 -0.0425  0.0165\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0069  0.0000  0.0000  ...  -0.0000 -0.0591 -0.0300\n",
      "  0.2547 -0.0000  0.0000  ...  -0.0000  0.0000 -0.1353\n",
      "  0.0001  0.0149  0.1674  ...  -0.0000 -0.0000 -0.2017\n",
      "           ...                          ...          \n",
      "  0.0000  0.0015  0.4908  ...  -0.0000 -0.0510 -0.0000\n",
      "  0.0000  0.0000  0.0253  ...  -0.0000 -0.0311 -0.0945\n",
      "  0.0000 -0.0018  0.0000  ...  -1.3439 -0.0011 -0.0273\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000  0.0000  0.6418  ...  -0.4995 -0.0849  0.0405\n",
      "  0.0003  0.0000  0.3711  ...  -0.0000 -0.0000  0.0056\n",
      "  0.0007  0.0009  0.0004  ...  -0.0000 -0.0000 -0.0180\n",
      "           ...                          ...          \n",
      "  0.0001  0.0000  0.0000  ...  -0.0000 -0.0134  0.0000\n",
      "  0.0000  0.0000  0.0427  ...  -0.0000  0.0106  0.0001\n",
      "  0.0070  0.0000  0.0408  ...  -0.0012  0.0084 -0.0471\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0000  0.2913  ...  -1.3746 -0.0182  0.0190\n",
      "  0.0004  0.0000  0.0000  ...  -0.0000  0.0000 -0.0388\n",
      "  0.0178  0.0332  0.0000  ...  -0.0000 -0.0000 -0.0367\n",
      "           ...                          ...          \n",
      "  0.0730  0.0002  0.0000  ...  -0.0000 -0.0612 -0.0000\n",
      "  0.0000  0.0000  0.0173  ...  -1.2675  0.0360 -0.0233\n",
      "  0.0001  0.0007  0.4134  ...  -0.0013 -0.0157 -0.0950\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0010  0.0000  0.0670  ...  -0.0091 -0.0625  0.0089\n",
      "  0.0001  0.0000  1.0837  ...  -0.0000  0.0000 -0.1298\n",
      "  0.0001  0.0244  0.0553  ...  -0.0000 -0.0000 -0.0765\n",
      "           ...                          ...          \n",
      "  0.0033  0.0094  0.0592  ...  -0.0000 -0.0481  0.0000\n",
      "  0.0000  0.0000  0.0931  ...  -0.0000 -0.0189 -0.0567\n",
      "  0.0008  0.0160  0.1624  ...  -0.0127 -0.0213 -0.0943\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0001 -0.0084 -0.0624  ...   0.0000 -0.0068  0.0282\n",
      " -0.0156 -0.0000  0.0177  ...  -0.0058 -0.0108 -0.0165\n",
      " -0.0000  0.0000 -0.0566  ...  -0.0019  0.0075  0.0086\n",
      "           ...                          ...          \n",
      " -0.0036  0.0087 -0.0020  ...   0.0000  0.0000  0.0004\n",
      " -0.0000 -0.0063  0.0114  ...  -0.0000  0.0092  0.0018\n",
      " -0.0085  0.0104  0.0000  ...  -0.0188  0.0007  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0044 -0.0010 -0.0041  ...  -0.0000 -0.0150  0.0195\n",
      " -0.1681 -0.0000 -0.0202  ...   0.0032 -0.0325 -0.0265\n",
      " -0.0000  0.0000 -0.0134  ...  -0.0085  0.0036 -0.0106\n",
      "           ...                          ...          \n",
      " -0.0057  0.0047  0.0249  ...   0.0000 -0.0000  0.0236\n",
      " -0.0003 -0.0036  0.0426  ...   0.0000  0.0284  0.0079\n",
      " -0.0337  0.0028  0.0000  ...   0.0007 -0.0136  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.4025  0.0107 -0.0280  ...  -0.0000  0.0223  0.0616\n",
      " -0.9213 -0.0000 -0.0644  ...   0.0304 -0.0040 -0.0071\n",
      " -0.0000  0.0000 -0.0191  ...  -0.0065 -0.0110 -0.0110\n",
      "           ...                          ...          \n",
      " -0.0112  0.0017 -0.0060  ...   0.0000  0.0000  0.0226\n",
      " -0.0033  0.0073  0.0666  ...  -0.0000  0.0243  0.0073\n",
      " -0.0010  0.0068  0.0000  ...  -0.0029 -0.0085  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0005  0.0036 -0.0246  ...   0.0000 -0.0007 -0.0032\n",
      " -0.0043  0.0000 -0.0120  ...  -0.0149  0.0138  0.0004\n",
      " -0.0000 -0.0000  0.0396  ...  -0.0167 -0.0284  0.0019\n",
      "           ...                          ...          \n",
      " -0.0011  0.0034 -0.0163  ...  -0.0000  0.0000  0.0063\n",
      " -0.0002 -0.0050 -0.0344  ...  -0.0000  0.0230  0.0117\n",
      " -0.0106 -0.0005 -0.0000  ...  -0.0109 -0.0150  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000 -0.0043 -0.0038  ...   0.0000 -0.0096 -0.0055\n",
      " -0.0004  0.0000  0.0054  ...  -0.0190 -0.0106 -0.0064\n",
      " -0.0000 -0.0000 -0.0152  ...  -0.0032 -0.0293 -0.0091\n",
      "           ...                          ...          \n",
      " -1.1879  0.0122  0.0931  ...  -0.0000  0.0000  0.0495\n",
      " -0.0000 -0.0085 -0.0154  ...  -0.0000  0.0002  0.0026\n",
      " -0.9321  0.0010 -0.0000  ...   0.0105 -0.0152  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0001  0.0009 -0.0146  ...  -0.0000 -0.0265  0.0188\n",
      " -0.0214  0.0000  0.0048  ...  -0.0059  0.0539  0.0035\n",
      " -0.0000  0.0000 -0.1271  ...   0.0158 -0.0002 -0.0209\n",
      "           ...                          ...          \n",
      " -0.1704  0.0111 -0.0738  ...   0.0000  0.0000  0.0356\n",
      " -0.0011 -0.0114 -0.0285  ...  -0.0000 -0.0102  0.0254\n",
      " -0.0442 -0.0007 -0.0000  ...   0.0228 -0.0235  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -6.1663e-03 -2.9251e-02 -5.9036e-02  ...   1.9437e-01 -2.9996e-02  3.7599e-03\n",
      "  6.2014e-02  3.3921e-01  2.3668e-03  ...  -8.9395e-02 -1.7321e-02  5.9965e-03\n",
      "  2.0964e-02  1.2274e-04 -5.5861e-02  ...  -1.9340e-02 -1.3188e-01  3.8209e-02\n",
      "                 ...                                      ...                \n",
      " -6.9782e-02 -7.2005e-04 -2.2652e-02  ...  -1.4215e-01 -1.3165e-01  4.1110e-02\n",
      " -1.5627e-01  1.7360e-02 -4.0311e-01  ...   2.6225e-02 -1.1692e-02  2.4314e-03\n",
      "  3.2810e-02 -4.5897e-02 -1.0840e-01  ...  -4.3704e-03 -3.2420e-03  1.3029e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -1.5598e-02 -4.0488e-02 -6.2937e-02  ...   1.0511e-01 -5.4348e-02  6.3372e-02\n",
      " -3.3670e-01  1.6811e-02 -1.2811e-01  ...  -1.7496e-01 -3.5404e-02  2.0042e-02\n",
      " -1.5458e-02  1.0353e-01 -1.0397e-01  ...  -6.5066e-02 -4.4272e-02  3.2811e-03\n",
      "                 ...                                      ...                \n",
      " -1.2683e-02  2.8568e-02 -5.8367e-02  ...  -2.0143e-01  1.9827e-03  4.1758e-03\n",
      " -3.6847e-02 -2.8695e-02 -3.1528e-02  ...   7.9779e-02 -1.8041e-01  3.0436e-02\n",
      "  9.6816e-02  2.3432e-04 -8.8961e-02  ...   9.7352e-02 -1.3465e-01  5.2194e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -8.4188e-02 -3.9100e-02 -2.4481e-02  ...   1.5745e-01 -1.3104e-02  3.3324e-03\n",
      " -1.3831e-01 -2.1628e-03 -1.0787e-02  ...  -3.5702e-01 -4.1335e-04  1.8556e-04\n",
      " -3.6592e-02  7.6068e-04 -9.9851e-02  ...   6.0769e-02 -5.4255e-02  1.1899e-02\n",
      "                 ...                                      ...                \n",
      "  2.9200e-01  4.8620e-03  6.5267e-01  ...  -8.0735e-02 -5.7222e-03  1.2058e-03\n",
      " -5.5439e-02  2.1847e-02 -2.4150e-01  ...   2.0511e-02 -5.5618e-03  3.3698e-02\n",
      "  1.8267e-01  5.5689e-02 -3.6594e-02  ...  -2.4981e-01 -4.9875e-02  8.3073e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -7.9361e-02  2.1895e-03 -1.2100e-01  ...  -9.0734e-02 -9.2340e-02  2.7517e-02\n",
      "  3.0455e-02  2.3359e-03 -3.8245e-03  ...  -1.4430e-02 -5.6652e-02  4.9970e-02\n",
      " -3.1752e-02  4.8134e-02 -1.4853e-01  ...  -1.6483e-01 -2.5995e-02  5.5191e-02\n",
      "                 ...                                      ...                \n",
      " -4.5865e-02  1.8226e-02 -1.9210e-01  ...   3.3093e-03 -7.2402e-03  2.8416e-03\n",
      "  6.1305e-02 -2.2968e-02 -6.9014e-02  ...  -2.9253e-02  3.2137e-02  7.5283e-02\n",
      "  1.7802e-01  1.5595e-02  3.1265e-01  ...  -2.6362e-02 -7.1862e-03  7.7267e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      " -5.1851e-02  9.6450e-02 -1.1934e-01  ...   1.9931e-02 -8.6686e-02  1.0975e-02\n",
      "  4.1846e-02  1.2178e-01 -3.4714e-03  ...   4.3897e-02 -9.8106e-04  6.2264e-04\n",
      " -9.7922e-02 -7.1541e-03 -2.1815e-01  ...  -3.1763e-02 -5.2569e-03  4.8540e-03\n",
      "                 ...                                      ...                \n",
      "  4.5366e-01 -5.3293e-03 -1.3243e-02  ...   1.2037e-03 -6.5019e-03  4.2630e-04\n",
      "  1.2021e-02  1.8731e-01 -1.8758e-01  ...  -1.3496e-01 -1.7209e-02  1.6880e-02\n",
      "  8.3794e-02  2.1338e-02 -3.4848e-01  ...   5.3111e-03 -1.2882e-02  6.5473e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      " -7.0600e-02  6.5297e-03 -1.9730e-01  ...   1.3650e-01 -4.2276e-03  7.9044e-04\n",
      "  1.6112e-01  1.8856e-04 -4.0951e-02  ...   3.9266e-02 -6.9920e-02  7.3020e-03\n",
      " -1.4741e-02 -4.0473e-03  1.1796e-01  ...  -2.0414e-02 -1.6802e-01  1.6241e-02\n",
      "                 ...                                      ...                \n",
      "  1.9168e-01 -7.8440e-03 -3.9260e-03  ...  -1.2046e-02 -4.2932e-02  1.0653e-01\n",
      " -7.1910e-02  2.6238e-03  1.0369e-01  ...  -1.5900e-02 -1.0574e-01  1.2453e-02\n",
      "  5.8391e-02  6.7156e-02 -8.1378e-02  ...   1.3263e-01 -6.4852e-02  8.6641e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.4660  0.0000  ...  -0.0000 -0.0000 -0.0061\n",
      "  0.0000  0.0017  0.0000  ...  -0.0000  0.0084 -0.0405\n",
      "  0.0039  0.0000  1.0713  ...  -0.0002 -0.0000  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0003  ...  -1.2930 -0.0000 -0.0000\n",
      "  0.0064  0.0000  0.1626  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.0000  ...  -1.2679 -0.0073 -0.0407\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0002  0.0261  0.0000  ...  -0.0000 -0.0000  0.0158\n",
      "  0.0007  0.0060  0.0430  ...  -0.0024 -0.0238 -0.0222\n",
      "  1.0825  0.0001  0.0000  ...  -0.0001 -0.0000  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000 -0.1043  ...  -0.2069 -0.0000 -0.0000\n",
      "  0.0000  0.1341  0.0000  ...  -0.0105 -0.0000 -0.0000\n",
      "  0.0177  0.0002  0.0004  ...  -0.1758 -0.0520 -0.0953\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0089  0.0002  0.0000  ...  -0.0000 -0.0000 -0.0190\n",
      "  0.0000  0.0113  0.0000  ...  -0.0014 -0.0043 -0.0237\n",
      "  0.0027  0.3500 -0.0000  ...  -0.0225 -0.0000  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0042  0.7121  ...  -0.9882 -0.0000 -0.0000\n",
      "  0.0006  0.4882  0.0480  ...  -0.4125 -0.0000 -0.0000\n",
      "  0.0115  0.0005  0.1669  ...  -0.0043 -0.0556 -0.0376\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000 -0.0000 -0.0219\n",
      "  0.0001  0.0002  0.0000  ...  -0.0000 -0.0095  0.0075\n",
      "  0.0001  0.0257  0.0001  ...  -0.0029 -0.0000  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0127  0.0000  ...  -0.0000 -0.0000  0.0000\n",
      "  0.0011  0.0001  0.5043  ...  -0.0085 -0.0000 -0.0000\n",
      "  0.0003  0.0054  1.0387  ...  -1.1171 -0.0506 -0.0129\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000  0.0000 -0.0000  ...  -0.0000 -0.0000 -0.0237\n",
      "  0.0000  0.0002  0.2395  ...  -0.0596 -0.0868  0.0950\n",
      "  0.0000 -0.0000  0.0000  ...  -1.2835 -0.0000  0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0368  0.5937  ...  -0.3531 -0.0000 -0.0000\n",
      "  0.0003  0.0000  0.0037  ...  -0.0017 -0.0000 -0.0000\n",
      "  0.0000  0.0000  1.1143  ...  -1.2991 -0.0476  0.0563\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.3846  0.0000  0.0000  ...  -0.0000 -0.0000 -0.1027\n",
      "  0.0275  0.0000  0.0001  ...  -0.0000 -0.0292  0.0300\n",
      "  0.0001  0.0018  0.2245  ...  -0.0000 -0.0000 -0.0000\n",
      "           ...                          ...          \n",
      "  0.0000  0.0000  0.0002  ...  -1.2006 -0.0000 -0.0000\n",
      "  0.0024  0.0000  0.2388  ...  -0.0000 -0.0000 -0.0000\n",
      "  0.0000  0.0000  0.9325  ...  -1.2128 -0.0367  0.0486\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0007 -0.0096 -0.0000  ...  -0.0000 -0.0213  0.0125\n",
      " -0.0000  0.0134  0.0536  ...  -0.0000  0.0179  0.0062\n",
      " -0.0000 -0.0055  0.0050  ...  -0.0058  0.0000  0.0131\n",
      "           ...                          ...          \n",
      " -0.0000  0.0106  0.0000  ...  -0.0081 -0.0064  0.0000\n",
      " -0.0000  0.0017  0.0646  ...  -0.0075 -0.0195  0.0000\n",
      " -0.0000 -0.0025 -0.0100  ...   0.0140 -0.0214  0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0001 -0.0047  0.0000  ...  -0.0000 -0.0063  0.0223\n",
      " -0.0003  0.0060  0.0395  ...  -0.0000 -0.0081  0.0443\n",
      " -0.0048 -0.0265 -0.0300  ...   0.0187  0.0000 -0.0100\n",
      "           ...                          ...          \n",
      " -0.0000  0.0065  0.0000  ...  -0.0013 -0.0205  0.0000\n",
      " -0.0000  0.0087  0.1814  ...  -0.0544  0.0082 -0.0000\n",
      " -0.0001 -0.0082 -0.0421  ...   0.0073 -0.0530  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000  0.0025  0.0000  ...  -0.0000 -0.0032  0.0198\n",
      " -0.0009  0.0083 -0.0029  ...  -0.0000 -0.0022  0.0186\n",
      " -1.2185 -0.0406 -0.3365  ...   0.0557  0.0000 -0.0346\n",
      "           ...                          ...          \n",
      " -0.0000  0.0091  0.0000  ...  -0.0052 -0.0120 -0.0000\n",
      " -0.0000  0.0053 -0.0041  ...  -0.0124  0.0133  0.0000\n",
      " -0.0000 -0.0187 -0.0324  ...  -0.0157 -0.0731  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0005  0.0000  ...  -0.0000 -0.0212  0.0064\n",
      " -1.2673  0.0023 -0.0250  ...   0.0000  0.0444 -0.0021\n",
      " -0.0168 -0.0223 -0.0467  ...   0.0095  0.0000  0.0516\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0100  0.0000  ...  -0.0166 -0.0518  0.0000\n",
      " -0.0000 -0.0057 -0.0110  ...   0.0001 -0.0180  0.0000\n",
      " -0.0015  0.0334  0.0945  ...   0.0199  0.1394  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0004  0.0013 -0.0000  ...  -0.0000 -0.0069  0.0288\n",
      " -0.0000 -0.0011 -0.0279  ...   0.0000  0.0085  0.0114\n",
      " -0.0000 -0.0016  0.0019  ...  -0.0030 -0.0000 -0.0055\n",
      "           ...                          ...          \n",
      " -0.0000  0.0155 -0.0000  ...   0.0170  0.0243  0.0000\n",
      " -0.0000 -0.0066  0.0056  ...   0.0007 -0.0447  0.0000\n",
      " -0.0005  0.0187  0.0876  ...   0.0085  0.1027 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0009  0.0058  0.0000  ...  -0.0000  0.0097  0.0369\n",
      " -0.0001  0.0008  0.0140  ...  -0.0000  0.0126  0.0020\n",
      " -0.0018  0.0110 -0.0180  ...   0.0029  0.0000  0.0019\n",
      "           ...                          ...          \n",
      " -0.0000  0.0109  0.0000  ...   0.0037 -0.0091  0.0000\n",
      " -0.0000  0.0054  0.0693  ...  -0.0064 -0.0192 -0.0000\n",
      " -0.0000  0.0042  0.0288  ...  -0.0006  0.0657 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.1316e-01  1.5125e-02 -2.2926e-01  ...   9.9396e-02 -3.0773e-02  1.0992e-02\n",
      " -4.6578e-02 -7.5369e-04 -8.4606e-02  ...   3.7478e-01 -6.4405e-02  5.0951e-02\n",
      " -2.8597e-02  6.4207e-03  1.9702e-01  ...  -7.1201e-03  1.3879e-02  1.0542e-01\n",
      "                 ...                                      ...                \n",
      " -3.9531e-02  2.9062e-01 -3.0853e-02  ...  -1.2182e-02 -2.4168e-01  7.8583e-04\n",
      " -2.1005e-01  1.2724e-02  2.5091e-01  ...  -2.8221e-03  6.5712e-03  4.5712e-03\n",
      " -4.4048e-03  1.8030e-01 -1.2775e-01  ...  -3.3807e-03 -3.8161e-02  9.5132e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -3.1318e-02  1.2014e-03  6.4156e-02  ...  -1.8172e-03 -2.9402e-01  5.1638e-02\n",
      " -2.4305e-02 -2.5898e-03 -1.0556e-01  ...   9.6529e-02 -3.9396e-01  6.0770e-02\n",
      " -1.6768e-01  2.1529e-02  1.5266e-01  ...  -5.4252e-02 -1.4678e-04  3.9764e-02\n",
      "                 ...                                      ...                \n",
      " -5.3832e-02  2.5758e-02 -1.1593e-01  ...  -4.7153e-02 -1.2898e-01  1.2516e-02\n",
      "  5.3168e-01 -2.9045e-03  9.8276e-02  ...   5.7563e-02 -1.3658e-03  1.9404e-03\n",
      " -1.1621e-02  5.4495e-02 -2.1556e-01  ...  -2.6448e-02  2.2264e-03  2.1122e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.7328e-01  1.9735e-01 -3.7756e-01  ...   8.8657e-03  1.1900e-02  1.0380e-02\n",
      " -7.2983e-02  5.8490e-02 -9.8368e-02  ...   1.4577e-01 -6.5365e-02  1.1739e-02\n",
      "  2.9707e-01 -2.1559e-01 -4.2927e-03  ...   1.4086e-01  2.1156e-06  1.4431e-04\n",
      "                 ...                                      ...                \n",
      " -1.8221e-02 -1.3728e-03  3.4898e-01  ...  -3.7240e-02 -6.6102e-02  1.2873e-02\n",
      "  4.6277e-01 -6.0193e-03 -1.1886e-01  ...  -1.2814e-02 -7.0782e-02  9.9136e-02\n",
      " -1.2146e-01  6.2263e-02  6.0539e-02  ...  -9.7752e-03  3.1319e-02  7.4885e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -5.7366e-03  8.6305e-02 -9.7355e-02  ...   2.4737e-02 -1.3723e-01  2.5078e-02\n",
      "  7.2330e-02 -1.0997e-01 -2.2889e-03  ...   2.8491e-01 -1.4803e-05  6.2101e-04\n",
      "  3.3951e-02 -3.9298e-04 -3.1558e-02  ...  -4.5631e-04 -7.4639e-02  3.4291e-03\n",
      "                 ...                                      ...                \n",
      " -1.1405e-01 -7.4767e-03 -1.4851e-01  ...   4.4290e-02 -1.1041e-02  5.1506e-03\n",
      " -9.4610e-02  1.1286e-01 -8.8336e-02  ...  -2.4425e-01  4.6650e-02 -1.9599e-03\n",
      " -1.0365e-01 -2.1218e-03 -3.8277e-02  ...   1.4965e-01 -1.0237e-01  8.5244e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      " -2.8567e-02  1.5114e-04  8.7565e-02  ...  -2.6618e-03 -1.2168e-01  8.7035e-03\n",
      "  2.9466e-02 -2.5798e-02  3.9740e-02  ...   3.3806e-04  1.0535e-02  2.6231e-02\n",
      "  5.4733e-03  1.1173e-01 -1.3607e-02  ...  -4.3543e-02 -5.7917e-01  9.1923e-04\n",
      "                 ...                                      ...                \n",
      "  1.1496e-03 -1.6137e-02 -1.8625e-02  ...   1.4577e-01 -1.0617e-01  3.5578e-02\n",
      " -1.6776e-01  8.8520e-02 -5.8105e-03  ...  -1.1973e-01  4.2003e-03  7.9654e-03\n",
      " -1.8982e-01  4.0820e-05 -9.8515e-03  ...   1.6039e-02 -9.0586e-02  2.6398e-02\n",
      "\n",
      "(69 ,.,.) = \n",
      " -1.2723e-01  7.3183e-02  1.1647e-01  ...  -1.2731e-02  1.4759e-04  2.5368e-04\n",
      " -1.6765e-02  5.7121e-02 -1.1609e-01  ...   6.4371e-02  3.5465e-03  4.8540e-02\n",
      "  7.2393e-03  7.8577e-04 -3.6161e-02  ...  -2.0119e-02 -1.4439e-01  2.7402e-02\n",
      "                 ...                                      ...                \n",
      " -6.1176e-03  8.6903e-02 -2.1147e-02  ...   1.8217e-01 -1.9473e-02 -1.6425e-02\n",
      "  1.5478e-03  3.5045e-02  1.6156e-01  ...  -3.0862e-02 -5.5226e-03  1.0494e-03\n",
      " -1.6536e-01  2.8519e-03 -1.3572e-02  ...   6.1144e-03 -1.0933e-01 -4.7330e-03\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0001  0.9982  ...  -0.0084 -0.0000 -0.1323\n",
      "  0.0000  0.0022  0.0000  ...  -0.0000 -0.0357  0.0623\n",
      "  0.0028  0.0000  0.0000  ...  -0.0000 -0.0399  0.0226\n",
      "           ...                          ...          \n",
      "  0.0039  0.0000  0.0000  ...  -1.2637 -0.0044 -0.0356\n",
      "  0.0000  0.0002  0.0000  ...  -0.0081 -0.0000 -0.0000\n",
      "  0.0009  0.0002  0.0000  ...  -0.5963 -0.0397  0.0761\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0000  0.0021  0.0366  ...  -0.0040 -0.0000 -0.1216\n",
      "  0.0000  0.7643  0.0005  ...  -0.0000 -0.0155 -0.0136\n",
      "  0.0001  0.0011  0.0000  ...  -0.0000 -0.0564  0.0463\n",
      "           ...                          ...          \n",
      "  0.0012  0.0001  0.1240  ...  -0.0058 -0.0046 -0.0394\n",
      "  0.0000  0.0002  0.0000  ...  -0.0006 -0.0000 -0.0000\n",
      "  0.0070  0.0000  0.0000  ...  -0.0000 -0.0513  0.1025\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0000  0.9963  0.0000  ...  -0.0000  0.0000 -0.0501\n",
      "  0.0000  0.0000  0.6317  ...  -0.0000  0.0192 -0.0735\n",
      "  0.0001  0.0200  0.0000  ...  -0.0000 -0.0396  0.0609\n",
      "           ...                          ...          \n",
      "  0.0001 -0.0000  0.0000  ...  -1.3278  0.0123 -0.0478\n",
      "  0.0000  0.0004  0.0000  ...  -0.0109 -0.0000 -0.0000\n",
      "  0.0001  0.0115  0.0000  ...  -0.0001 -0.0675  0.0932\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0000 -0.0000  0.0005  ...  -0.3029 -0.0000  0.0266\n",
      "  0.0000  0.0000  0.0095  ...  -0.0000  0.0362 -0.0454\n",
      "  0.0001  0.0000  0.0000  ...  -0.0000 -0.0208  0.0074\n",
      "           ...                          ...          \n",
      "  0.0024  0.0000  0.0039  ...  -0.7287 -0.0299 -0.0427\n",
      "  0.0000  0.1301  0.0000  ...  -0.0078 -0.0000 -0.0000\n",
      "  0.0002  0.0011  0.0000  ...  -0.0000  0.0051  0.0008\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0000 -0.0000  0.0002  ...  -0.0001 -0.0000  0.0114\n",
      "  0.0000  0.0001  0.0000  ...  -0.0000  0.0308 -0.0523\n",
      "  0.0000 -0.0000  0.0000  ...  -0.0000 -0.0042 -0.0159\n",
      "           ...                          ...          \n",
      "  0.0182  0.0000  0.0202  ...  -0.0014 -0.0210 -0.0477\n",
      "  0.0000  0.0002  0.0000  ...  -1.3542 -0.0000 -0.0000\n",
      "  0.0006  0.2445  0.0000  ...  -0.0000  0.0395 -0.0170\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0000  0.0193  0.0201  ...  -0.9687 -0.0000 -0.0029\n",
      "  0.0000  0.0004  0.9529  ...  -0.0000  0.0129 -0.0700\n",
      "  0.0000  0.0012  0.0000  ...  -0.0000 -0.0662 -0.0316\n",
      "           ...                          ...          \n",
      "  0.0000  0.0003  0.9214  ...  -0.0000 -0.0213 -0.0217\n",
      "  0.0000  0.0003  0.0000  ...  -0.1512  0.0000 -0.0000\n",
      "  0.0169  0.0024  0.0000  ...  -0.0043  0.0561 -0.0295\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0257  0.0090 -0.0000  ...   0.0027 -0.0106  0.0000\n",
      " -1.2202 -0.0271 -0.1047  ...  -0.0340  0.0378  0.0181\n",
      " -0.0001  0.0099 -0.0079  ...   0.0259  0.0438  0.0131\n",
      "           ...                          ...          \n",
      " -0.0000  0.0085  0.0000  ...  -0.0027 -0.0000  0.0195\n",
      " -0.0145 -0.0072  0.0075  ...  -0.0000 -0.0473 -0.0096\n",
      " -0.0000  0.0013 -0.0122  ...   0.0294  0.0000 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0299 -0.0044 -0.0000  ...   0.0136 -0.0190  0.0000\n",
      " -0.0023 -0.0080 -0.1306  ...  -0.0133  0.0642  0.0274\n",
      " -1.1731 -0.0013  0.0755  ...   0.0149  0.0389  0.0123\n",
      "           ...                          ...          \n",
      " -0.0000  0.0105  0.0000  ...  -0.0002 -0.0000  0.0189\n",
      " -0.0002  0.0029 -0.0726  ...   0.0000  0.0033  0.0224\n",
      " -0.0000 -0.0029 -0.0182  ...   0.0142  0.0000  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0002 -0.0066 -0.0000  ...   0.0188  0.0062  0.0000\n",
      " -0.0000 -0.0037 -0.0209  ...  -0.0188  0.0251  0.0047\n",
      " -0.0011  0.0000 -0.0420  ...   0.0070  0.0053  0.0180\n",
      "           ...                          ...          \n",
      " -0.0000  0.0001  0.0000  ...  -0.0091 -0.0000 -0.0002\n",
      " -0.0001 -0.0011 -0.0333  ...   0.0000  0.0093  0.0536\n",
      " -0.0235 -0.0142 -0.0269  ...   0.0266  0.0000  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0003  0.0026  0.0000  ...  -0.0077  0.0462  0.0000\n",
      " -0.0000 -0.0041 -0.0034  ...  -0.0130 -0.0282  0.0314\n",
      " -0.0005  0.0004 -0.0472  ...   0.0093  0.0321 -0.0159\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0008 -0.0000  ...   0.0022  0.0000  0.0081\n",
      " -0.0017 -0.0120 -0.1306  ...   0.0000  0.0413  0.0158\n",
      " -0.0000 -0.0116  0.0684  ...  -0.0045 -0.0000  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0012 -0.0077  0.0000  ...  -0.0009  0.0594  0.0000\n",
      " -1.3501 -0.0214 -0.1534  ...  -0.0145  0.0011  0.0794\n",
      " -0.0000  0.0099 -0.0117  ...  -0.0018  0.0269 -0.0035\n",
      "           ...                          ...          \n",
      " -0.0000  0.0034 -0.0000  ...  -0.0085  0.0000  0.0291\n",
      " -0.0000 -0.0075 -0.0367  ...   0.0000 -0.0079 -0.0051\n",
      " -0.0033 -0.0114  0.0155  ...   0.0038  0.0000  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.6560 -0.0079 -0.0000  ...   0.0083  0.0397  0.0000\n",
      " -0.0000 -0.0068 -0.0367  ...  -0.0106 -0.0132  0.0361\n",
      " -0.1758  0.0037  0.0020  ...  -0.0024 -0.0007  0.0183\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0041 -0.0000  ...   0.0042  0.0000  0.0323\n",
      " -0.0145  0.0017 -0.0076  ...   0.0000  0.0059  0.0115\n",
      " -1.1529 -0.0076 -0.1067  ...   0.0081  0.0000  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.5007e-01 -3.9233e-03 -1.2537e-01  ...  -1.1582e-02  2.3797e-03  3.4176e-04\n",
      "  8.8220e-02 -5.4157e-04 -1.2042e-03  ...   6.1992e-02  3.3515e-05  3.7611e-06\n",
      "  2.1642e-01  1.1742e-02 -1.8618e-01  ...  -7.1516e-02 -3.9559e-03  6.7731e-02\n",
      "                 ...                                      ...                \n",
      " -2.0579e-01 -5.4804e-02 -3.1761e-01  ...   9.7938e-02 -4.9151e-03  1.4313e-02\n",
      "  4.6965e-01  3.5431e-02  1.3274e-01  ...  -2.6576e-03 -1.6544e-02  1.2193e-02\n",
      " -4.5603e-02  8.8274e-03 -6.1177e-02  ...   1.7962e-03 -1.8982e-02 -1.4366e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  4.9447e-02  1.0570e-02  2.6900e-01  ...  -4.0175e-02 -2.2911e-02  2.0647e-02\n",
      "  6.7036e-02 -2.5384e-03 -1.1888e-02  ...  -3.9347e-02 -4.7563e-03  2.6642e-02\n",
      "  2.9913e-01 -3.1825e-02 -3.3787e-01  ...  -1.6100e-02 -4.6460e-03 -1.6481e-05\n",
      "                 ...                                      ...                \n",
      " -4.1466e-02 -1.9865e-03 -6.5820e-02  ...   2.1055e-02 -3.4320e-02  1.1387e-01\n",
      "  2.4648e-01  9.4635e-02 -7.4413e-02  ...  -1.4906e-02  1.5546e-02  8.0401e-04\n",
      " -1.2927e-01  1.0032e-01  1.9415e-02  ...   4.1227e-02  3.2273e-02  3.2029e-03\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  6.1127e-02  1.2628e-02 -3.1194e-01  ...  -4.1335e-02 -1.3702e-02  7.2955e-03\n",
      "  1.5450e-01  6.2654e-03 -5.2458e-03  ...  -2.6627e-03 -6.7941e-03  1.4321e-02\n",
      "  8.0016e-02 -1.7059e-02 -1.7744e-01  ...  -1.7682e-01 -6.3788e-02  4.7370e-02\n",
      "                 ...                                      ...                \n",
      "  1.4909e-01 -4.1967e-04 -5.4231e-01  ...   2.1273e-02 -7.1636e-02  1.4256e-02\n",
      "  1.1469e-01  5.4345e-03 -2.6780e-01  ...  -2.0987e-02 -1.2354e-01  6.2344e-02\n",
      " -1.5840e-02  3.7770e-03  1.8043e-01  ...   1.9532e-02  2.6263e-02  1.2759e-02\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  2.4893e-03  1.1392e-02  3.0844e-02  ...   2.0083e-01 -1.7275e-01  1.0277e-01\n",
      " -3.3577e-01  9.9914e-03 -3.0608e-01  ...   1.3754e-01  2.0519e-03  5.0360e-03\n",
      "  1.9670e-01  7.9753e-03 -5.5472e-02  ...  -5.7274e-02  4.3796e-02  2.3585e-02\n",
      "                 ...                                      ...                \n",
      " -9.6455e-03  1.1611e-03 -4.3595e-01  ...   2.9749e-02 -3.0736e-02  4.5368e-01\n",
      "  7.6596e-03 -1.9856e-03  9.4631e-03  ...   4.1872e-02 -2.0021e-02  3.3061e-01\n",
      " -1.0786e-01  6.3168e-02 -3.5519e-01  ...   4.7773e-01 -3.1654e-04  4.9277e-03\n",
      "\n",
      "(68 ,.,.) = \n",
      "  2.6420e-04  1.0306e-01 -3.7198e-02  ...   1.5882e-01 -3.3273e-03  1.8211e-01\n",
      "  2.3911e-01 -1.0710e-02 -1.5870e-02  ...   7.2069e-02 -3.2484e-05  5.4133e-06\n",
      " -8.8345e-02  8.3076e-02 -2.4022e-02  ...  -2.4988e-01  5.6701e-04  6.7572e-04\n",
      "                 ...                                      ...                \n",
      " -1.3517e-01  7.0139e-02  1.8686e-01  ...   3.6414e-02  1.3659e-02  6.0769e-03\n",
      " -4.9994e-02  3.8005e-02 -1.0079e-02  ...   2.6195e-02 -9.5275e-03  8.7477e-02\n",
      " -1.1970e-02 -2.5144e-02 -3.2325e-01  ...   8.7948e-02 -1.4940e-02  6.2460e-03\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.4116e-02 -3.2243e-03 -2.5592e-01  ...   2.3244e-02 -1.1272e-03  5.1498e-04\n",
      "  1.6944e-01  1.9436e-02  3.7552e-03  ...  -1.8625e-01  1.8164e-03  3.4918e-02\n",
      " -4.6270e-02 -5.5291e-03 -3.4572e-01  ...  -2.3751e-01  4.1136e-03  6.6137e-04\n",
      "                 ...                                      ...                \n",
      " -2.7550e-01  2.1953e-02 -3.5236e-01  ...   7.1016e-03  1.2123e-02  3.4008e-03\n",
      " -1.3776e-01 -8.1257e-03 -8.1126e-02  ...   1.0950e-01 -4.5950e-02  7.1150e-02\n",
      "  1.6816e-02 -4.2128e-02 -1.4471e-01  ...   1.4225e-01 -1.4301e-03  2.0770e-04\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.0000  0.0000  0.3632  ...  -0.0000 -0.0000 -0.0272\n",
      "  0.0001  0.0000  0.0010  ...  -0.0000 -0.0106  0.0041\n",
      "  0.0003  0.0000  0.0000  ...  -1.4004 -0.0000 -0.0317\n",
      "           ...                          ...          \n",
      "  0.0031 -0.0000  0.0034  ...  -0.0000  0.0000 -0.0293\n",
      "  0.0142 -0.0039  0.0000  ...  -1.2858 -0.0000  0.0000\n",
      "  0.0003  0.0012  0.8748  ...  -1.0814  0.0309 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0003 -0.0000  0.0000  ...  -0.0000 -0.0000 -0.0114\n",
      "  0.0000  0.5775  0.0122  ...  -0.0000 -0.0870  0.0328\n",
      "  0.0061  0.0000  0.0000  ...  -0.8514 -0.0000 -0.0499\n",
      "           ...                          ...          \n",
      "  0.0044  0.0000 -0.1794  ...  -0.0000  0.0000 -0.0409\n",
      "  0.0099  0.2637  0.0000  ...  -0.0049 -0.0000  0.0000\n",
      "  0.0468  0.0000  0.7021  ...  -0.0011  0.0234 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0016  0.0000  0.2017  ...  -0.0000 -0.0000 -0.0269\n",
      "  0.0000  0.0000  0.9095  ...  -0.0000 -0.0781  0.0384\n",
      "  0.0155  0.0007  0.0000  ...  -0.5025  0.0000  0.0097\n",
      "           ...                          ...          \n",
      "  0.1845  0.0005 -0.0000  ...  -0.0000  0.0000 -0.0016\n",
      "  0.0438  0.0003  0.0000  ...  -0.0197 -0.0000  0.0000\n",
      "  0.0016  0.0000  0.5994  ...  -0.0000 -0.0506 -0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  0.0187  0.0018  0.1520  ...  -0.0000 -0.0000  0.1545\n",
      "  0.0527  0.0001  0.0735  ...  -0.0000 -0.0357  0.0418\n",
      "  0.0211  0.0001  0.0000  ...  -0.0109 -0.0000  0.0152\n",
      "           ...                          ...          \n",
      "  0.0002  0.0000  0.0144  ...  -0.0000 -0.0000 -0.0880\n",
      "  0.0007 -0.0000  0.0000  ...  -1.2687  0.0000 -0.0000\n",
      "  0.0029  0.0000 -0.0001  ...  -0.0073 -0.0502  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      "  0.0187  0.0018  0.1520  ...  -0.0000 -0.0000  0.1546\n",
      "  0.0527  0.0001  0.0735  ...  -0.0000 -0.0358  0.0417\n",
      "  0.0352  0.0002  0.0000  ...  -0.0118 -0.0000  0.0307\n",
      "           ...                          ...          \n",
      "  0.0004  0.0005  0.9741  ...  -0.0000 -0.0000 -0.0778\n",
      "  0.0042  0.0000 -0.1087  ...  -0.1758 -0.0000 -0.0000\n",
      "  0.0100  0.0106  0.0000  ...  -0.0001 -0.0409 -0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      "  0.0187  0.0018  0.1519  ...  -0.0000 -0.0000  0.1546\n",
      "  0.0526  0.0001  0.0734  ...  -0.0000 -0.0359  0.0417\n",
      "  0.0319  0.0001  0.0000  ...  -0.0133 -0.0000  0.0411\n",
      "           ...                          ...          \n",
      "  0.0000 -0.0001  0.0022  ...  -0.0000 -0.0000 -0.0566\n",
      "  0.1621 -0.0000 -0.0000  ...  -1.2932 -0.0000 -0.0000\n",
      "  0.0004  0.0350  0.0000  ...  -1.1374 -0.0858 -0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0000 -0.0094 -0.0269  ...  -0.0042  0.0144  0.0000\n",
      " -0.0068  0.0000 -0.0000  ...  -0.0000 -0.0000  0.0221\n",
      " -0.0000 -0.0042 -0.0150  ...   0.0008 -0.0000 -0.0030\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0033  0.0026  ...  -0.0081  0.0009  0.0084\n",
      " -0.0000 -0.0000 -0.0000  ...   0.0140 -0.0000 -0.0000\n",
      " -0.0008 -0.0000 -0.0523  ...   0.0000  0.0186 -0.0000\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0000 -0.0041 -0.0023  ...  -0.0148 -0.0067  0.0000\n",
      " -1.4127  0.0000 -0.0000  ...   0.0000  0.0000  0.0168\n",
      " -0.0716  0.0013  0.0090  ...   0.0061 -0.0000 -0.0137\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0006  0.0107  ...  -0.0061 -0.0028  0.0185\n",
      " -0.0006  0.0000  0.0000  ...   0.0080 -0.0000 -0.0000\n",
      " -0.0000  0.0000 -0.0111  ...  -0.0000  0.0249 -0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0000 -0.0018  0.0193  ...  -0.0047 -0.0033  0.0000\n",
      " -0.4837  0.0000  0.0000  ...   0.0000  0.0000  0.0039\n",
      " -0.0149  0.0083  0.0243  ...   0.0103 -0.0000 -0.0312\n",
      "           ...                          ...          \n",
      " -0.0000  0.0089  0.0275  ...  -0.0003  0.0287  0.0062\n",
      " -0.0000  0.0000  0.0000  ...  -0.0072 -0.0000 -0.0000\n",
      " -0.0031 -0.0000  0.0133  ...   0.0000  0.0410  0.0000\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      " -0.0000  0.0084 -0.0639  ...   0.0173 -0.0321 -0.0000\n",
      " -0.0112  0.0000 -0.0000  ...  -0.0000 -0.0000  0.0131\n",
      " -0.0099  0.0024  0.0038  ...   0.0061 -0.0000 -0.0166\n",
      "           ...                          ...          \n",
      " -0.0000  0.0052 -0.0042  ...   0.0113 -0.0075  0.0182\n",
      " -0.0004  0.0000 -0.0000  ...  -0.0050 -0.0000 -0.0000\n",
      " -0.0000  0.0000 -0.0038  ...  -0.0000  0.0034  0.0000\n",
      "\n",
      "(68 ,.,.) = \n",
      " -0.0000  0.0085 -0.0639  ...   0.0173 -0.0320 -0.0000\n",
      " -0.0112  0.0000 -0.0000  ...  -0.0000 -0.0000  0.0130\n",
      " -0.0058  0.0029  0.0052  ...   0.0051 -0.0000 -0.0208\n",
      "           ...                          ...          \n",
      " -0.0000  0.0015 -0.0118  ...   0.0067  0.0130  0.0203\n",
      " -0.0002  0.0000  0.0000  ...   0.0016 -0.0000  0.0000\n",
      " -1.4063  0.0000 -0.0119  ...  -0.0000  0.0387  0.0000\n",
      "\n",
      "(69 ,.,.) = \n",
      " -0.0000  0.0085 -0.0639  ...   0.0173 -0.0320 -0.0000\n",
      " -0.0112  0.0000 -0.0000  ...  -0.0000 -0.0000  0.0128\n",
      " -0.0055  0.0030  0.0068  ...   0.0035 -0.0000 -0.0237\n",
      "           ...                          ...          \n",
      " -0.0000  0.0002  0.0067  ...   0.0037  0.0005  0.0072\n",
      " -0.0000 -0.0000 -0.0000  ...   0.0015 -0.0000  0.0000\n",
      " -0.0177  0.0000  0.0041  ...   0.0000  0.0127  0.0000\n",
      "[torch.cuda.FloatTensor of size 70x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  4.6810e-02 -8.0143e-04 -2.0131e-01  ...  -7.0283e-03 -5.5197e-02  2.3022e-01\n",
      "  6.6318e-02  8.8012e-03  2.0423e-02  ...   4.8714e-02 -1.0389e-02  8.9417e-03\n",
      "  7.1284e-02  1.7528e-01 -1.8494e-01  ...  -1.2434e-01 -7.8405e-03 -7.7449e-03\n",
      "                 ...                                      ...                \n",
      " -2.0180e-02  9.3913e-02 -1.9303e-01  ...  -1.9430e-01 -8.6784e-02  5.0559e-02\n",
      " -2.5890e-01  3.2013e-02 -1.1377e-01  ...   8.5875e-02 -1.0015e-02  2.3544e-03\n",
      "  4.8681e-02 -5.3771e-03 -2.5690e-03  ...   9.4083e-03 -1.9729e-01  4.1399e-02\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -5.5251e-04  1.2032e-01 -1.0659e-01  ...  -5.9082e-02 -3.3473e-02  7.5738e-03\n",
      "  2.6210e-01 -1.0747e-02 -1.4286e-01  ...   1.1626e-02 -2.7735e-04  4.3424e-04\n",
      " -2.1099e-01  2.9209e-02 -3.0215e-01  ...  -8.1930e-02 -3.0691e-02  5.1943e-02\n",
      "                 ...                                      ...                \n",
      "  2.4886e-02  1.5471e-02 -3.1065e-01  ...  -1.8018e-01 -6.7470e-02  7.0448e-02\n",
      " -1.3204e-02  1.0927e-02 -4.3342e-01  ...   2.0461e-02  7.3875e-04  3.6761e-04\n",
      " -1.2729e-01  2.9228e-02  4.5523e-01  ...   3.8955e-02 -4.3999e-03  2.6635e-02\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -1.0287e-01  2.0691e-03 -2.3833e-01  ...   2.7038e-02 -1.3375e-01  4.8239e-02\n",
      "  7.4673e-02  4.9289e-03 -1.1334e-01  ...  -5.7921e-02 -1.1926e-01  4.3608e-02\n",
      " -1.1441e-01  8.6889e-02 -1.8826e-01  ...   1.1444e-01 -1.1860e-01  1.5678e-01\n",
      "                 ...                                      ...                \n",
      " -1.0607e-01  1.3450e-02 -3.1233e-01  ...  -1.3750e-01 -1.0915e-01  1.6639e-01\n",
      " -3.6431e-02  3.1620e-03  1.8624e-02  ...  -3.7784e-02 -2.7818e-02  4.1885e-01\n",
      "  4.7372e-02 -1.7983e-02  4.3466e-01  ...   9.7553e-03 -1.4136e-02  7.6204e-03\n",
      "... \n",
      "\n",
      "(67 ,.,.) = \n",
      "  8.8869e-04  1.0128e-02  2.7860e-01  ...   2.3755e-04 -2.0381e-01  3.5165e-02\n",
      " -9.8483e-04  1.7595e-02  2.4545e-02  ...   1.3082e-01 -4.8396e-01  9.1366e-02\n",
      " -4.8615e-03  2.5228e-02 -3.8569e-02  ...  -3.2182e-02 -3.4219e-01  7.9342e-02\n",
      "                 ...                                      ...                \n",
      "  8.9315e-04 -1.7920e-02  3.4067e-02  ...   1.1860e-01 -1.9892e-01  4.9193e-01\n",
      "  7.0519e-02 -1.0177e-02 -1.4665e-02  ...   3.2858e-03 -2.4826e-03  5.8009e-04\n",
      " -1.9463e-01  1.5009e-01  4.0158e-02  ...  -4.9869e-02  3.3574e-02  1.3038e-02\n",
      "\n",
      "(68 ,.,.) = \n",
      "  1.2080e-03  1.0514e-02  2.8285e-01  ...   1.1630e-04 -2.0329e-01  3.4506e-02\n",
      " -9.3445e-04  1.9054e-02  2.7753e-02  ...   1.2592e-01 -4.8382e-01  9.9283e-02\n",
      "  1.7643e-03  1.8963e-02 -1.1122e-02  ...  -1.3097e-03 -4.3992e-01  1.3111e-01\n",
      "                 ...                                      ...                \n",
      " -1.5638e-02 -1.4695e-02 -1.5708e-01  ...  -3.4448e-03 -2.5447e-01  8.5149e-02\n",
      "  9.7030e-02 -2.4791e-02  4.9062e-02  ...   1.7572e-03 -5.4737e-01 -3.2889e-03\n",
      "  2.5494e-02 -9.1265e-02 -6.9796e-03  ...   1.0574e-02  1.1076e-03  3.5262e-04\n",
      "\n",
      "(69 ,.,.) = \n",
      "  1.5475e-03  1.0818e-02  2.8827e-01  ...  -4.1436e-05 -2.0184e-01  3.3675e-02\n",
      " -8.3687e-04  2.0750e-02  2.8521e-02  ...   1.1950e-01 -4.8048e-01  1.0683e-01\n",
      "  3.2813e-03  1.7565e-02 -1.1847e-02  ...   6.5312e-03 -4.3888e-01  1.6331e-01\n",
      "                 ...                                      ...                \n",
      "  7.7831e-02  1.6373e-03 -1.9361e-01  ...  -2.1467e-01 -1.7487e-01  1.6832e-02\n",
      " -2.7432e-01 -3.3546e-03 -2.8677e-01  ...   4.8779e-03 -3.5981e-01  1.6548e-03\n",
      "  6.9909e-02  3.2317e-02 -2.2425e-02  ...  -4.6851e-02  6.5533e-02  3.1457e-02\n",
      "[torch.cuda.FloatTensor of size 70x8x200 (GPU 0)]\n",
      "], [Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.1249  0.0000  0.2455  ...  -0.0927 -0.0593  0.1775\n",
      "  0.0143  0.0001  0.0000  ...  -0.0277 -0.0340  0.0000\n",
      "  0.0120 -0.0011  0.2021  ...  -0.0169 -0.0000  0.0656\n",
      "           ...                          ...          \n",
      "  0.0003 -0.0000  0.0917  ...  -0.0000  0.0207 -0.0000\n",
      "  0.8671  0.0000 -0.4425  ...  -0.0000 -0.0000  0.0081\n",
      "  0.0002  0.0000  0.9481  ...  -0.0001 -0.0532 -0.0184\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0887  0.0000  0.2375  ...  -0.1685 -0.0348  0.1430\n",
      "  0.0182 -0.0020  0.0000  ...  -0.0344 -0.0296  0.0000\n",
      "  0.0131 -0.0018  0.2130  ...  -0.0454 -0.0000  0.0941\n",
      "           ...                          ...          \n",
      "  0.0051  0.0000  0.0000  ...  -0.0000  0.0030 -0.0000\n",
      "  0.0005  0.0000  0.1727  ...  -0.0000 -0.0000 -0.0820\n",
      "  0.0058  0.0000 -0.0454  ...  -0.0000 -0.0018 -0.0587\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0642  0.0000  0.1595  ...  -0.1557 -0.0248  0.1196\n",
      "  0.0178 -0.0019  0.0000  ...  -0.0421 -0.0234  0.0000\n",
      "  0.0124 -0.0027  0.1748  ...  -0.0395 -0.0000  0.1100\n",
      "           ...                          ...          \n",
      "  0.0005  0.0385  0.3931  ...  -0.0000 -0.0241 -0.0000\n",
      "  0.0000  0.0000  0.0023  ...  -0.0000 -0.0000 -0.0362\n",
      "  0.0010  0.0000  0.2332  ...  -0.0375 -0.0023 -0.0578\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0222  0.0004  0.3612  ...  -0.0000 -0.0498  0.0000\n",
      "  0.0137  0.0000  0.2506  ...  -0.0000 -0.0000  0.0664\n",
      "  0.0000 -0.0000 -0.0000  ...  -1.3245 -0.0058 -0.0298\n",
      "\n",
      "(50 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0224  0.0004  0.3600  ...  -0.0000 -0.0506  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0709\n",
      "  0.0000  0.0000  0.0000  ...  -1.3336 -0.0313 -0.0776\n",
      "\n",
      "(51 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0226  0.0004  0.3599  ...  -0.0000 -0.0511  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0741\n",
      "  0.0004  0.0000  0.0797  ...  -0.3190 -0.0678 -0.1082\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0041  0.0000 -0.0066  ...   0.0000 -0.0316 -0.0000\n",
      " -0.0000  0.0093 -0.0706  ...   0.0003 -0.0050  0.0000\n",
      " -0.0030  0.0117  0.0114  ...   0.0000 -0.0014  0.0019\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0000  0.0112  0.0000\n",
      " -0.0000  0.0000 -0.0038  ...   0.0010 -0.0161 -0.0123\n",
      " -0.0050  0.0036 -0.0671  ...   0.0041 -0.0285  0.0513\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0043  0.0000 -0.0346  ...   0.0000 -0.0296 -0.0000\n",
      " -0.0000  0.0107 -0.0539  ...  -0.0030 -0.0086  0.0000\n",
      " -0.0021  0.0154  0.0071  ...   0.0000  0.0029  0.0086\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000 -0.0000  ...  -0.0000  0.0351  0.0000\n",
      " -0.0000  0.0000  0.0059  ...   0.0065  0.0173 -0.0124\n",
      " -0.0013 -0.0006  0.0555  ...  -0.0209 -0.0348  0.0121\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0049  0.0000 -0.0462  ...   0.0000 -0.0268 -0.0000\n",
      " -0.0000  0.0108 -0.0426  ...  -0.0023 -0.0128  0.0000\n",
      " -0.0029  0.0170  0.0068  ...   0.0000  0.0049  0.0105\n",
      "           ...                          ...          \n",
      " -0.0004  0.0000 -0.0000  ...   0.0000  0.0588  0.0000\n",
      " -0.0000  0.0000 -0.0009  ...   0.0089  0.0156 -0.0386\n",
      " -0.0002 -0.0059  0.0316  ...  -0.0087 -0.0378 -0.0007\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0129 -0.0000\n",
      " -0.0000  0.0000 -0.0210  ...   0.0050 -0.0122  0.0085\n",
      " -0.0000 -0.0048  0.0163  ...  -0.0030 -0.0220 -0.0098\n",
      "\n",
      "(50 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0122 -0.0000\n",
      " -0.0000  0.0000 -0.0216  ...   0.0051 -0.0122  0.0090\n",
      " -0.0021 -0.0082  0.0004  ...   0.0030 -0.0171 -0.0054\n",
      "\n",
      "(51 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0118 -0.0000\n",
      " -0.0000  0.0000 -0.0217  ...   0.0051 -0.0121  0.0094\n",
      " -0.0008  0.0028 -0.0395  ...   0.0029  0.0148  0.0248\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.2458e-03  8.7113e-03  1.5615e-01  ...   1.0511e-03 -3.4246e-02  9.3160e-02\n",
      "  1.6440e-03  1.5580e-02  6.5035e-02  ...  -3.5910e-02 -8.1517e-02  5.3498e-02\n",
      "  5.6775e-03  3.0201e-03 -4.4422e-02  ...  -2.3107e-02 -1.9810e-01  4.6526e-02\n",
      "                 ...                                      ...                \n",
      "  3.2747e-02  2.5253e-02 -8.8830e-02  ...  -6.9768e-02 -4.7884e-02  3.3285e-04\n",
      " -1.5779e-01  1.2834e-01 -1.9318e-01  ...  -9.2916e-02 -5.2056e-04  1.5515e-03\n",
      " -4.2371e-02  9.6233e-03  6.4710e-02  ...  -5.8583e-02  2.4529e-02  1.2164e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.7982e-03  3.9203e-03  1.3109e-01  ...   1.2617e-02 -4.4666e-03  9.5297e-02\n",
      "  5.4326e-03  8.8408e-03 -2.5101e-02  ...  -1.1051e-01 -7.1092e-03  5.7667e-02\n",
      "  8.5618e-03  2.8817e-03 -9.3897e-02  ...  -7.7938e-02 -1.2714e-01  5.6355e-02\n",
      "                 ...                                      ...                \n",
      " -3.8636e-02  8.6608e-04  1.2561e-01  ...  -5.3316e-03 -2.6278e-02  1.5395e-02\n",
      "  8.8907e-02  2.4031e-02  1.7218e-01  ...  -3.1122e-02 -9.2906e-04  2.1702e-04\n",
      " -4.8558e-02  1.2444e-02 -4.2940e-02  ...  -9.8066e-02 -1.1404e-01  1.8107e-05\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  9.1112e-03  4.1698e-03  1.0478e-01  ...   2.8698e-02 -1.6538e-02  9.7076e-02\n",
      "  1.0099e-02  8.4244e-03 -3.8806e-02  ...  -1.0868e-01 -2.4257e-03  5.2825e-02\n",
      "  1.0661e-02  2.8269e-03 -1.0834e-01  ...  -1.0367e-01 -6.5392e-02  5.1589e-02\n",
      "                 ...                                      ...                \n",
      " -9.5537e-03  1.1279e-01  1.1044e-02  ...  -2.6348e-02  8.2377e-02  8.5361e-03\n",
      "  3.5080e-02  6.9985e-02 -1.6682e-01  ...   3.0933e-01  9.0400e-02  1.9465e-03\n",
      " -3.4016e-02  7.0110e-04  2.3338e-01  ...   3.7035e-03 -1.0715e-01  3.3775e-03\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  1.5787e-01  4.0386e-03 -2.9706e-01  ...  -4.3813e-01  8.6774e-03  1.1279e-02\n",
      "  7.6055e-02  6.7669e-03 -2.8087e-01  ...  -4.7266e-01 -1.1756e-03  2.2558e-02\n",
      "  1.6703e-02  1.1379e-02 -9.5844e-02  ...  -1.0695e-01  2.7542e-02  5.9055e-02\n",
      "                 ...                                      ...                \n",
      " -5.4963e-03  2.7957e-02 -2.6366e-02  ...   2.2478e-02  5.6376e-02  4.2229e-02\n",
      "  5.7358e-02  1.3850e-02 -1.5816e-01  ...  -1.6360e-01 -1.0346e-01  2.7932e-02\n",
      "  2.6478e-02  9.7819e-02 -9.1238e-02  ...  -2.4474e-01 -6.2434e-02  1.0283e-01\n",
      "\n",
      "(50 ,.,.) = \n",
      "  1.6388e-01  4.0558e-03 -2.9706e-01  ...  -4.4597e-01  8.7005e-03  1.1049e-02\n",
      "  7.5816e-02  6.7876e-03 -2.8027e-01  ...  -4.7485e-01 -1.4158e-03  2.2351e-02\n",
      "  1.6601e-02  1.1464e-02 -9.6398e-02  ...  -1.0686e-01  2.7614e-02  5.9635e-02\n",
      "                 ...                                      ...                \n",
      " -5.8475e-03  2.9788e-02 -2.1429e-02  ...   2.0583e-02  6.1296e-02  3.9498e-02\n",
      "  6.6094e-02  1.1282e-02 -1.5613e-01  ...  -1.9974e-01 -1.0232e-01  2.5547e-02\n",
      "  1.2053e-02  2.5828e-02 -5.2196e-02  ...  -4.4959e-01 -3.7889e-02  3.0552e-03\n",
      "\n",
      "(51 ,.,.) = \n",
      "  1.7001e-01  4.0707e-03 -2.9688e-01  ...  -4.5330e-01  8.7054e-03  1.0785e-02\n",
      "  7.5572e-02  6.8114e-03 -2.7961e-01  ...  -4.7690e-01 -1.6539e-03  2.2175e-02\n",
      "  1.6497e-02  1.1545e-02 -9.7006e-02  ...  -1.0669e-01  2.7689e-02  6.0170e-02\n",
      "                 ...                                      ...                \n",
      " -6.0868e-03  3.1388e-02 -1.1914e-02  ...   1.9073e-02  6.4154e-02  3.7929e-02\n",
      "  7.4657e-02  9.6033e-03 -1.5607e-01  ...  -2.4294e-01 -1.0464e-01  2.5088e-02\n",
      "  6.0126e-04  4.1605e-05  4.3443e-01  ...   1.2659e-01 -5.3086e-02  3.6345e-03\n",
      "[torch.cuda.FloatTensor of size 52x8x200 (GPU 0)]\n",
      "]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> outputs[-1]\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.1249  0.0000  0.2455  ...  -0.0927 -0.0593  0.1775\n",
      "  0.0143  0.0001  0.0000  ...  -0.0277 -0.0340  0.0000\n",
      "  0.0120 -0.0011  0.2021  ...  -0.0169 -0.0000  0.0656\n",
      "           ...                          ...          \n",
      "  0.0003 -0.0000  0.0917  ...  -0.0000  0.0207 -0.0000\n",
      "  0.8671  0.0000 -0.4425  ...  -0.0000 -0.0000  0.0081\n",
      "  0.0002  0.0000  0.9481  ...  -0.0001 -0.0532 -0.0184\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0887  0.0000  0.2375  ...  -0.1685 -0.0348  0.1430\n",
      "  0.0182 -0.0020  0.0000  ...  -0.0344 -0.0296  0.0000\n",
      "  0.0131 -0.0018  0.2130  ...  -0.0454 -0.0000  0.0941\n",
      "           ...                          ...          \n",
      "  0.0051  0.0000  0.0000  ...  -0.0000  0.0030 -0.0000\n",
      "  0.0005  0.0000  0.1727  ...  -0.0000 -0.0000 -0.0820\n",
      "  0.0058  0.0000 -0.0454  ...  -0.0000 -0.0018 -0.0587\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0642  0.0000  0.1595  ...  -0.1557 -0.0248  0.1196\n",
      "  0.0178 -0.0019  0.0000  ...  -0.0421 -0.0234  0.0000\n",
      "  0.0124 -0.0027  0.1748  ...  -0.0395 -0.0000  0.1100\n",
      "           ...                          ...          \n",
      "  0.0005  0.0385  0.3931  ...  -0.0000 -0.0241 -0.0000\n",
      "  0.0000  0.0000  0.0023  ...  -0.0000 -0.0000 -0.0362\n",
      "  0.0010  0.0000  0.2332  ...  -0.0375 -0.0023 -0.0578\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0222  0.0004  0.3612  ...  -0.0000 -0.0498  0.0000\n",
      "  0.0137  0.0000  0.2506  ...  -0.0000 -0.0000  0.0664\n",
      "  0.0000 -0.0000 -0.0000  ...  -1.3245 -0.0058 -0.0298\n",
      "\n",
      "(50 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0224  0.0004  0.3600  ...  -0.0000 -0.0506  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0709\n",
      "  0.0000  0.0000  0.0000  ...  -1.3336 -0.0313 -0.0776\n",
      "\n",
      "(51 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0226  0.0004  0.3599  ...  -0.0000 -0.0511  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0741\n",
      "  0.0004  0.0000  0.0797  ...  -0.3190 -0.0678 -0.1082\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0041  0.0000 -0.0066  ...   0.0000 -0.0316 -0.0000\n",
      " -0.0000  0.0093 -0.0706  ...   0.0003 -0.0050  0.0000\n",
      " -0.0030  0.0117  0.0114  ...   0.0000 -0.0014  0.0019\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0000  0.0112  0.0000\n",
      " -0.0000  0.0000 -0.0038  ...   0.0010 -0.0161 -0.0123\n",
      " -0.0050  0.0036 -0.0671  ...   0.0041 -0.0285  0.0513\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0043  0.0000 -0.0346  ...   0.0000 -0.0296 -0.0000\n",
      " -0.0000  0.0107 -0.0539  ...  -0.0030 -0.0086  0.0000\n",
      " -0.0021  0.0154  0.0071  ...   0.0000  0.0029  0.0086\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000 -0.0000  ...  -0.0000  0.0351  0.0000\n",
      " -0.0000  0.0000  0.0059  ...   0.0065  0.0173 -0.0124\n",
      " -0.0013 -0.0006  0.0555  ...  -0.0209 -0.0348  0.0121\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0049  0.0000 -0.0462  ...   0.0000 -0.0268 -0.0000\n",
      " -0.0000  0.0108 -0.0426  ...  -0.0023 -0.0128  0.0000\n",
      " -0.0029  0.0170  0.0068  ...   0.0000  0.0049  0.0105\n",
      "           ...                          ...          \n",
      " -0.0004  0.0000 -0.0000  ...   0.0000  0.0588  0.0000\n",
      " -0.0000  0.0000 -0.0009  ...   0.0089  0.0156 -0.0386\n",
      " -0.0002 -0.0059  0.0316  ...  -0.0087 -0.0378 -0.0007\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0129 -0.0000\n",
      " -0.0000  0.0000 -0.0210  ...   0.0050 -0.0122  0.0085\n",
      " -0.0000 -0.0048  0.0163  ...  -0.0030 -0.0220 -0.0098\n",
      "\n",
      "(50 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0122 -0.0000\n",
      " -0.0000  0.0000 -0.0216  ...   0.0051 -0.0122  0.0090\n",
      " -0.0021 -0.0082  0.0004  ...   0.0030 -0.0171 -0.0054\n",
      "\n",
      "(51 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0118 -0.0000\n",
      " -0.0000  0.0000 -0.0217  ...   0.0051 -0.0121  0.0094\n",
      " -0.0008  0.0028 -0.0395  ...   0.0029  0.0148  0.0248\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.2458e-03  8.7113e-03  1.5615e-01  ...   1.0511e-03 -3.4246e-02  9.3160e-02\n",
      "  1.6440e-03  1.5580e-02  6.5035e-02  ...  -3.5910e-02 -8.1517e-02  5.3498e-02\n",
      "  5.6775e-03  3.0201e-03 -4.4422e-02  ...  -2.3107e-02 -1.9810e-01  4.6526e-02\n",
      "                 ...                                      ...                \n",
      "  3.2747e-02  2.5253e-02 -8.8830e-02  ...  -6.9768e-02 -4.7884e-02  3.3285e-04\n",
      " -1.5779e-01  1.2834e-01 -1.9318e-01  ...  -9.2916e-02 -5.2056e-04  1.5515e-03\n",
      " -4.2371e-02  9.6233e-03  6.4710e-02  ...  -5.8583e-02  2.4529e-02  1.2164e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.7982e-03  3.9203e-03  1.3109e-01  ...   1.2617e-02 -4.4666e-03  9.5297e-02\n",
      "  5.4326e-03  8.8408e-03 -2.5101e-02  ...  -1.1051e-01 -7.1092e-03  5.7667e-02\n",
      "  8.5618e-03  2.8817e-03 -9.3897e-02  ...  -7.7938e-02 -1.2714e-01  5.6355e-02\n",
      "                 ...                                      ...                \n",
      " -3.8636e-02  8.6608e-04  1.2561e-01  ...  -5.3316e-03 -2.6278e-02  1.5395e-02\n",
      "  8.8907e-02  2.4031e-02  1.7218e-01  ...  -3.1122e-02 -9.2906e-04  2.1702e-04\n",
      " -4.8558e-02  1.2444e-02 -4.2940e-02  ...  -9.8066e-02 -1.1404e-01  1.8107e-05\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  9.1112e-03  4.1698e-03  1.0478e-01  ...   2.8698e-02 -1.6538e-02  9.7076e-02\n",
      "  1.0099e-02  8.4244e-03 -3.8806e-02  ...  -1.0868e-01 -2.4257e-03  5.2825e-02\n",
      "  1.0661e-02  2.8269e-03 -1.0834e-01  ...  -1.0367e-01 -6.5392e-02  5.1589e-02\n",
      "                 ...                                      ...                \n",
      " -9.5537e-03  1.1279e-01  1.1044e-02  ...  -2.6348e-02  8.2377e-02  8.5361e-03\n",
      "  3.5080e-02  6.9985e-02 -1.6682e-01  ...   3.0933e-01  9.0400e-02  1.9465e-03\n",
      " -3.4016e-02  7.0110e-04  2.3338e-01  ...   3.7035e-03 -1.0715e-01  3.3775e-03\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  1.5787e-01  4.0386e-03 -2.9706e-01  ...  -4.3813e-01  8.6774e-03  1.1279e-02\n",
      "  7.6055e-02  6.7669e-03 -2.8087e-01  ...  -4.7266e-01 -1.1756e-03  2.2558e-02\n",
      "  1.6703e-02  1.1379e-02 -9.5844e-02  ...  -1.0695e-01  2.7542e-02  5.9055e-02\n",
      "                 ...                                      ...                \n",
      " -5.4963e-03  2.7957e-02 -2.6366e-02  ...   2.2478e-02  5.6376e-02  4.2229e-02\n",
      "  5.7358e-02  1.3850e-02 -1.5816e-01  ...  -1.6360e-01 -1.0346e-01  2.7932e-02\n",
      "  2.6478e-02  9.7819e-02 -9.1238e-02  ...  -2.4474e-01 -6.2434e-02  1.0283e-01\n",
      "\n",
      "(50 ,.,.) = \n",
      "  1.6388e-01  4.0558e-03 -2.9706e-01  ...  -4.4597e-01  8.7005e-03  1.1049e-02\n",
      "  7.5816e-02  6.7876e-03 -2.8027e-01  ...  -4.7485e-01 -1.4158e-03  2.2351e-02\n",
      "  1.6601e-02  1.1464e-02 -9.6398e-02  ...  -1.0686e-01  2.7614e-02  5.9635e-02\n",
      "                 ...                                      ...                \n",
      " -5.8475e-03  2.9788e-02 -2.1429e-02  ...   2.0583e-02  6.1296e-02  3.9498e-02\n",
      "  6.6094e-02  1.1282e-02 -1.5613e-01  ...  -1.9974e-01 -1.0232e-01  2.5547e-02\n",
      "  1.2053e-02  2.5828e-02 -5.2196e-02  ...  -4.4959e-01 -3.7889e-02  3.0552e-03\n",
      "\n",
      "(51 ,.,.) = \n",
      "  1.7001e-01  4.0707e-03 -2.9688e-01  ...  -4.5330e-01  8.7054e-03  1.0785e-02\n",
      "  7.5572e-02  6.8114e-03 -2.7961e-01  ...  -4.7690e-01 -1.6539e-03  2.2175e-02\n",
      "  1.6497e-02  1.1545e-02 -9.7006e-02  ...  -1.0669e-01  2.7689e-02  6.0170e-02\n",
      "                 ...                                      ...                \n",
      " -6.0868e-03  3.1388e-02 -1.1914e-02  ...   1.9073e-02  6.4154e-02  3.7929e-02\n",
      "  7.4657e-02  9.6033e-03 -1.5607e-01  ...  -2.4294e-01 -1.0464e-01  2.5088e-02\n",
      "  6.0126e-04  4.1605e-05  4.3443e-01  ...   1.2659e-01 -5.3086e-02  3.6345e-03\n",
      "[torch.cuda.FloatTensor of size 52x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> outputs[-1]\n",
      "[Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  0.1249  0.0000  0.2455  ...  -0.0927 -0.0593  0.1775\n",
      "  0.0143  0.0001  0.0000  ...  -0.0277 -0.0340  0.0000\n",
      "  0.0120 -0.0011  0.2021  ...  -0.0169 -0.0000  0.0656\n",
      "           ...                          ...          \n",
      "  0.0003 -0.0000  0.0917  ...  -0.0000  0.0207 -0.0000\n",
      "  0.8671  0.0000 -0.4425  ...  -0.0000 -0.0000  0.0081\n",
      "  0.0002  0.0000  0.9481  ...  -0.0001 -0.0532 -0.0184\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  0.0887  0.0000  0.2375  ...  -0.1685 -0.0348  0.1430\n",
      "  0.0182 -0.0020  0.0000  ...  -0.0344 -0.0296  0.0000\n",
      "  0.0131 -0.0018  0.2130  ...  -0.0454 -0.0000  0.0941\n",
      "           ...                          ...          \n",
      "  0.0051  0.0000  0.0000  ...  -0.0000  0.0030 -0.0000\n",
      "  0.0005  0.0000  0.1727  ...  -0.0000 -0.0000 -0.0820\n",
      "  0.0058  0.0000 -0.0454  ...  -0.0000 -0.0018 -0.0587\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.0642  0.0000  0.1595  ...  -0.1557 -0.0248  0.1196\n",
      "  0.0178 -0.0019  0.0000  ...  -0.0421 -0.0234  0.0000\n",
      "  0.0124 -0.0027  0.1748  ...  -0.0395 -0.0000  0.1100\n",
      "           ...                          ...          \n",
      "  0.0005  0.0385  0.3931  ...  -0.0000 -0.0241 -0.0000\n",
      "  0.0000  0.0000  0.0023  ...  -0.0000 -0.0000 -0.0362\n",
      "  0.0010  0.0000  0.2332  ...  -0.0375 -0.0023 -0.0578\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0222  0.0004  0.3612  ...  -0.0000 -0.0498  0.0000\n",
      "  0.0137  0.0000  0.2506  ...  -0.0000 -0.0000  0.0664\n",
      "  0.0000 -0.0000 -0.0000  ...  -1.3245 -0.0058 -0.0298\n",
      "\n",
      "(50 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0224  0.0004  0.3600  ...  -0.0000 -0.0506  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0709\n",
      "  0.0000  0.0000  0.0000  ...  -1.3336 -0.0313 -0.0776\n",
      "\n",
      "(51 ,.,.) = \n",
      "  0.0360 -0.0000  0.1812  ...  -0.0885 -0.0046  0.0798\n",
      "  0.0063 -0.0026  0.0000  ...  -0.0342 -0.0118 -0.0000\n",
      "  0.0118 -0.0030  0.1789  ...  -0.0454 -0.0000  0.1365\n",
      "           ...                          ...          \n",
      "  0.0226  0.0004  0.3599  ...  -0.0000 -0.0511  0.0000\n",
      "  0.0134  0.0000  0.2474  ...  -0.0000 -0.0000  0.0741\n",
      "  0.0004  0.0000  0.0797  ...  -0.3190 -0.0678 -0.1082\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0041  0.0000 -0.0066  ...   0.0000 -0.0316 -0.0000\n",
      " -0.0000  0.0093 -0.0706  ...   0.0003 -0.0050  0.0000\n",
      " -0.0030  0.0117  0.0114  ...   0.0000 -0.0014  0.0019\n",
      "           ...                          ...          \n",
      " -0.0000 -0.0000 -0.0000  ...  -0.0000  0.0112  0.0000\n",
      " -0.0000  0.0000 -0.0038  ...   0.0010 -0.0161 -0.0123\n",
      " -0.0050  0.0036 -0.0671  ...   0.0041 -0.0285  0.0513\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0043  0.0000 -0.0346  ...   0.0000 -0.0296 -0.0000\n",
      " -0.0000  0.0107 -0.0539  ...  -0.0030 -0.0086  0.0000\n",
      " -0.0021  0.0154  0.0071  ...   0.0000  0.0029  0.0086\n",
      "           ...                          ...          \n",
      " -0.0000  0.0000 -0.0000  ...  -0.0000  0.0351  0.0000\n",
      " -0.0000  0.0000  0.0059  ...   0.0065  0.0173 -0.0124\n",
      " -0.0013 -0.0006  0.0555  ...  -0.0209 -0.0348  0.0121\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0049  0.0000 -0.0462  ...   0.0000 -0.0268 -0.0000\n",
      " -0.0000  0.0108 -0.0426  ...  -0.0023 -0.0128  0.0000\n",
      " -0.0029  0.0170  0.0068  ...   0.0000  0.0049  0.0105\n",
      "           ...                          ...          \n",
      " -0.0004  0.0000 -0.0000  ...   0.0000  0.0588  0.0000\n",
      " -0.0000  0.0000 -0.0009  ...   0.0089  0.0156 -0.0386\n",
      " -0.0002 -0.0059  0.0316  ...  -0.0087 -0.0378 -0.0007\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0129 -0.0000\n",
      " -0.0000  0.0000 -0.0210  ...   0.0050 -0.0122  0.0085\n",
      " -0.0000 -0.0048  0.0163  ...  -0.0030 -0.0220 -0.0098\n",
      "\n",
      "(50 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0122 -0.0000\n",
      " -0.0000  0.0000 -0.0216  ...   0.0051 -0.0122  0.0090\n",
      " -0.0021 -0.0082  0.0004  ...   0.0030 -0.0171 -0.0054\n",
      "\n",
      "(51 ,.,.) = \n",
      " -0.0064  0.0000 -0.0691  ...   0.0000 -0.0143 -0.0000\n",
      " -0.0000  0.0098 -0.0399  ...   0.0010 -0.0158  0.0000\n",
      " -0.0030  0.0182  0.0074  ...   0.0000  0.0073  0.0100\n",
      "           ...                          ...          \n",
      " -0.0010  0.0000 -0.0000  ...   0.0000 -0.0118 -0.0000\n",
      " -0.0000  0.0000 -0.0217  ...   0.0051 -0.0121  0.0094\n",
      " -0.0008  0.0028 -0.0395  ...   0.0029  0.0148  0.0248\n",
      "[torch.cuda.FloatTensor of size 52x8x500 (GPU 0)]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -3.2458e-03  8.7113e-03  1.5615e-01  ...   1.0511e-03 -3.4246e-02  9.3160e-02\n",
      "  1.6440e-03  1.5580e-02  6.5035e-02  ...  -3.5910e-02 -8.1517e-02  5.3498e-02\n",
      "  5.6775e-03  3.0201e-03 -4.4422e-02  ...  -2.3107e-02 -1.9810e-01  4.6526e-02\n",
      "                 ...                                      ...                \n",
      "  3.2747e-02  2.5253e-02 -8.8830e-02  ...  -6.9768e-02 -4.7884e-02  3.3285e-04\n",
      " -1.5779e-01  1.2834e-01 -1.9318e-01  ...  -9.2916e-02 -5.2056e-04  1.5515e-03\n",
      " -4.2371e-02  9.6233e-03  6.4710e-02  ...  -5.8583e-02  2.4529e-02  1.2164e-03\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.7982e-03  3.9203e-03  1.3109e-01  ...   1.2617e-02 -4.4666e-03  9.5297e-02\n",
      "  5.4326e-03  8.8408e-03 -2.5101e-02  ...  -1.1051e-01 -7.1092e-03  5.7667e-02\n",
      "  8.5618e-03  2.8817e-03 -9.3897e-02  ...  -7.7938e-02 -1.2714e-01  5.6355e-02\n",
      "                 ...                                      ...                \n",
      " -3.8636e-02  8.6608e-04  1.2561e-01  ...  -5.3316e-03 -2.6278e-02  1.5395e-02\n",
      "  8.8907e-02  2.4031e-02  1.7218e-01  ...  -3.1122e-02 -9.2906e-04  2.1702e-04\n",
      " -4.8558e-02  1.2444e-02 -4.2940e-02  ...  -9.8066e-02 -1.1404e-01  1.8107e-05\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  9.1112e-03  4.1698e-03  1.0478e-01  ...   2.8698e-02 -1.6538e-02  9.7076e-02\n",
      "  1.0099e-02  8.4244e-03 -3.8806e-02  ...  -1.0868e-01 -2.4257e-03  5.2825e-02\n",
      "  1.0661e-02  2.8269e-03 -1.0834e-01  ...  -1.0367e-01 -6.5392e-02  5.1589e-02\n",
      "                 ...                                      ...                \n",
      " -9.5537e-03  1.1279e-01  1.1044e-02  ...  -2.6348e-02  8.2377e-02  8.5361e-03\n",
      "  3.5080e-02  6.9985e-02 -1.6682e-01  ...   3.0933e-01  9.0400e-02  1.9465e-03\n",
      " -3.4016e-02  7.0110e-04  2.3338e-01  ...   3.7035e-03 -1.0715e-01  3.3775e-03\n",
      "... \n",
      "\n",
      "(49 ,.,.) = \n",
      "  1.5787e-01  4.0386e-03 -2.9706e-01  ...  -4.3813e-01  8.6774e-03  1.1279e-02\n",
      "  7.6055e-02  6.7669e-03 -2.8087e-01  ...  -4.7266e-01 -1.1756e-03  2.2558e-02\n",
      "  1.6703e-02  1.1379e-02 -9.5844e-02  ...  -1.0695e-01  2.7542e-02  5.9055e-02\n",
      "                 ...                                      ...                \n",
      " -5.4963e-03  2.7957e-02 -2.6366e-02  ...   2.2478e-02  5.6376e-02  4.2229e-02\n",
      "  5.7358e-02  1.3850e-02 -1.5816e-01  ...  -1.6360e-01 -1.0346e-01  2.7932e-02\n",
      "  2.6478e-02  9.7819e-02 -9.1238e-02  ...  -2.4474e-01 -6.2434e-02  1.0283e-01\n",
      "\n",
      "(50 ,.,.) = \n",
      "  1.6388e-01  4.0558e-03 -2.9706e-01  ...  -4.4597e-01  8.7005e-03  1.1049e-02\n",
      "  7.5816e-02  6.7876e-03 -2.8027e-01  ...  -4.7485e-01 -1.4158e-03  2.2351e-02\n",
      "  1.6601e-02  1.1464e-02 -9.6398e-02  ...  -1.0686e-01  2.7614e-02  5.9635e-02\n",
      "                 ...                                      ...                \n",
      " -5.8475e-03  2.9788e-02 -2.1429e-02  ...   2.0583e-02  6.1296e-02  3.9498e-02\n",
      "  6.6094e-02  1.1282e-02 -1.5613e-01  ...  -1.9974e-01 -1.0232e-01  2.5547e-02\n",
      "  1.2053e-02  2.5828e-02 -5.2196e-02  ...  -4.4959e-01 -3.7889e-02  3.0552e-03\n",
      "\n",
      "(51 ,.,.) = \n",
      "  1.7001e-01  4.0707e-03 -2.9688e-01  ...  -4.5330e-01  8.7054e-03  1.0785e-02\n",
      "  7.5572e-02  6.8114e-03 -2.7961e-01  ...  -4.7690e-01 -1.6539e-03  2.2175e-02\n",
      "  1.6497e-02  1.1545e-02 -9.7006e-02  ...  -1.0669e-01  2.7689e-02  6.0170e-02\n",
      "                 ...                                      ...                \n",
      " -6.0868e-03  3.1388e-02 -1.1914e-02  ...   1.9073e-02  6.4154e-02  3.7929e-02\n",
      "  7.4657e-02  9.6033e-03 -1.5607e-01  ...  -2.4294e-01 -1.0464e-01  2.5088e-02\n",
      "  6.0126e-04  4.1605e-05  4.3443e-01  ...   1.2659e-01 -5.3086e-02  3.6345e-03\n",
      "[torch.cuda.FloatTensor of size 52x8x200 (GPU 0)]\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipdb> c\n",
      "> \u001b[0;32m/home/wgilliam/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m(189)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    187 \u001b[0;31m            \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    188 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 189 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0ml_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    190 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    191 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs[-1]\n",
      "Variable containing:\n",
      "( 0  ,.,.) = \n",
      " -5.1802e-03  1.3690e-02  4.2789e-02  ...  -5.7836e-02 -6.7825e-02  1.4687e-02\n",
      " -5.7780e-02  6.6521e-03  3.7108e-01  ...  -2.3029e-02 -2.8528e-02  6.2480e-02\n",
      " -3.3851e-02  3.3785e-02 -1.4701e-01  ...   3.7199e-02 -5.2373e-03  1.9855e-02\n",
      "                 ...                                      ...                \n",
      "  1.3672e-02 -3.7273e-02 -1.2874e-01  ...   3.6899e-02  2.8976e-03  4.6424e-03\n",
      " -3.8872e-02  1.1902e-02  2.2493e-01  ...  -1.3780e-01 -1.8635e-02  7.7463e-02\n",
      "  1.0265e-02  3.9806e-03 -1.2600e-01  ...   1.3483e-02 -2.1334e-03  6.6054e-03\n",
      "\n",
      "( 1  ,.,.) = \n",
      "  4.4655e-02  3.6596e-02 -3.8554e-03  ...   4.4402e-02 -4.0145e-02  2.6596e-03\n",
      "  3.9205e-03 -9.1737e-02 -2.3739e-01  ...   5.6661e-02  5.1622e-03  5.8671e-03\n",
      " -1.7147e-01  1.5610e-01 -1.4801e-01  ...   1.6742e-02  1.3414e-02  5.5239e-03\n",
      "                 ...                                      ...                \n",
      "  1.3196e-01 -7.1455e-05 -1.4382e-01  ...  -4.5849e-02 -1.2068e-02  1.8030e-02\n",
      "  4.2198e-02  8.3415e-02 -2.7305e-02  ...  -8.4920e-02 -1.3645e-02  1.2678e-02\n",
      "  3.7452e-02  1.4637e-02  3.4703e-02  ...  -6.8702e-03 -8.9994e-02  7.1971e-02\n",
      "\n",
      "( 2  ,.,.) = \n",
      "  1.1459e-02  1.1481e-02 -8.2179e-02  ...   3.6689e-02 -1.1950e-01  3.5259e-02\n",
      "  3.6867e-02  8.8298e-03 -4.3731e-02  ...   1.0142e-01  1.6975e-01  1.7540e-02\n",
      " -1.0857e-01 -3.2389e-03  5.4021e-01  ...  -3.5778e-04 -8.6116e-03  9.1528e-03\n",
      "                 ...                                      ...                \n",
      "  1.4409e-01  2.2776e-02 -2.8356e-02  ...  -5.4030e-03 -2.7029e-02  2.4835e-02\n",
      " -1.2766e-02  1.0539e-02 -4.2866e-01  ...  -1.8772e-03 -1.7710e-03  2.3454e-03\n",
      "  2.1759e-02  2.2187e-01 -6.2478e-02  ...   6.0411e-03 -3.5166e-02  7.2553e-04\n",
      " ... \n",
      "\n",
      "(1099,.,.) = \n",
      "  1.5787e-01  4.0386e-03 -2.9706e-01  ...  -4.3813e-01  8.6774e-03  1.1279e-02\n",
      "  7.6055e-02  6.7669e-03 -2.8087e-01  ...  -4.7266e-01 -1.1756e-03  2.2558e-02\n",
      "  1.6703e-02  1.1379e-02 -9.5844e-02  ...  -1.0695e-01  2.7542e-02  5.9055e-02\n",
      "                 ...                                      ...                \n",
      " -5.4963e-03  2.7957e-02 -2.6366e-02  ...   2.2478e-02  5.6376e-02  4.2229e-02\n",
      "  5.7358e-02  1.3850e-02 -1.5816e-01  ...  -1.6360e-01 -1.0346e-01  2.7932e-02\n",
      "  2.6478e-02  9.7819e-02 -9.1238e-02  ...  -2.4474e-01 -6.2434e-02  1.0283e-01\n",
      "\n",
      "(1100,.,.) = \n",
      "  1.6388e-01  4.0558e-03 -2.9706e-01  ...  -4.4597e-01  8.7005e-03  1.1049e-02\n",
      "  7.5816e-02  6.7876e-03 -2.8027e-01  ...  -4.7485e-01 -1.4158e-03  2.2351e-02\n",
      "  1.6601e-02  1.1464e-02 -9.6398e-02  ...  -1.0686e-01  2.7614e-02  5.9635e-02\n",
      "                 ...                                      ...                \n",
      " -5.8475e-03  2.9788e-02 -2.1429e-02  ...   2.0583e-02  6.1296e-02  3.9498e-02\n",
      "  6.6094e-02  1.1282e-02 -1.5613e-01  ...  -1.9974e-01 -1.0232e-01  2.5547e-02\n",
      "  1.2053e-02  2.5828e-02 -5.2196e-02  ...  -4.4959e-01 -3.7889e-02  3.0552e-03\n",
      "\n",
      "(1101,.,.) = \n",
      "  1.7001e-01  4.0707e-03 -2.9688e-01  ...  -4.5330e-01  8.7054e-03  1.0785e-02\n",
      "  7.5572e-02  6.8114e-03 -2.7961e-01  ...  -4.7690e-01 -1.6539e-03  2.2175e-02\n",
      "  1.6497e-02  1.1545e-02 -9.7006e-02  ...  -1.0669e-01  2.7689e-02  6.0170e-02\n",
      "                 ...                                      ...                \n",
      " -6.0868e-03  3.1388e-02 -1.1914e-02  ...   1.9073e-02  6.4154e-02  3.7929e-02\n",
      "  7.4657e-02  9.6033e-03 -1.5607e-01  ...  -2.4294e-01 -1.0464e-01  2.5088e-02\n",
      "  6.0126e-04  4.1605e-05  4.3443e-01  ...   1.2659e-01 -5.3086e-02  3.6345e-03\n",
      "[torch.cuda.FloatTensor of size 1102x8x200 (GPU 0)]\n",
      "\n",
      "ipdb> c\n",
      "  0%|          | 6/3124 [13:11<114:12:00, 131.85s/it, loss=1.1] "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-16201178a75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# freeze everything except last layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, use_clr, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_geom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_len\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcycle_len\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         return fit(model, data, n_epoch, layer_opt.opt, self.crit,\n\u001b[0;32m--> 156\u001b[0;31m             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, epochs, opt, crit, metrics, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/lm_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_with_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropoute\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/development/_training/ml/fastai-course/fastai-projects/part1v2/dl1/fastai/rnn_reg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, words, dropout, scale)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mmasked_embed_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmasked_embed_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512387374934/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "m3.freeze_to(-1) # freeze everything except last layer\n",
    "m3.fit(lrs/2, 1, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.unfreeze()\n",
    "m3.fit(lrs, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.fit(lrs, 7, metrics=[accuracy], cycle_len=2, cycle_save_name='imdb_sent1_c7_cl2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.load_cycle('imdb_sent1_c7_cl2', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = m3.predict_with_targs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10], y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

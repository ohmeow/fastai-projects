{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path('data/aclImdb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "    return texts,labels\n",
    "\n",
    "trn_texts,trn_labels = get_texts(PATH/'train')\n",
    "val_texts,val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       0  Story of a man who has unnatural feelings for ...\n",
       "1       0  Airport '77 starts as a brand new luxury 747 p...\n",
       "2       0  This film lacked something I couldn't put my f...\n",
       "3       0  Sorry everyone,,, I know this is supposed to b...\n",
       "4       0  When I was little my parents took me along to ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1</td>\n",
       "      <td>I was extraordinarily impressed by this film. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>Although I'm not a golf fan, I attended a snea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "      <td>From the start of \"The Edge Of Love\", the view...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>This movie, with all its complexity and subtle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>1</td>\n",
       "      <td>I've seen this story before but my kids haven'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                               text\n",
       "24995       1  I was extraordinarily impressed by this film. ...\n",
       "24996       1  Although I'm not a golf fan, I attended a snea...\n",
       "24997       1  From the start of \"The Edge Of Love\", the view...\n",
       "24998       1  This movie, with all its complexity and subtle...\n",
       "24999       1  I've seen this story before but my kids haven'..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_trn.head())\n",
    "display(df_val.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(path):\n",
    "    return [fname.open('r').read() for fname in (path/'all').glob('*.*')]\n",
    "\n",
    "all_texts =  get_texts(PATH/'train')\n",
    "all_texts += get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(all_texts, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_PATH=Path('data/imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>0</td>\n",
       "      <td>I would like to say i have seen Many film's , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>0</td>\n",
       "      <td>After his father was killed a young man named ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a nice piece of work. Very sexy and en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>0</td>\n",
       "      <td>This is, without any doubt, the WORST movie in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>0</td>\n",
       "      <td>I got to see this just this last Friday at the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       labels                                               text\n",
       "89995       0  I would like to say i have seen Many film's , ...\n",
       "89996       0  After his father was killed a young man named ...\n",
       "89997       0  This is a nice piece of work. Very sexy and en...\n",
       "89998       0  This is, without any doubt, the WORST movie in...\n",
       "89999       0  I got to see this just this last Friday at the..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "#     pdb.set_trace()\n",
    "    \n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 90000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_trn), len(trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'xbos',\n",
       " 'xfld',\n",
       " '1',\n",
       " 'sophisticated',\n",
       " 'sex',\n",
       " 'comedies',\n",
       " 'are',\n",
       " 'always',\n",
       " 'difficult',\n",
       " 'to',\n",
       " 'pull',\n",
       " 'off',\n",
       " '.',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'films',\n",
       " 'of',\n",
       " 'blake',\n",
       " 'edwards',\n",
       " ',',\n",
       " 'who',\n",
       " 'is',\n",
       " 'arguably',\n",
       " 'the',\n",
       " 'master',\n",
       " 'of',\n",
       " 'the',\n",
       " 'genre',\n",
       " ',',\n",
       " 'and',\n",
       " 'you',\n",
       " 'will',\n",
       " 'find',\n",
       " 'just',\n",
       " 'as',\n",
       " 'many',\n",
       " 'misses',\n",
       " 'as',\n",
       " 'hits',\n",
       " '.',\n",
       " 'for',\n",
       " ',',\n",
       " 'if',\n",
       " 'a',\n",
       " 'film',\n",
       " 'of',\n",
       " 'this',\n",
       " 'nature',\n",
       " 'ever',\n",
       " 'fails',\n",
       " 'to',\n",
       " 'work',\n",
       " ',',\n",
       " 'it',\n",
       " 'can',\n",
       " 'never',\n",
       " 'fall',\n",
       " 'back',\n",
       " 'on',\n",
       " 'the',\n",
       " 'tried',\n",
       " 'and',\n",
       " 'true',\n",
       " 'toilet',\n",
       " 'humor',\n",
       " 'of',\n",
       " 'a',\n",
       " 'teen',\n",
       " 'sex',\n",
       " 'comedy',\n",
       " '[',\n",
       " 'i.e.',\n",
       " '\"',\n",
       " 'american',\n",
       " 'pie',\n",
       " '\"',\n",
       " ']',\n",
       " ',',\n",
       " 'or',\n",
       " 'warm',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'with',\n",
       " 'the',\n",
       " 'sentimentality',\n",
       " 'of',\n",
       " 'a',\n",
       " 'romantic',\n",
       " 'comedy',\n",
       " '[',\n",
       " 'i.e.',\n",
       " 'julia',\n",
       " 'roberts',\n",
       " \"'\",\n",
       " 'entire',\n",
       " 'career',\n",
       " ']',\n",
       " '.',\n",
       " 'it',\n",
       " 'can',\n",
       " 'only',\n",
       " 'maintain',\n",
       " 'a',\n",
       " 'push',\n",
       " 'to',\n",
       " 'the',\n",
       " 'end',\n",
       " ',',\n",
       " 'and',\n",
       " 'hope',\n",
       " 'that',\n",
       " 'the',\n",
       " 'audience',\n",
       " 'can',\n",
       " 'appreciate',\n",
       " 'the',\n",
       " 'almost',\n",
       " 'required',\n",
       " 'irony',\n",
       " 'of',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'resolution',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'written',\n",
       " 'by',\n",
       " 'husband',\n",
       " '/',\n",
       " 'wife',\n",
       " 'team',\n",
       " 'wally',\n",
       " 'wolodarsky',\n",
       " 'and',\n",
       " 'maya',\n",
       " 'forbes',\n",
       " ',',\n",
       " '\"',\n",
       " 'seeing',\n",
       " 'other',\n",
       " 'people',\n",
       " '\"',\n",
       " 'opens',\n",
       " 'with',\n",
       " 'engaged',\n",
       " 'couple',\n",
       " 'ed',\n",
       " '&',\n",
       " 'alice',\n",
       " '[',\n",
       " 'jay',\n",
       " 'mohr',\n",
       " '&',\n",
       " 'julianne',\n",
       " 'nicholson',\n",
       " ']',\n",
       " 'only',\n",
       " 'seconds',\n",
       " 'away',\n",
       " 'from',\n",
       " 'rear',\n",
       " '-',\n",
       " 'ending',\n",
       " 'the',\n",
       " 'car',\n",
       " 'in',\n",
       " 'front',\n",
       " 'of',\n",
       " 'them',\n",
       " '.',\n",
       " 'as',\n",
       " 'the',\n",
       " 'frame',\n",
       " 'freezes',\n",
       " ',',\n",
       " 'we',\n",
       " 'unexpectedly',\n",
       " 'hear',\n",
       " 'the',\n",
       " 'thoughts',\n",
       " 'and',\n",
       " 'fears',\n",
       " 'of',\n",
       " 'both',\n",
       " 'characters',\n",
       " '.',\n",
       " 'from',\n",
       " 'here',\n",
       " 'on',\n",
       " 'out',\n",
       " ',',\n",
       " 'we',\n",
       " 'welcome',\n",
       " 'that',\n",
       " 'the',\n",
       " 'story',\n",
       " 'about',\n",
       " 'to',\n",
       " 'unfold',\n",
       " 'will',\n",
       " 'enjoy',\n",
       " 'a',\n",
       " 'point',\n",
       " 'of',\n",
       " 'view',\n",
       " 'from',\n",
       " 'both',\n",
       " 'sexes',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'two',\n",
       " 'months',\n",
       " 'shy',\n",
       " 'of',\n",
       " 'their',\n",
       " 'vows',\n",
       " ',',\n",
       " 'ed',\n",
       " '&',\n",
       " 'alice',\n",
       " 'already',\n",
       " 'look',\n",
       " 'and',\n",
       " 'act',\n",
       " 'like',\n",
       " 'an',\n",
       " 'old',\n",
       " 'married',\n",
       " 'couple',\n",
       " '.',\n",
       " 'in',\n",
       " 'an',\n",
       " 'early',\n",
       " 'bathroom',\n",
       " 'scene',\n",
       " ',',\n",
       " 'their',\n",
       " 'actions',\n",
       " 'alone',\n",
       " 'show',\n",
       " 'us',\n",
       " 'just',\n",
       " 'how',\n",
       " 'comfortable',\n",
       " 'they',\n",
       " 'are',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " 'and',\n",
       " 'how',\n",
       " 'long',\n",
       " 'they',\n",
       " 'have',\n",
       " 'been',\n",
       " 'together',\n",
       " '.',\n",
       " 'so',\n",
       " 'when',\n",
       " 'the',\n",
       " 'line',\n",
       " 'to',\n",
       " 'propel',\n",
       " 'the',\n",
       " 'plot',\n",
       " 'forward',\n",
       " 'is',\n",
       " 'uttered',\n",
       " '-',\n",
       " 'expectedly',\n",
       " 'from',\n",
       " 'the',\n",
       " 'least',\n",
       " 'likely',\n",
       " 'of',\n",
       " 'the',\n",
       " 'two',\n",
       " '-',\n",
       " 'it',\n",
       " 'is',\n",
       " 'as',\n",
       " 'if',\n",
       " 'the',\n",
       " 'very',\n",
       " 'relationship',\n",
       " 'itself',\n",
       " 'is',\n",
       " 'calling',\n",
       " 'for',\n",
       " 'a',\n",
       " 'change',\n",
       " ',',\n",
       " 'even',\n",
       " 'if',\n",
       " 'it',\n",
       " 'means',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'own',\n",
       " 'destruction',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'once',\n",
       " 'all',\n",
       " 'the',\n",
       " 'ground',\n",
       " 'rules',\n",
       " 'are',\n",
       " 'set',\n",
       " '[',\n",
       " 'ed',\n",
       " 'can',\n",
       " 'not',\n",
       " 'sleep',\n",
       " 'with',\n",
       " 'her',\n",
       " 'mother',\n",
       " 'or',\n",
       " ',',\n",
       " 'for',\n",
       " 'that',\n",
       " 'matter',\n",
       " ',',\n",
       " 'salma',\n",
       " 'hayek',\n",
       " ']',\n",
       " ',',\n",
       " 'the',\n",
       " 'two',\n",
       " 'head',\n",
       " 'off',\n",
       " 'in',\n",
       " 'their',\n",
       " 'separate',\n",
       " 'directions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hope',\n",
       " 'of',\n",
       " 'finding',\n",
       " 'some',\n",
       " 'meaningless',\n",
       " 'sex',\n",
       " 'to',\n",
       " 'strengthen',\n",
       " 'their',\n",
       " 'relationship',\n",
       " '.',\n",
       " 'at',\n",
       " 'first',\n",
       " ',',\n",
       " 'everything',\n",
       " 'seems',\n",
       " 'to',\n",
       " 'go',\n",
       " 'as',\n",
       " 'planned',\n",
       " 'as',\n",
       " 'their',\n",
       " 'daily',\n",
       " 'trysts',\n",
       " 'only',\n",
       " 'help',\n",
       " 'to',\n",
       " 'fire',\n",
       " 'up',\n",
       " 'the',\n",
       " 'passion',\n",
       " 'between',\n",
       " 'them',\n",
       " '.',\n",
       " 'but',\n",
       " 'predictably',\n",
       " ',',\n",
       " 'as',\n",
       " 'the',\n",
       " 'deeper',\n",
       " 'emotions',\n",
       " 'of',\n",
       " 'regret',\n",
       " 'and',\n",
       " 'jealousy',\n",
       " 'begin',\n",
       " 'to',\n",
       " 'emerge',\n",
       " ',',\n",
       " 'they',\n",
       " 'soon',\n",
       " 'find',\n",
       " 'themselves',\n",
       " 'growing',\n",
       " 'apart',\n",
       " 'and',\n",
       " 'on',\n",
       " 'the',\n",
       " 'verge',\n",
       " 'of',\n",
       " 'breaking',\n",
       " 'up',\n",
       " '.',\n",
       " 'all',\n",
       " 'of',\n",
       " 'these',\n",
       " 'actions',\n",
       " 'leading',\n",
       " 'to',\n",
       " 'a',\n",
       " 'resolution',\n",
       " 'you',\n",
       " 'may',\n",
       " 'or',\n",
       " 'may',\n",
       " 'not',\n",
       " 'like',\n",
       " '-',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'your',\n",
       " 'own',\n",
       " 'degree',\n",
       " 'of',\n",
       " 'cynicism',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'for',\n",
       " 'a',\n",
       " 'comedy',\n",
       " 'like',\n",
       " 'this',\n",
       " ',',\n",
       " 'you',\n",
       " 'need',\n",
       " 'a',\n",
       " 'solid',\n",
       " 'cast',\n",
       " 'with',\n",
       " 'supporting',\n",
       " 'characters',\n",
       " 'just',\n",
       " 'as',\n",
       " 'strong',\n",
       " 'as',\n",
       " 'the',\n",
       " 'leads',\n",
       " '.',\n",
       " 'and',\n",
       " 'director',\n",
       " 'wolodarsky',\n",
       " 'does',\n",
       " 'not',\n",
       " 'disappoint',\n",
       " '.',\n",
       " 'here',\n",
       " 'he',\n",
       " 'has',\n",
       " 'cast',\n",
       " 'two',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'actresses',\n",
       " 'as',\n",
       " 'sisters',\n",
       " '-',\n",
       " 'julianne',\n",
       " 'nicholson',\n",
       " '&',\n",
       " 'lauren',\n",
       " 'graham',\n",
       " '-',\n",
       " 'and',\n",
       " 'allows',\n",
       " 'them',\n",
       " 'to',\n",
       " 'play',\n",
       " 'to',\n",
       " 'their',\n",
       " 'strengths',\n",
       " '.',\n",
       " 'for',\n",
       " 'nicholson',\n",
       " ',',\n",
       " 'who',\n",
       " 'has',\n",
       " 'always',\n",
       " 'reminded',\n",
       " 'me',\n",
       " 'of',\n",
       " 'a',\n",
       " 'young',\n",
       " 'shirley',\n",
       " 'maclaine',\n",
       " ',',\n",
       " 'she',\n",
       " 'brings',\n",
       " 'an',\n",
       " 'air',\n",
       " 'of',\n",
       " 'naivete',\n",
       " 'and',\n",
       " 'vulnerability',\n",
       " 'to',\n",
       " 'alice',\n",
       " 'even',\n",
       " 'when',\n",
       " 'her',\n",
       " 'actions',\n",
       " 'seems',\n",
       " 'less',\n",
       " 'than',\n",
       " 'so',\n",
       " '.',\n",
       " 'and',\n",
       " 'as',\n",
       " 'for',\n",
       " 'graham',\n",
       " ',',\n",
       " 'an',\n",
       " 'actress',\n",
       " 'who',\n",
       " 'has',\n",
       " 'proven',\n",
       " 'she',\n",
       " 'could',\n",
       " 'outperform',\n",
       " 'an',\n",
       " 'entire',\n",
       " 'howard',\n",
       " 'hawks',\n",
       " 'ensemble',\n",
       " ',',\n",
       " 'she',\n",
       " 'steals',\n",
       " 'every',\n",
       " 'scene',\n",
       " 'she',\n",
       " 'is',\n",
       " 'in',\n",
       " 'with',\n",
       " 'an',\n",
       " 'edgy',\n",
       " '\"',\n",
       " 'no',\n",
       " 'bs',\n",
       " '\"',\n",
       " 'persona',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'as',\n",
       " 'for',\n",
       " 'the',\n",
       " 'guys',\n",
       " ',',\n",
       " 'jay',\n",
       " 'mohr',\n",
       " 'is',\n",
       " 'serviceable',\n",
       " 'here',\n",
       " 'as',\n",
       " 'is',\n",
       " 'josh',\n",
       " 'charles',\n",
       " '.',\n",
       " '\"',\n",
       " 'malcolm',\n",
       " 'in',\n",
       " 'the',\n",
       " 'middle',\n",
       " '\"',\n",
       " \"'s\",\n",
       " 'byron',\n",
       " 'cranston',\n",
       " 'has',\n",
       " 'to',\n",
       " 'be',\n",
       " 'applauded',\n",
       " 'for',\n",
       " 'taking',\n",
       " 'on',\n",
       " 'a',\n",
       " 'british',\n",
       " 'accent',\n",
       " 'and',\n",
       " 'letting',\n",
       " 'it',\n",
       " 'all',\n",
       " 'hang',\n",
       " 'out',\n",
       " '.',\n",
       " 'but',\n",
       " 'the',\n",
       " 'real',\n",
       " 'treat',\n",
       " 'here',\n",
       " 'is',\n",
       " 'andy',\n",
       " 'richter',\n",
       " 'and',\n",
       " 'his',\n",
       " 'sub',\n",
       " '-',\n",
       " 'plot',\n",
       " 'involving',\n",
       " 'single',\n",
       " 'mother',\n",
       " ',',\n",
       " 'helen',\n",
       " 'slater',\n",
       " '.',\n",
       " 'while',\n",
       " 'his',\n",
       " 'scenes',\n",
       " 'almost',\n",
       " 'seem',\n",
       " 'to',\n",
       " 'belong',\n",
       " 'in',\n",
       " 'another',\n",
       " 'movie',\n",
       " ',',\n",
       " 'they',\n",
       " 'are',\n",
       " 'by',\n",
       " 'far',\n",
       " 'the',\n",
       " 'funniest',\n",
       " 'and',\n",
       " 'his',\n",
       " 'dead',\n",
       " 'panned',\n",
       " 'delivery',\n",
       " 'steals',\n",
       " 'the',\n",
       " 'show',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'for',\n",
       " 'an',\n",
       " 'independent',\n",
       " 'production',\n",
       " ',',\n",
       " '\"',\n",
       " 'seeing',\n",
       " 'other',\n",
       " 'people',\n",
       " '\"',\n",
       " 'has',\n",
       " 'a',\n",
       " 'more',\n",
       " 'personal',\n",
       " 'and',\n",
       " 'introspective',\n",
       " 'feeling',\n",
       " '-',\n",
       " 'something',\n",
       " 'that',\n",
       " 'would',\n",
       " 'be',\n",
       " 'noticeable',\n",
       " 'absent',\n",
       " 'from',\n",
       " 'a',\n",
       " 'big',\n",
       " 'hollywood',\n",
       " 'film',\n",
       " 'of',\n",
       " 'this',\n",
       " 'kind',\n",
       " '.',\n",
       " 'not',\n",
       " 'to',\n",
       " 'mention',\n",
       " 'that',\n",
       " 'this',\n",
       " 'film',\n",
       " 'also',\n",
       " 'has',\n",
       " 'some',\n",
       " 'genuinely',\n",
       " 'funny',\n",
       " 'moments',\n",
       " '-',\n",
       " 'unlike',\n",
       " ',',\n",
       " 'say',\n",
       " ',',\n",
       " 'most',\n",
       " 'hollywood',\n",
       " 'comedies',\n",
       " 'in',\n",
       " 'general',\n",
       " '.',\n",
       " '\\n\\n',\n",
       " 'rating',\n",
       " '[',\n",
       " 'on',\n",
       " 'a',\n",
       " '5',\n",
       " 'star',\n",
       " 'system',\n",
       " ']',\n",
       " ':',\n",
       " '3',\n",
       " '1',\n",
       " '/',\n",
       " '2',\n",
       " 'stars']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_trn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_joined = [' '.join(o) for o in tok_trn]\n",
    "# mdl_fn = f'{PATH}tmp/{pr_abbr}_joined.txt'\n",
    "# open(mdl_fn, 'w', encoding='utf-8').writelines(trn_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1208033),\n",
       " ('.', 991897),\n",
       " (',', 984093),\n",
       " ('and', 587619),\n",
       " ('a', 583275),\n",
       " ('of', 524479),\n",
       " ('to', 485475),\n",
       " ('is', 393321),\n",
       " ('it', 341241),\n",
       " ('in', 337750),\n",
       " ('i', 307977),\n",
       " ('this', 270649),\n",
       " ('that', 260925),\n",
       " ('\"', 236575),\n",
       " (\"'s\", 221012),\n",
       " ('-', 187782),\n",
       " ('was', 180429),\n",
       " ('\\n\\n', 178930),\n",
       " ('as', 165752),\n",
       " ('with', 159247),\n",
       " ('for', 158772),\n",
       " ('movie', 157584),\n",
       " ('but', 150310),\n",
       " ('film', 144079),\n",
       " ('you', 124187)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2808"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['freddy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_lm), len(val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "em_sz,nh,nl = 400,1150,3\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "trn_lm = np.concatenate(trn_lm)\n",
    "val_lm = np.concatenate(val_lm)\n",
    "\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))\n",
    "vs = len(itos)\n",
    "\n",
    "trn_dl = LanguageModelLoader(trn_lm, bs, bptt)\n",
    "val_dl = LanguageModelLoader(val_lm, bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(start_lr=1e-6,end_lr=1e12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit(lr, 1, wds=wd, use_clr=(32,5), cycle_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit(lr, 1, wds=wd, use_clr=(32,10), cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm')\n",
    "learner.save_encoder('lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit(lr/2, 1, wds=wd, use_clr=(32,10), cycle_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')\n",
    "\n",
    "trn_labels = np.load(CLAS_PATH/'tmp'/'trn_labels.npy')\n",
    "val_labels = np.load(CLAS_PATH/'tmp'/'val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 335844),\n",
       " ('.', 277583),\n",
       " (',', 275297),\n",
       " ('and', 163775),\n",
       " ('a', 162489),\n",
       " ('of', 145813),\n",
       " ('to', 135629),\n",
       " ('is', 110387),\n",
       " ('it', 95826),\n",
       " ('in', 93847),\n",
       " ('i', 86730),\n",
       " ('this', 75735),\n",
       " ('that', 73495),\n",
       " ('\"', 65053),\n",
       " (\"'s\", 62103),\n",
       " ('-', 52852),\n",
       " ('was', 50493),\n",
       " ('\\n\\n', 49832),\n",
       " ('as', 46849),\n",
       " ('for', 44290),\n",
       " ('with', 44076),\n",
       " ('movie', 43840),\n",
       " ('but', 42441),\n",
       " ('film', 40027),\n",
       " (')', 34632)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40,\n",
       " 41,\n",
       " 42,\n",
       " 39,\n",
       " 81,\n",
       " 7,\n",
       " 6,\n",
       " 144,\n",
       " 48,\n",
       " 60,\n",
       " 7154,\n",
       " 1427,\n",
       " 22,\n",
       " 6,\n",
       " 4469,\n",
       " 3,\n",
       " 529,\n",
       " 59,\n",
       " 21,\n",
       " 6,\n",
       " 650,\n",
       " 149,\n",
       " 14,\n",
       " 9,\n",
       " 6,\n",
       " 1351,\n",
       " 510,\n",
       " 7,\n",
       " 1895,\n",
       " 222,\n",
       " 3,\n",
       " 6,\n",
       " 11601,\n",
       " 7125,\n",
       " 327,\n",
       " 9,\n",
       " 674,\n",
       " 103,\n",
       " 47,\n",
       " 2018,\n",
       " 4,\n",
       " 1074,\n",
       " 2492,\n",
       " 46,\n",
       " 2,\n",
       " 952,\n",
       " 0,\n",
       " 7,\n",
       " 10,\n",
       " 16,\n",
       " 6073,\n",
       " 3,\n",
       " 492,\n",
       " 10,\n",
       " 2890,\n",
       " 1895,\n",
       " 2,\n",
       " 31,\n",
       " 240,\n",
       " 74,\n",
       " 21,\n",
       " 73,\n",
       " 768,\n",
       " 1406,\n",
       " 868,\n",
       " 253,\n",
       " 10,\n",
       " 55,\n",
       " 116,\n",
       " 141,\n",
       " 1513,\n",
       " 3,\n",
       " 75,\n",
       " 164,\n",
       " 50,\n",
       " 2,\n",
       " 962,\n",
       " 153,\n",
       " 37,\n",
       " 674,\n",
       " 141,\n",
       " 3,\n",
       " 2,\n",
       " 13038,\n",
       " 428,\n",
       " 72,\n",
       " 111,\n",
       " 2301,\n",
       " 329,\n",
       " 745,\n",
       " 8,\n",
       " 6,\n",
       " 836,\n",
       " 13203,\n",
       " 3,\n",
       " 28,\n",
       " 6,\n",
       " 1983,\n",
       " 649,\n",
       " 10,\n",
       " 16,\n",
       " 145,\n",
       " 92,\n",
       " 26,\n",
       " 251,\n",
       " 121,\n",
       " 21,\n",
       " 64,\n",
       " 66,\n",
       " 671,\n",
       " 46,\n",
       " 711,\n",
       " 100,\n",
       " 38817,\n",
       " 40892,\n",
       " 3,\n",
       " 711,\n",
       " 423,\n",
       " 3747,\n",
       " 21302,\n",
       " 5,\n",
       " 11400,\n",
       " 6329,\n",
       " 77,\n",
       " 37,\n",
       " 130,\n",
       " 3371,\n",
       " 3]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_clas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(LM_PATH/'tmp'/'val_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([0, 0, 0, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels[-10:], val_labels[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels.min(), trn_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels -= trn_labels.min()\n",
    "val_labels -= val_labels.min()\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 24, 1042, 25000, 128, 0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_ds), trn_dl.batch_size, len(trn_dl), len(trn_dl.dataset), len(trn_ds[0][0]), trn_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([688, 24]), torch.Size([24]), 48)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "      1      1      1  ...       1      1     40\n",
       "      1      1      1  ...       1     40     41\n",
       "      1      1      1  ...       1     41     42\n",
       "         ...            ⋱           ...         \n",
       "   1215      9     93  ...     223     38   8729\n",
       "   1146    367    145  ...     124    149      4\n",
       "      3      3      3  ...     183      3   3213\n",
       " [torch.LongTensor of size 688x24], \n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  1\n",
       "  1\n",
       " [torch.LongTensor of size 24])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-6\n",
    "learn.load_encoder('lm_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=20, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

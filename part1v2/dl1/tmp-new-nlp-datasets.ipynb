{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html\n",
    "\n",
    "import pdb\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "# pandas and plotting config\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = '<bos>'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def clean_text(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_example(row, txt_cols, lbl_cols=[], lbl_dtype=np.int64):\n",
    "    n_txt_cols = len(txt_cols)\n",
    "    n_label_cols = len(lbl_cols)\n",
    "    \n",
    "    labels = row[lbl_cols].values.astype(lbl_dtype) if (n_label_cols > 0) else []\n",
    "    \n",
    "    docs = f'\\n{BOS} {FLD} 1 ' + row[txt_cols[0]].astype(str)\n",
    "    for i, col in enumerate(lbl_cols[1:]):\n",
    "        docs += f' {FLD} {i+ 1} ' + row[col].astype(str)\n",
    "\n",
    "    docs = docs.apply(clean_text).values.astype(str)\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(docs))\n",
    "    \n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_examples(df, txt_cols, lbl_cols=[], lbl_dtype=np.int64):\n",
    "    tok, labels = [], []\n",
    "    \n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = process_example(r, txt_cols, lbl_cols, lbl_dtype)\n",
    "        tok += tok_\n",
    "        labels += labels_\n",
    "        \n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, tokens, min_freq=1, max_size=None, \n",
    "                 specials=['<unk>', '<pad>', '<bos>', '<eos>'], unk_idx=0):\n",
    "        \n",
    "        self.min_freq = max(min_freq, 1)\n",
    "        self.specials = specials\n",
    "        self.unk_idx = unk_idx\n",
    "        \n",
    "        self.tokens = list(specials)\n",
    "        self.max_size = None if max_size is None else max_size + len(self.tokens)\n",
    "        \n",
    "        self.token_freqs = Counter(tokens)\n",
    "        for t in self.specials: del self.token_freqs[t]\n",
    "            \n",
    "        # sort by frequency, then alphabetically\n",
    "        self.token_freqs = sorted(self.token_freqs.items(), key=lambda tf: tf[0])\n",
    "        self.token_freqs.sort(key=lambda tf: tf[1], reverse=True)\n",
    "        \n",
    "        for token, freq in self.token_freqs:\n",
    "            if freq < self.min_freq or len(self.tokens) == self.max_size:\n",
    "                break\n",
    "            self.tokens.append(token)\n",
    " \n",
    "        #itos\n",
    "        self.itos = self.tokens\n",
    "        \n",
    "        #stoi\n",
    "        stoi = defaultdict(lambda x: self.unk_idx) # default is <unk>\n",
    "        stoi.update({ tok: i for i, tok in enumerate(self.tokens) })\n",
    "        self.stoi = defaultdict(self.unk_token_idx, stoi)\n",
    "        \n",
    "    def unk_token_idx(self):\n",
    "        return self.unk_idx\n",
    "    \n",
    "    def token_freq(self, token):\n",
    "        return self.token_freqs.get(token, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, docs, vocab=None, min_freq=1, max_size=None):\n",
    "        self.tokens = []\n",
    "        for d in docs: self.tokens += d\n",
    "        \n",
    "        if (vocab):\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            self.vocab = Vocab(self.tokens, min_freq, max_size)\n",
    "        \n",
    "        self.data = np.array([[ self.vocab.stoi[t] for t in self.tokens ]])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB - Multi-classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= Path('data/aclImdb')\n",
    "TRN_PATH = PATH/'train'\n",
    "VAL_PATH = PATH/'test'\n",
    "\n",
    "LM_PATH = PATH/'imdb_lm'\n",
    "CLS_PATH = PATH/'imdb_class'\n",
    "\n",
    "(LM_PATH/'models').mkdir(parents=True, exist_ok=True)\n",
    "(LM_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "(CLS_PATH/'models').mkdir(parents=True, exist_ok=True)\n",
    "(CLS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "# [child for child in PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README      imdbEr.txt  \u001b[34mimdb_lm\u001b[m\u001b[m/    \u001b[34mtrain\u001b[m\u001b[m/\r\n",
      "imdb.vocab  \u001b[34mimdb_class\u001b[m\u001b[m/ \u001b[34mtest\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls {str(PATH)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of documents and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_docs, trn_labels = texts_labels_from_folders(TRN_PATH, ['neg', 'pos'])\n",
    "val_docs, val_labels = texts_labels_from_folders(VAL_PATH, ['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000, 12500, 12500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_docs), len(val_docs), len(trn_labels[trn_labels == 1]), len(trn_labels[trn_labels == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put documents and labels into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['review_text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.DataFrame({'review_text':trn_docs, 'label':trn_labels}, columns=col_names)\n",
    "val_df = pd.DataFrame({'review_text':val_docs, 'label':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       review_text  \\\n",
       "0  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.   \n",
       "\n",
       "   label  \n",
       "0  0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Working-class romantic drama from director Martin Ritt is as unbelievable as they come, yet there are moments of pleasure due mostly to the charisma of stars Jane Fonda and Robert De Niro (both terrific). She's a widow who can't move on, he's illiterate and a closet-inventor--you can probably guess the rest. Adaptation of Pat Barker's novel \"Union Street\" (a better title!) is so laid-back it verges on bland, and the film's editing is a mess, but it's still pleasant; a rosy-hued blue-collar fantasy. There are no overtures to serious issues (even the illiteracy angle is just a plot-tool for the ensuing love story) and no real fireworks, though the characters are intentionally a bit colorless and the leads are toned down to an interesting degree. The finale is pure fluff--and cynics will find it difficult to swallow--though these two characters deserve a happy ending and the picture wouldn't really be satisfying any other way. *** from ****</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   review_text  \\\n",
       "24999  Working-class romantic drama from director Martin Ritt is as unbelievable as they come, yet there are moments of pleasure due mostly to the charisma of stars Jane Fonda and Robert De Niro (both terrific). She's a widow who can't move on, he's illiterate and a closet-inventor--you can probably guess the rest. Adaptation of Pat Barker's novel \"Union Street\" (a better title!) is so laid-back it verges on bland, and the film's editing is a mess, but it's still pleasant; a rosy-hued blue-collar fantasy. There are no overtures to serious issues (even the illiteracy angle is just a plot-tool for the ensuing love story) and no real fireworks, though the characters are intentionally a bit colorless and the leads are toned down to an interesting degree. The finale is pure fluff--and cynics will find it difficult to swallow--though these two characters deserve a happy ending and the picture wouldn't really be satisfying any other way. *** from ****   \n",
       "\n",
       "       label  \n",
       "24999  1      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(trn_df.head(1))\n",
    "display(trn_df.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df.to_csv(CLS_PATH/'train.csv', index=False)\n",
    "val_df.to_csv(CLS_PATH/'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a language model, we want to use the entire corpus.  In the case of IMDB, only 50k of the 100k documents are labeled and so we look to the `train/all` and `test/all` folders to graby all 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_docs(path):\n",
    "    return [fname.open('r').read() for fname in (path/'all').glob('*.*')]\n",
    "\n",
    "all_docs = get_all_docs(TRN_PATH)\n",
    "all_docs += get_all_docs(VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_docs, val_docs = sklearn.model_selection.train_test_split(all_docs, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_docs), len(val_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_all_df = pd.DataFrame({'review_text':trn_docs}, columns=[col_names[0]])\n",
    "val_all_df = pd.DataFrame({'review_text':val_docs}, columns=[col_names[0]])\n",
    "\n",
    "trn_all_df.to_csv(LM_PATH/'train_all.csv', index=False)\n",
    "val_all_df.to_csv(LM_PATH/'test_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is another film I had missed out on a number of times on Cable TV in the past. It's considered something of a censorship milestone with the treatment of taboo subjects such as prostitution, homosexuality and pornography  not to mention the proliferation of bad language throughout (unfortunately, the DVD is said to contain the slightly edited PG-rated version, which cuts some brief nudity involving female lead Barbra Streisand and her use of the f-word in one scene)! &lt;br /&gt;&lt;br /&gt;With this in mind, one has to consider the development which the comedy genre underwent during this time: from the mildly risqué sophisticated antics of the Doris Day/Rock Hudson films of the early 1960s to the cynical anxiety-ridden variety that started emanating towards the tail-end of the decade  with which the likes of Jack Lemmon, George Segal (the male lead of this film) and, in particular, Woody Allen (since he was his own writer and mostly directed himself as well) are forever associated.&lt;br /&gt;&lt;br /&gt;THE OWL AND THE PUSSYCAT is also notable for giving the current female singing sensation  Barbra Streisand  her first non-musical role; in fact, it led to other wacky comedy vehicles: foremost among them WHAT'S UP, DOC? (1972; Peter Bogdanovich's updating of the Howard Hawks classic BRINGING UP BABY [1938]) and FOR PETE'S SAKE (1974; whose trailer, included on the Columbia R2 DVD of the film under review, makes it seem like a good deal of fun). Thanks largely to his role in the film, Segal went on to do his fair share of sex comedies up till the early 1980s  with the most successful among them being A TOUCH OF CLASS (1973), which I should be acquiring shortly.&lt;br /&gt;&lt;br /&gt;Anyway, to get to the main item: the film can be seen as a modern variation on the perennial \"Pygmalion\" theme  with Segal as intellectual but, at the same time, neurotic and Streisand the uncouth yet liberated woman. There's no plot to speak of  instead, we follow the two stars on a logical pattern of location-hopping around New York throughout which their relationship blossoms: from his apartment when she's evicted because of his snitching (which leads to both of them being given the gate by the landlord), to them shacking up at the flat of Segal's pal (who drives them out because of their constant bickering), then going their separate ways till they meet again (after he has learned about her movie experience  a hilarious scene  and a 'colleague' of hers has gone to see him at his workplace) and go out together (where they're harassed by a band of thrill-seekers), after which they find themselves at the house of Segal's fiancée (a scene with an unexpectedly ironic punchline), to finally deciding to be completely honest with one another (beginning with their real names).&lt;br /&gt;&lt;br /&gt;In this respect, the film emerges to be overly talky (betraying its stage origins) but there is a reasonable amount of invention and wit in the undeniable comedy highlights: Segal dressing up as Death to scare the hiccupping Streisand; Segal using an aquarium as a TV set  with him delivering an impromptu news flash  to humor the insomniac Streisand (her addiction to TV is illustrated by a surprising reference to the Lionel Atwill/Lon Chaney Jr. horror pic MAN MADE MONSTER [1941]); the couple's argument over \"the sun spat morning\" line in the opening paragraph of a book by aspiring novelist Segal; Streisand's account of the sordid activities her clients invariably came up with (prompting Segal to describe her as \"a sexual Disneyland\"), etc. The film's soundtrack is highlighted by several songs from jazz/rock band Blood, Sweat &amp; Tears.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Nemesis' was the last book to feature Miss Marple written by Agatha Christie (the official final case 'Sleeping Murder' was written in the forties) and I've always had a very soft spot for it. I loved the characters and they are lovingly brought to life in this excellent BBC adaptation with Joan Hickson, terrific as ever, as Miss Marple.&lt;br /&gt;&lt;br /&gt;On the whole it is very faithful to the book. A few characters are dropped, the first (new) murder is slightly different and a couple of new characters are introduced. Personally I felt that the added character of Lionel Peel was unnecessary and rather irritating. Tour guide Madge was irritating in a different way but often quite amusing. It's largely because of Lionel that I don't award 10 out of 10! The other characters are beautifully done especially Helen Cherry as a dignified Miss Temple and all of the three weird sisters but particularly Margaret Tyzack who gives a towering performance as Clothilde. She threatens to go over the top towards the end but just avoids it. The female bodyguards are good value too and the episode contains one of my favourite Hickson lines...'An Archdeacon?!' &lt;br /&gt;&lt;br /&gt;This is another relatively early BBC Marple that looks wonderful and is has a gloriously nostalgic feel to it. Highly recommended.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             review_text\n",
       "0  This is another film I had missed out on a number of times on Cable TV in the past. It's considered something of a censorship milestone with the treatment of taboo subjects such as prostitution, homosexuality and pornography  not to mention the proliferation of bad language throughout (unfortunately, the DVD is said to contain the slightly edited PG-rated version, which cuts some brief nudity involving female lead Barbra Streisand and her use of the f-word in one scene)! <br /><br />With this in mind, one has to consider the development which the comedy genre underwent during this time: from the mildly risqué sophisticated antics of the Doris Day/Rock Hudson films of the early 1960s to the cynical anxiety-ridden variety that started emanating towards the tail-end of the decade  with which the likes of Jack Lemmon, George Segal (the male lead of this film) and, in particular, Woody Allen (since he was his own writer and mostly directed himself as well) are forever associated.<br /><br />THE OWL AND THE PUSSYCAT is also notable for giving the current female singing sensation  Barbra Streisand  her first non-musical role; in fact, it led to other wacky comedy vehicles: foremost among them WHAT'S UP, DOC? (1972; Peter Bogdanovich's updating of the Howard Hawks classic BRINGING UP BABY [1938]) and FOR PETE'S SAKE (1974; whose trailer, included on the Columbia R2 DVD of the film under review, makes it seem like a good deal of fun). Thanks largely to his role in the film, Segal went on to do his fair share of sex comedies up till the early 1980s  with the most successful among them being A TOUCH OF CLASS (1973), which I should be acquiring shortly.<br /><br />Anyway, to get to the main item: the film can be seen as a modern variation on the perennial \"Pygmalion\" theme  with Segal as intellectual but, at the same time, neurotic and Streisand the uncouth yet liberated woman. There's no plot to speak of  instead, we follow the two stars on a logical pattern of location-hopping around New York throughout which their relationship blossoms: from his apartment when she's evicted because of his snitching (which leads to both of them being given the gate by the landlord), to them shacking up at the flat of Segal's pal (who drives them out because of their constant bickering), then going their separate ways till they meet again (after he has learned about her movie experience  a hilarious scene  and a 'colleague' of hers has gone to see him at his workplace) and go out together (where they're harassed by a band of thrill-seekers), after which they find themselves at the house of Segal's fiancée (a scene with an unexpectedly ironic punchline), to finally deciding to be completely honest with one another (beginning with their real names).<br /><br />In this respect, the film emerges to be overly talky (betraying its stage origins) but there is a reasonable amount of invention and wit in the undeniable comedy highlights: Segal dressing up as Death to scare the hiccupping Streisand; Segal using an aquarium as a TV set  with him delivering an impromptu news flash  to humor the insomniac Streisand (her addiction to TV is illustrated by a surprising reference to the Lionel Atwill/Lon Chaney Jr. horror pic MAN MADE MONSTER [1941]); the couple's argument over \"the sun spat morning\" line in the opening paragraph of a book by aspiring novelist Segal; Streisand's account of the sordid activities her clients invariably came up with (prompting Segal to describe her as \"a sexual Disneyland\"), etc. The film's soundtrack is highlighted by several songs from jazz/rock band Blood, Sweat & Tears.\n",
       "1  'Nemesis' was the last book to feature Miss Marple written by Agatha Christie (the official final case 'Sleeping Murder' was written in the forties) and I've always had a very soft spot for it. I loved the characters and they are lovingly brought to life in this excellent BBC adaptation with Joan Hickson, terrific as ever, as Miss Marple.<br /><br />On the whole it is very faithful to the book. A few characters are dropped, the first (new) murder is slightly different and a couple of new characters are introduced. Personally I felt that the added character of Lionel Peel was unnecessary and rather irritating. Tour guide Madge was irritating in a different way but often quite amusing. It's largely because of Lionel that I don't award 10 out of 10! The other characters are beautifully done especially Helen Cherry as a dignified Miss Temple and all of the three weird sisters but particularly Margaret Tyzack who gives a towering performance as Clothilde. She threatens to go over the top towards the end but just avoids it. The female bodyguards are good value too and the episode contains one of my favourite Hickson lines...'An Archdeacon?!' <br /><br />This is another relatively early BBC Marple that looks wonderful and is has a gloriously nostalgic feel to it. Highly recommended.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_all_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and tokenize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_all_df = pd.read_csv(LM_PATH/'train_all.csv', chunksize=chunksize)\n",
    "val_all_df = pd.read_csv(LM_PATH/'test_all.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trn_toks, _ = process_examples(trn_all_df, [col_names[0]])\n",
    "val_toks, _ = process_examples(val_all_df, [col_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_toks), len(val_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '<bos>', 'xfld', '1', 'this', 'is', 'another', 'film', 'i', 'had', 'missed', 'out', 'on', 'a', 'number']\n"
     ]
    }
   ],
   "source": [
    "print(trn_toks[0][:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', trn_toks)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', val_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_toks = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "val_toks = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the vocab and build the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.74 s, sys: 392 ms, total: 10.1 s\n",
      "Wall time: 10.1 s\n",
      "CPU times: user 577 ms, sys: 32.6 ms, total: 609 ms\n",
      "Wall time: 609 ms\n"
     ]
    }
   ],
   "source": [
    "%time trn_ds = LanguageDataset(np.concatenate((trn_toks, val_toks)), min_freq=min_freq, max_size=max_vocab)\n",
    "%time val_ds = LanguageDataset(val_toks, vocab=trn_ds.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27787632 27787632 60004 1\n",
      "2795406 2795406 60004 1\n"
     ]
    }
   ],
   "source": [
    "print(len(trn_ds[0]), len(trn_ds.tokens), len(trn_ds.vocab.tokens), len(trn_ds))\n",
    "print(len(val_ds[0]), len(val_ds.tokens), len(val_ds.vocab.tokens), len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 42   2  43  41  15  11 175  27  14  85]\n",
      "['\\n', '<bos>', 'xfld', '1', 'this', 'is', 'another', 'film', 'i', 'had']\n"
     ]
    }
   ],
   "source": [
    "print(trn_ds[0][:10])\n",
    "print([ trn_ds.vocab.itos[idx] for idx in trn_ds[0][:10] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure and build the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 70\n",
    "bsz = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(trn_ds[0], bsz, bptt)\n",
    "val_dl = LanguageModelLoader(val_ds[0], bsz, bptt)\n",
    "\n",
    "md = LanguageModelData(PATH, 1, len(trn_ds.vocab.tokens), trn_dl, val_dl, bs=bsz, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7632, 60004, 1, 27787632)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(trn_ds), len(trn_ds.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([69, 52])\n",
      "torch.Size([3588])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(md.trn_dl))\n",
    "print(batch[0].size()), print(batch[1].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(CLS_PATH/'train.csv', chunksize=chunksize)\n",
    "val_df = pd.read_csv(CLS_PATH/'test.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "trn_toks, trn_labels = process_examples(trn_df, [col_names[0]], [col_names[1]])\n",
    "val_toks, val_labels = process_examples(val_df, [col_names[0]], [col_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLS_PATH/'tmp'/'tok_trn.npy', trn_toks)\n",
    "np.save(CLS_PATH/'tmp'/'tok_val.npy', val_toks)\n",
    "\n",
    "np.save(CLS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_toks = np.load(CLS_PATH/'tmp'/'tok_trn.npy')\n",
    "val_toks = np.load(CLS_PATH/'tmp'/'tok_val.npy')\n",
    "\n",
    "trn_labels = np.load(CLS_PATH/'tmp'/'trn_labels.npy')\n",
    "val_labels = np.load(CLS_PATH/'tmp'/'val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 335844),\n",
       " ('.', 277583),\n",
       " (',', 275297),\n",
       " ('and', 163775),\n",
       " ('a', 162489),\n",
       " ('of', 145813),\n",
       " ('to', 135629),\n",
       " ('is', 110387),\n",
       " ('it', 95826),\n",
       " ('in', 93847)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in trn_toks for p in o)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "# stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "# len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = trn_ds.vocab\n",
    "\n",
    "trn_clas = np.array([[vocab.stoi[o] for o in p] for p in trn_toks])\n",
    "val_clas = np.array([[vocab.stoi[o] for o in p] for p in val_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 2, 43, 41, 82, 9, 8, 145, 49, 60, 7108, 1428, 24, 8, 4388, 5, 529, 61, 23, 8, 651, 150, 16, 11, 8, 1359, 513, 9, 1904, 224, 5, 8, 11301, 7170, 329, 11, 663, 103, 48, 2028, 6, 1065, 2499, 47, 4, 955, 0, 9, 12, 18, 5991, 5, 496, 12, 2937, 1904, 4, 33, 240, 75, 23, 74, 774, 1411, 871, 255, 12, 56, 117, 141, 1509, 5, 76, 165, 51, 4, 970, 154, 39, 663, 141, 5, 4, 12894, 427, 73, 114, 2307, 328, 752, 10, 8, 845, 12432, 5, 30, 8, 1965, 648, 12, 18, 146, 93, 28, 253, 122, 23, 65, 67, 665, 47, 713, 102, 39512, 41578, 5, 713, 428, 3597, 22380, 7, 11229, 6384, 78, 39, 131, 3368, 5]\n"
     ]
    }
   ],
   "source": [
    "print(trn_clas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(trn_labels)\n",
    "val_labels = np.squeeze(trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels -= trn_labels.min()\n",
    "val_labels -= val_labels.min()\n",
    "c=int(trn_labels.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bsz//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bsz//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bsz, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 26, 962, 25000, 128, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_ds), trn_dl.batch_size, len(trn_dl), len(trn_dl.dataset), len(trn_ds[0][0]), trn_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([259, 26]) torch.LongTensor torch.Size([26]) torch.LongTensor 52\n"
     ]
    }
   ],
   "source": [
    "print(x.size(), x.type(), y.size(), y.type(), bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOXIC- Multi-label problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH= Path('data/toxic-comment')\n",
    "\n",
    "(PATH/'models').mkdir(parents=True, exist_ok=True)\n",
    "(PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "# [child for child in PATH.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(PATH/'train.csv')\n",
    "test_df = pd.read_csv(PATH/'test.csv')\n",
    "sample_subm_df = pd.read_csv(PATH/'sample_submission.csv')\n",
    "\n",
    "txt_col = 'comment_text'\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "raw_train_df['none'] = 1 - raw_train_df[label_cols].max(axis=1)\n",
    "\n",
    "model_cols = ['id', txt_col] + label_cols + ['none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91058 4793 9288 502\n"
     ]
    }
   ],
   "source": [
    "# split the training data into a train and validatin dataset\n",
    "trn, val = train_test_split(raw_train_df, test_size=0.05, random_state=9)\n",
    "print(len(trn), len(val), len(trn[trn.none != 1]), len(val[val.none != 1]))\n",
    "\n",
    "# save train, val, and test datasets for torchtext\n",
    "trn[model_cols].to_csv(PATH/'train_ds.csv', index=None)\n",
    "val[model_cols].to_csv(PATH/'valid_ds.csv', index=None)\n",
    "\n",
    "# save full cleaned datasets (train+valid and test) as well\n",
    "raw_train_df[model_cols].to_csv(PATH/'full_train_ds.csv', index=None)\n",
    "test_df[['id', txt_col]].to_csv(PATH/'test_ds.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you did with this edit to W. S. Merwin. If you continue to do so, you will be blocked from editing.    \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  22256635   \n",
       "1  27450690   \n",
       "\n",
       "                                                                                                                                       comment_text  \\\n",
       "0  Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.                                                                \n",
       "1  \"\\n\\n Please do not vandalize pages, as you did with this edit to W. S. Merwin. If you continue to do so, you will be blocked from editing.    \"   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  none  \n",
       "0  1      0             0        0       0       0              0     \n",
       "1  0      0             0        0       0       0              1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6044863</td>\n",
       "      <td>==Orphaned non-free media (Image:41cD1jboEvL. SS500 .jpg)==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6102620</td>\n",
       "      <td>::Kentuckiana is colloquial.  Even though the area is often referred to as this, it (in my opinion) has never held the encyclopedic precision of \"Louisville metropolitian area\", which has a specific U.S. Census definition.  Also, apparently Kentuckiana often refers to the local television viewing area, which isn't nearly contiguous with the official metro area.  As you indicate, Kentuckiana seems to be more of a slang or marketing phenomena than anything we could pin down in encyclopedic terms here.  That's why we see Wikipedia language like \"the Louisville metropolitan area, sometimes referred to as Kentuckiana\". That's my take on it. —   •</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "0  6044863   \n",
       "1  6102620   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                comment_text  \n",
       "0  ==Orphaned non-free media (Image:41cD1jboEvL. SS500 .jpg)==                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1  ::Kentuckiana is colloquial.  Even though the area is often referred to as this, it (in my opinion) has never held the encyclopedic precision of \"Louisville metropolitian area\", which has a specific U.S. Census definition.  Also, apparently Kentuckiana often refers to the local television viewing area, which isn't nearly contiguous with the official metro area.  As you indicate, Kentuckiana seems to be more of a slang or marketing phenomena than anything we could pin down in encyclopedic terms here.  That's why we see Wikipedia language like \"the Louisville metropolitan area, sometimes referred to as Kentuckiana\". That's my take on it. —   •  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.read_csv(PATH/\"full_train_ds.csv\").head(2))\n",
    "display(pd.read_csv(PATH/\"test_ds.csv\").head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean and tokenize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 100000 #30000\n",
    "min_freq = 10 #0\n",
    "max_len = 175 #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(PATH/'train_ds.csv', chunksize=chunksize)\n",
    "val_df = pd.read_csv(PATH/'valid_ds.csv', chunksize=chunksize)\n",
    "test_df = pd.read_csv(PATH/'test_ds.csv', chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "trn_docs, trn_labels = process_examples(trn_df, [txt_col], label_cols, lbl_dtype=np.float32)\n",
    "val_docs, val_labels = process_examples(val_df, [txt_col], label_cols, lbl_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91058, 4793, (6,), (6,))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_docs), len(val_docs), trn_labels[0].shape, val_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xfld', 546348),\n",
       " ('0', 444487),\n",
       " ('.', 297272),\n",
       " ('the', 283109),\n",
       " (',', 269182),\n",
       " ('\"', 214611),\n",
       " ('1', 196267),\n",
       " ('to', 169607),\n",
       " ('\\n', 140276),\n",
       " ('i', 137007)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in trn_docs for p in o)\n",
    "freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocab, fix lengths of each document, and numericalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toks = []\n",
    "for doc in np.concatenate((trn_docs, val_docs)): all_toks += doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab(all_toks, min_freq, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_docs = [ d[:max_len] + ['<pad>']*(max_len-len(d)) for d in trn_docs ]\n",
    "val_docs = [ d[:max_len] + ['<pad>']*(max_len-len(d)) for d in val_docs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_toks = np.array([ [vocab.stoi[o] for o in p] for p in trn_docs ])\n",
    "val_toks = np.array([ [vocab.stoi[o] for o in p] for p in val_docs ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91058, 4793, 175)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_toks), len(val_toks), len(trn_toks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(trn_labels)\n",
    "val_labels = np.squeeze(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91058, 6), (4793, 6))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build datasets and data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 64\n",
    "pretrained_vectors = None #'fasttext.en.300d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_toks, trn_labels)\n",
    "val_ds = TextDataset(val_toks, val_labels)\n",
    "\n",
    "trn_samp = SortishSampler(trn_toks, key=lambda x: len(trn_toks[x]), bs=bsz//2)\n",
    "val_samp = SortSampler(val_toks, key=lambda x: len(val_toks[x]))\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bsz//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bsz, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91058, 32, 2846, 91058, 175, array([0., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_ds), trn_dl.batch_size, len(trn_dl), len(trn_dl.dataset), len(trn_ds[0][0]), trn_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([175, 32]) torch.LongTensor torch.Size([32, 6]) torch.FloatTensor 64\n"
     ]
    }
   ],
   "source": [
    "print(x.size(), x.type(), y.size(), y.type(), bsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

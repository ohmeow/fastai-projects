{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai.structured import *\n",
    "from fastai import sgdr\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "# pandas and plotting config\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this if tqdm goes crazy (see http://forums.fast.ai/t/a-christmas-gift/9163?u=wgpubs)\n",
    "from tqdm import tqdm as tqdm_cls\n",
    "\n",
    "inst = tqdm_cls._instances\n",
    "for i in range(len(inst)): inst.pop().close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/toxic-comments'\n",
    "\n",
    "os.makedirs(f'{PATH}/models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df = pd.read_csv(f'{PATH}/train.csv')\n",
    "test_df = pd.read_csv(f'{PATH}/test.csv')\n",
    "sample_subm_df = pd.read_csv(f'{PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 95851 | Test size: 153164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22256635</td>\n",
       "      <td>Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27450690</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you did with this edit to W. S. Merwin. If you continue to do so, you will be blocked from editing.    \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54037174</td>\n",
       "      <td>\"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the \"\"points of interest\"\" section you added because it seemed kind of spammy. I know you probably didn't mean to disobey the rules, but generally, a point of interest tends to be rather touristy, and quite irrelevant to an area culture. That's just my opinion, though.\\n\\nIf you want to reply, just put your reply here and add {{talkback|Jamiegraham08}} on my talkpage.   \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  \\\n",
       "0  22256635   \n",
       "1  27450690   \n",
       "2  54037174   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                        comment_text  \\\n",
       "0  Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.                                                                                                                                                                                                                                                                                                                                                 \n",
       "1  \"\\n\\n Please do not vandalize pages, as you did with this edit to W. S. Merwin. If you continue to do so, you will be blocked from editing.    \"                                                                                                                                                                                                                                                                                    \n",
       "2  \"\\n\\n \"\"Points of interest\"\" \\n\\nI removed the \"\"points of interest\"\" section you added because it seemed kind of spammy. I know you probably didn't mean to disobey the rules, but generally, a point of interest tends to be rather touristy, and quite irrelevant to an area culture. That's just my opinion, though.\\n\\nIf you want to reply, just put your reply here and add {{talkback|Jamiegraham08}} on my talkpage.   \"   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0  1      0             0        0       0       0              \n",
       "1  0      0             0        0       0       0              \n",
       "2  0      0             0        0       0       0              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is, IMO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  00001cee341fdb12   \n",
       "1  0000247867823ef7   \n",
       "2  00013b17ad220c46   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      comment_text  \n",
       "0  Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,  \n",
       "1  == From RfC == \\n\\n The title is fine as it is, IMO.                                                                                                                                                                                                                                                                                                                             \n",
       "2  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"                                                                                                                                                                                                                                                                                                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12  0.5    0.5           0.5      0.5     0.5      \n",
       "1  0000247867823ef7  0.5    0.5           0.5      0.5     0.5      \n",
       "2  00013b17ad220c46  0.5    0.5           0.5      0.5     0.5      \n",
       "\n",
       "   identity_hate  \n",
       "0  0.5            \n",
       "1  0.5            \n",
       "2  0.5            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Train size: {len(raw_train_df)} | Test size: {len(test_df)}')\n",
    "display(raw_train_df.head(3))\n",
    "display(test_df.head(3))\n",
    "display(sample_subm_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.99436e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0963683</td>\n",
       "      <td>0.0100677</td>\n",
       "      <td>0.0533015</td>\n",
       "      <td>0.00318202</td>\n",
       "      <td>0.0497126</td>\n",
       "      <td>0.00849235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.89014e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295097</td>\n",
       "      <td>0.0998321</td>\n",
       "      <td>0.224635</td>\n",
       "      <td>0.0563199</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>0.0917623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.22566e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.47344e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.0013e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.50109e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.99988e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>numeric</td>\n",
       "      <td>unique</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id comment_text      toxic severe_toxic    obscene  \\\n",
       "count         95851        NaN          95851      95851        95851       \n",
       "mean          4.99436e+11  NaN          0.0963683  0.0100677    0.0533015   \n",
       "std           2.89014e+11  NaN          0.295097   0.0998321    0.224635    \n",
       "min           2.22566e+07  NaN          0          0            0           \n",
       "25%           2.47344e+11  NaN          0          0            0           \n",
       "50%           5.0013e+11   NaN          0          0            0           \n",
       "75%           7.50109e+11  NaN          0          0            0           \n",
       "max           9.99988e+11  NaN          1          1            1           \n",
       "counts        95851        95851        95851      95851        95851       \n",
       "uniques       95851        95851        2          2            2           \n",
       "missing       0            0            0          0            0           \n",
       "missing_perc  0%           0%           0%         0%           0%          \n",
       "types         numeric      unique       bool       bool         bool        \n",
       "\n",
       "                  threat     insult identity_hate  \n",
       "count         95851       95851      95851         \n",
       "mean          0.00318202  0.0497126  0.00849235    \n",
       "std           0.0563199   0.217352   0.0917623     \n",
       "min           0           0          0             \n",
       "25%           0           0          0             \n",
       "50%           0           0          0             \n",
       "75%           0           0          0             \n",
       "max           1           1          1             \n",
       "counts        95851       95851      95851         \n",
       "uniques       2           2          2             \n",
       "missing       0           0          0             \n",
       "missing_perc  0%          0%         0%            \n",
       "types         bool        bool       bool          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameSummary(raw_train_df).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mean: 395.34', ' Standard Deviation: 595.10', 'Max: 5000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_len = raw_train_df.comment_text.str.len()\n",
    "f'Mean: {comment_len.mean():.2f}', f' Standard Deviation: {comment_len.std():.2f}', f'Max: {comment_len.max()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mean: 364.88', ' Standard Deviation: 592.49', 'Max: 5000')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment_len = test_df.comment_text.str.len()\n",
    "f'Mean: {test_comment_len.mean():.2f}', f' Standard Deviation: {test_comment_len.std():.2f}', f'Max: {test_comment_len.max()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.comment_text = test_df.comment_text.str[0:5000]\n",
    "\n",
    "raw_train_df.comment_text.fillna(\"unknown\", inplace=True)\n",
    "test_df.comment_text.fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ded967588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ded967ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comment_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.99436e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0963683</td>\n",
       "      <td>0.0100677</td>\n",
       "      <td>0.0533015</td>\n",
       "      <td>0.00318202</td>\n",
       "      <td>0.0497126</td>\n",
       "      <td>0.00849235</td>\n",
       "      <td>0.897862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.89014e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295097</td>\n",
       "      <td>0.0998321</td>\n",
       "      <td>0.224635</td>\n",
       "      <td>0.0563199</td>\n",
       "      <td>0.217352</td>\n",
       "      <td>0.0917623</td>\n",
       "      <td>0.302831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.22566e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.47344e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.0013e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.50109e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.99988e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>95851</td>\n",
       "      <td>95851</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>numeric</td>\n",
       "      <td>unique</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id comment_text      toxic severe_toxic    obscene  \\\n",
       "count         95851        NaN          95851      95851        95851       \n",
       "mean          4.99436e+11  NaN          0.0963683  0.0100677    0.0533015   \n",
       "std           2.89014e+11  NaN          0.295097   0.0998321    0.224635    \n",
       "min           2.22566e+07  NaN          0          0            0           \n",
       "25%           2.47344e+11  NaN          0          0            0           \n",
       "50%           5.0013e+11   NaN          0          0            0           \n",
       "75%           7.50109e+11  NaN          0          0            0           \n",
       "max           9.99988e+11  NaN          1          1            1           \n",
       "counts        95851        95851        95851      95851        95851       \n",
       "uniques       95851        95851        2          2            2           \n",
       "missing       0            0            0          0            0           \n",
       "missing_perc  0%           0%           0%         0%           0%          \n",
       "types         numeric      unique       bool       bool         bool        \n",
       "\n",
       "                  threat     insult identity_hate      none  \n",
       "count         95851       95851      95851         95851     \n",
       "mean          0.00318202  0.0497126  0.00849235    0.897862  \n",
       "std           0.0563199   0.217352   0.0917623     0.302831  \n",
       "min           0           0          0             0         \n",
       "25%           0           0          0             1         \n",
       "50%           0           0          0             1         \n",
       "75%           0           0          0             1         \n",
       "max           1           1          1             1         \n",
       "counts        95851       95851      95851         95851     \n",
       "uniques       2           2          2             2         \n",
       "missing       0           0          0             0         \n",
       "missing_perc  0%          0%         0%            0%        \n",
       "types         bool        bool       bool          bool      "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "raw_train_df['none'] = 1 - raw_train_df[label_cols].max(axis=1)\n",
    "\n",
    "DataFrameSummary(raw_train_df).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>153164</td>\n",
       "      <td>153164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>153164</td>\n",
       "      <td>153164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>09b56e282e874eac</td>\n",
       "      <td>Well as expected, two administrators, RRick and Gadfium, staff engineers in Silicon Valley have started using their deleting power on a newbie.  Because they have to make sure African Americans are constantly denegrated and under attack, they will maintain their unbelievable attention to this stupid page, which only race oriented people would use ask their definition guide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>153164</td>\n",
       "      <td>153164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>153164</td>\n",
       "      <td>153164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>unique</td>\n",
       "      <td>unique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "count         153164             \n",
       "unique        153164             \n",
       "top           09b56e282e874eac   \n",
       "freq          1                  \n",
       "counts        153164             \n",
       "uniques       153164             \n",
       "missing       0                  \n",
       "missing_perc  0%                 \n",
       "types         unique             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                          comment_text  \n",
       "count         153164                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "unique        153164                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "top           Well as expected, two administrators, RRick and Gadfium, staff engineers in Silicon Valley have started using their deleting power on a newbie.  Because they have to make sure African Americans are constantly denegrated and under attack, they will maintain their unbelievable attention to this stupid page, which only race oriented people would use ask their definition guide!  \n",
       "freq          1                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "counts        153164                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "uniques       153164                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "missing       0                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "missing_perc  0%                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "types         unique                                                                                                                                                                                                                                                                                                                                                                                    "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrameSummary(test_df).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95851, 153164)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try this clean function from https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view\n",
    "# Aphost lookup dict\n",
    "APPO = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "lem = WordNetLemmatizer()\n",
    "tweet_tokenizer=TweetTokenizer()\n",
    "\n",
    "def clean(comment):\n",
    "    \"\"\"\n",
    "    This function receives comments and returns clean word-list\n",
    "    \"\"\"\n",
    "    #Convert to lower case , so that Hi and hi are the same\n",
    "    comment=comment.lower()\n",
    "    #remove \\n\n",
    "    comment=re.sub(\"\\\\n\",\"\",comment)\n",
    "    # remove leaky elements like ip,user\n",
    "    comment=re.sub(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\",\"\",comment)\n",
    "    #removing usernames\n",
    "    comment=re.sub(\"\\[\\[.*\\]\",\"\",comment)\n",
    "    \n",
    "    #Split the sentences into words\n",
    "    words=tweet_tokenizer.tokenize(comment)\n",
    "    \n",
    "    # (')aphostophe  replacement (ie)   you're --> you are  \n",
    "    # ( basic dictionary lookup : master dictionary present in a hidden block of code)\n",
    "    words=[APPO[word] if word in APPO else word for word in words]\n",
    "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [w for w in words if not w in eng_stopwords]\n",
    "    \n",
    "    clean_sent=\" \".join(words)\n",
    "    # remove any non alphanum,digit character\n",
    "    #clean_sent=re.sub(\"\\W+\",\" \",clean_sent)\n",
    "    #clean_sent=re.sub(\"  \",\" \",clean_sent)\n",
    "    return(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_df['clean_comment_text'] = raw_train_df.comment_text.apply(lambda x: clean(x))\n",
    "test_df['clean_comment_text'] = test_df.comment_text.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset and ModelData classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMultiLabelDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, df, tt_text_field, tt_label_field, txt_col, lbl_cols, **kwargs):\n",
    "        # torchtext Field objects\n",
    "        fields = [('text', tt_text_field)]\n",
    "        for l in lbl_cols: fields.append((l, tt_label_field))\n",
    "            \n",
    "        is_test = False if lbl_cols[0] in df.columns else True\n",
    "        n_labels = len(lbl_cols)\n",
    "        \n",
    "        examples = []\n",
    "        for idx, row in df.iterrows():\n",
    "            if not is_test:\n",
    "                lbls = [ row[l] for l in lbl_cols ]\n",
    "            else:\n",
    "                lbls = [0.0] * n_labels\n",
    "                \n",
    "            txt = str(row[txt_col])\n",
    "            examples.append(data.Example.fromlist([txt]+lbls, fields))\n",
    "                            \n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(example): \n",
    "        return len(example.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, train_df, txt_col, lbl_cols, val_df=None, test_df=None, **kwargs):\n",
    "        # build train, val, and test data\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        \n",
    "        if train_df is not None: \n",
    "            train_data = cls(train_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if val_df is not None: \n",
    "            val_data = cls(val_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if test_df is not None: \n",
    "            test_data = cls(test_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMultiLabelDataLoader():\n",
    "    def __init__(self, src, x_fld, y_flds, y_dtype='torch.cuda.FloatTensor'):\n",
    "        self.src, self.x_fld, self.y_flds = src, x_fld, y_flds\n",
    "        self.y_dtype = y_dtype\n",
    "\n",
    "    def __len__(self): return len(self.src)#-1\n",
    "\n",
    "    def __iter__(self):\n",
    "        it = iter(self.src)\n",
    "        for i in range(len(self)):\n",
    "            b = next(it)\n",
    "            \n",
    "            if (len(self.y_flds) > 1):\n",
    "                targ = [ getattr(b, y) for y in self.y_flds ] \n",
    "                targ = torch.stack(targ, dim=1).type(self.y_dtype)\n",
    "            else: \n",
    "                targ = getattr(b, self.y_flds[0])\n",
    "                targ = targ.type(self.y_dtype)\n",
    "\n",
    "            yield getattr(b, self.x_fld), targ\n",
    "\n",
    "class TextMultiLabelData(ModelData):\n",
    "\n",
    "    @classmethod\n",
    "    def from_splits(cls, path, splits, bs, text_name='text', label_names=['label'], \n",
    "                    target_dtype='torch.cuda.FloatTensor'):\n",
    "        \n",
    "        text_fld = splits[0].fields[text_name]\n",
    "        \n",
    "        label_flds = []\n",
    "        if (len(label_names) == 1): \n",
    "            label_fld = splits[0].fields[label_names[0]]\n",
    "            label_flds.append(label_fld)\n",
    "            if (label_fld.use_vocab): \n",
    "                label_fld.build_vocab(splits[0])\n",
    "                target_dtype = 'torch.cuda.LongTensor'\n",
    "        else:\n",
    "            for n in label_names:\n",
    "                label_fld = splits[0].fields[n]\n",
    "                label_flds.append(label_fld)\n",
    "\n",
    "        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n",
    "        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n",
    "        test_dl = None\n",
    "        if len(iters) == 3:\n",
    "            test_iter = iters[2]\n",
    "            test_dl = TextMultiLabelDataLoader(test_iter, text_name, label_names, target_dtype)\n",
    "        trn_dl = TextMultiLabelDataLoader(trn_iter, text_name, label_names, target_dtype)\n",
    "        val_dl = TextMultiLabelDataLoader(val_iter, text_name, label_names, target_dtype)\n",
    "\n",
    "        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n",
    "        obj.bs = bs\n",
    "        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n",
    "        obj.nt = len(text_fld.vocab)\n",
    "\n",
    "        # if multiple labels, assume the # of classes = the # of labels \n",
    "        if (len(label_names) > 1):\n",
    "            c = len(label_names)\n",
    "        # if label has a vocab, assume the vocab represents the # of classes\n",
    "        elif (hasattr(label_flds[0], 'vocab')): \n",
    "            c = len(label_flds[0].vocab)\n",
    "        else:\n",
    "            c = 1\n",
    "            \n",
    "        obj.c = c\n",
    "\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizer(text): # create a tokenizer function\n",
    "# #     return text.split()\n",
    "#     return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeremy's tokenizer from his kernel here: https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline-eda-0-052-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenizer(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 8 #16 #32 #64\n",
    "\n",
    "max_tokens = 20000 # max number of words based on frequency\n",
    "max_len = None #100      # max length of each comment to look at\n",
    "\n",
    "n_hidden = 256\n",
    "n_fac = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bsz, \n",
    "                 fc_szs=[], fc_drops=[], n_lstm_hidden=256, n_lstm_layers=1, out_sz=1,\n",
    "                 lstm_drop=0.5, is_multi=False, y_range=None, use_bn=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size, self.out_sz = vocab_size, out_sz\n",
    "        self.n_lstm_layers, self.n_lstm_hidden = n_lstm_layers, n_lstm_hidden\n",
    "        \n",
    "        self.is_multi = is_multi\n",
    "        self.y_range = y_range\n",
    "        self.use_bn = use_bn\n",
    "        \n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.e.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.rnn = nn.LSTM(n_fac, n_lstm_hidden, n_lstm_layers, dropout=lstm_drop)\n",
    "        \n",
    "        fc_szs = [n_lstm_hidden] + fc_szs\n",
    "        \n",
    "        self.linears, self.linear_drops, self.linear_bns = [], [], []\n",
    "        if (len(fc_szs) > 1):\n",
    "            self.linears = nn.ModuleList(\n",
    "                [ nn.Linear(fc_szs[idx], sz) for idx, sz in enumerate(fc_szs[1:]) ]\n",
    "            )\n",
    "            \n",
    "            self.linear_bns = nn.ModuleList(\n",
    "                [ nn.BatchNorm1d(sz) for sz in fc_szs[1:] ]\n",
    "            )\n",
    "            \n",
    "            for l in self.linears: kaiming_normal(l.weight.data)\n",
    "                \n",
    "        if (len(fc_drops) > 0):\n",
    "            self.linear_drops = nn.ModuleList([ nn.Dropout(d) for d in fc_drops ])\n",
    "                \n",
    "        self.outp = nn.Linear(fc_szs[-1], out_sz)\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "            \n",
    "        self.h = self.init_hidden(bsz)\n",
    "        \n",
    "    def forward(self, words):\n",
    "        bsz = words[0].size(0)\n",
    "        if (self.h[0].size(1) != bsz): self.h = self.init_hidden(bsz)\n",
    "            \n",
    "        x, h = self.rnn(self.e(words), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        \n",
    "        x = x[-1]\n",
    "        \n",
    "        for l, d, b in zip(self.linears, self.linear_drops, self.linear_bns):\n",
    "            x = F.relu(l(x))\n",
    "            if (self.use_bn): x = b(x)\n",
    "            x = d(x)\n",
    "        \n",
    "        x = self.outp(x)\n",
    "\n",
    "        if (self.is_multi):\n",
    "            return F.sigmoid(x)\n",
    "        \n",
    "        if (not self.is_multi and self.out_sz > 1):\n",
    "            return F.log_softmax(x)\n",
    "        \n",
    "        if (self.y_range):\n",
    "            x = F.sigmoid(x)\n",
    "            x = x * (self.y_range[1] - self.y_range[0])\n",
    "            x = x + self.y_range[0]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        return(V(torch.zeros(self.n_lstm_layers, bsz, self.n_lstm_hidden)), \n",
    "               V(torch.zeros(self.n_lstm_layers, bsz, self.n_lstm_hidden)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Multi-Label Classification\n",
    "\n",
    "Predict class probabilities where multiple classes can be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86266, 9585, 153164)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_col = 'clean_comment_text'\n",
    "\n",
    "val_idxs = get_cv_idxs(len(raw_train_df), val_pct=0.1)\n",
    "\n",
    "train_df =  raw_train_df.drop(val_idxs)\n",
    "val_df = raw_train_df.copy().iloc[val_idxs]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure target fields are the correct datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    int64  \n",
       "comment_text          object \n",
       "toxic                 float32\n",
       "severe_toxic          float32\n",
       "obscene               float32\n",
       "threat                float32\n",
       "insult                float32\n",
       "identity_hate         float32\n",
       "none                  float32\n",
       "clean_comment_text    object \n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[label_cols + ['none']] = train_df[label_cols + ['none']].astype(np.float32)\n",
    "val_df[label_cols + ['none']] = val_df[label_cols + ['none']].astype(np.float32)\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our label is essentially a OHE vector, set `use_vocab=False` for the label's torchtext field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_TEXT = data.Field(sequential=True, tokenize=tokenizer, fix_length=max_len)\n",
    "tt_LABEL = data.Field(sequential=False, use_vocab=False) # use_vocab=False if labels are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = TextMultiLabelDataset.splits(tt_TEXT, tt_LABEL, train_df, \n",
    "                                      'comment_text', label_cols + ['none'], val_df, test_df)\n",
    "\n",
    "# splits = TextMultiLabelDataset.splits(tt_TEXT, tt_LABEL, train_df, \n",
    "#                                       txt_col, label_cols, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.0,\n",
       " \"Nonsense ? kiss off , geek . what I said is true . I ' ll have your account terminated .\")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------ multi-label problem ------\n",
    "t = splits[0].examples[0]\n",
    "t.toxic, t.insult, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_TEXT.build_vocab(splits[0], max_size=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10784, 20002, 7)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = TextMultiLabelData.from_splits(PATH, splits, bsz, text_name='text', label_names=label_cols + ['none'])\n",
    "# md = TextMultiLabelData.from_splits(PATH, splits, bsz, text_name='text', label_names=label_cols)\n",
    "\n",
    "len(md.trn_dl), md.nt, md.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab a batch and make sure it looks as expected (e.g., size and datatypes)\n",
    "\n",
    "NOTE: After playing with a batch like this, reset your iterator (`md.val_dl.it.close()`).  When I went back to training after looking at a batch, though the predictions would be different for each label, they would be identical for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 7]), Variable containing:\n",
       "     0     0     0     0     0     0     1\n",
       "     1     1     1     0     0     0     0\n",
       "     0     0     0     0     0     0     1\n",
       "     0     0     0     0     0     0     1\n",
       "     0     0     0     0     0     0     1\n",
       " [torch.cuda.FloatTensor of size 5x7 (GPU 0)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(), y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.val_dl.it.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground for seeing what a torchtext field gives us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['<unk>', '<pad>', '.', ',', 'the', '\"', 'to', 'I', 'of', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(tt_TEXT.vocab.stoi[tt_TEXT.pad_token])\n",
    "print(tt_TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 369968),\n",
       " (',', 256529),\n",
       " ('the', 242333),\n",
       " ('\"', 210215),\n",
       " ('to', 157588),\n",
       " ('I', 121070),\n",
       " ('of', 119718),\n",
       " (\"'\", 118690),\n",
       " ('and', 114839),\n",
       " ('a', 110598)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('most common words: ')\n",
    "tt_TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least common words: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Bovineboy', 1),\n",
       " ('aggio', 1),\n",
       " ('SvWp', 1),\n",
       " ('alums', 1),\n",
       " ('pantsed', 1),\n",
       " ('Heonsi', 1),\n",
       " ('R41', 1),\n",
       " ('trotting', 1),\n",
       " ('plskthxbai', 1),\n",
       " ('wahabi', 1)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('least common words: ')\n",
    "tt_TEXT.vocab.freqs.most_common()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LstmClassifier(md.nt, n_fac, bsz, [512, 256], [0.4, 0.2],\n",
    "                   n_hidden, n_lstm_layers=1, out_sz=md.c, is_multi=True, use_bn=True).cuda()\n",
    "\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c3fa5ff80046e280a8a7c33437f4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, train_loss: 0.101189, val_loss: 0.107058              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, lo.opt, F.binary_cross_entropy) \n",
    "# use F.binary_cross_entropy for multi-label problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14210f0b2c948ce924dc53914672f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, train_loss: 0.086670, val_loss: 0.101966              \n",
      "epoch:   1, train_loss: 0.115624, val_loss: 0.105787              \n",
      "epoch:   2, train_loss: 0.063796, val_loss: 0.099387              \n",
      "epoch:   3, train_loss: 0.096943, val_loss: 0.120711              \n",
      "epoch:   4, train_loss: 0.088000, val_loss: 0.097374              \n",
      "epoch:   5, train_loss: 0.092271, val_loss: 0.089704              \n",
      "epoch:   6, train_loss: 0.068992, val_loss: 0.092155              \n",
      "epoch:   7, train_loss: 0.109500, val_loss: 0.092864              \n",
      "epoch:   8, train_loss: 0.078277, val_loss: 0.103546              \n",
      "epoch:   9, train_loss: 0.072766, val_loss: 0.094332              \n",
      "epoch:  10, train_loss: 0.096662, val_loss: 0.094484              \n",
      "epoch:  11, train_loss: 0.087408, val_loss: 0.099717              \n",
      "epoch:  12, train_loss: 0.093081, val_loss: 0.093246              \n",
      "epoch:  13, train_loss: 0.071157, val_loss: 0.106066              \n",
      "epoch:  14, train_loss: 0.070634, val_loss: 0.093239              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4 cycles of len 1, 2, 4, 8\n",
    "\n",
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}/models/multi-label-cyc_{cycle}-of-4')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 2**4-1, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dcc697fd94400ba9b9d17ddecdbe63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, train_loss: 0.116827, val_loss: 0.098823              \n",
      "epoch:   1, train_loss: 0.083464, val_loss: 0.097865              \n",
      "epoch:   2, train_loss: 0.086959, val_loss: 0.095516              \n",
      "epoch:   3, train_loss: 0.079783, val_loss: 0.098271              \n",
      "epoch:   4, train_loss: 0.104110, val_loss: 0.093550              \n",
      "epoch:   5, train_loss: 0.081411, val_loss: 0.092314              \n",
      "epoch:   6, train_loss: 0.067334, val_loss: 0.093089              \n",
      "epoch:   7, train_loss: 0.081514, val_loss: 0.095191              \n",
      "epoch:   8, train_loss: 0.090165, val_loss: 0.105924              \n",
      "epoch:   9, train_loss: 0.072762, val_loss: 0.090905              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 cycle of len 10\n",
    "\n",
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}/models/multi-label-2-cyc_{cycle}-of-1')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl) * 10, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 10, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(m, f'{PATH}/models/multi-label-2-cyc_0-of-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 153164, 86266, 9585)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(m, md.test_dl)\n",
    "len(preds), len(test_df), len(train_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.649353</td>\n",
       "      <td>0.049358</td>\n",
       "      <td>0.365194</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.340106</td>\n",
       "      <td>0.056535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.610632</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.306081</td>\n",
       "      <td>0.050376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.585741</td>\n",
       "      <td>0.037411</td>\n",
       "      <td>0.296549</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>0.285878</td>\n",
       "      <td>0.046867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.573432</td>\n",
       "      <td>0.035507</td>\n",
       "      <td>0.284552</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.276321</td>\n",
       "      <td>0.045241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.571875</td>\n",
       "      <td>0.035274</td>\n",
       "      <td>0.283062</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.275132</td>\n",
       "      <td>0.045040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.571877</td>\n",
       "      <td>0.035275</td>\n",
       "      <td>0.283064</td>\n",
       "      <td>0.018724</td>\n",
       "      <td>0.275134</td>\n",
       "      <td>0.045041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283032</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275108</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.770773</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>0.530578</td>\n",
       "      <td>0.031454</td>\n",
       "      <td>0.464476</td>\n",
       "      <td>0.080382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.586869</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.297668</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>0.286768</td>\n",
       "      <td>0.047019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.818939</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.609379</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>0.523440</td>\n",
       "      <td>0.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035269</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.035270</td>\n",
       "      <td>0.283031</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.275107</td>\n",
       "      <td>0.045036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "153144  fff7159b3ee95618  0.649353  0.049358      0.365194  0.023031   \n",
       "153145  fff718ffe5f05559  0.610632  0.041627      0.322034  0.020729   \n",
       "153146  fff7fc22a0cdccd3  0.585741  0.037411      0.296549  0.019412   \n",
       "153147  fff83b80284d8440  0.573432  0.035507      0.284552  0.018799   \n",
       "153148  fff8ef316d0c6990  0.571875  0.035274      0.283062  0.018724   \n",
       "153149  fff8f521a7dbcd47  0.571877  0.035275      0.283064  0.018724   \n",
       "153150  fff8f64043129fa2  0.571843  0.035270      0.283032  0.018722   \n",
       "153151  fff9d70fe0722906  0.010160  0.000140      0.001615  0.000220   \n",
       "153152  fff9fa508f400ee6  0.770773  0.086369      0.530578  0.031454   \n",
       "153153  fffa3fae1890b40a  0.586869  0.037591      0.297668  0.019469   \n",
       "153154  fffa8a11c4378854  0.571843  0.035270      0.283031  0.018722   \n",
       "153155  fffac2a094c8e0e2  0.010160  0.000140      0.001615  0.000220   \n",
       "153156  fffb5451268fb5ba  0.571843  0.035270      0.283031  0.018722   \n",
       "153157  fffc2b34bbe61c8d  0.571843  0.035270      0.283031  0.018722   \n",
       "153158  fffc489742ffe69b  0.571843  0.035270      0.283031  0.018722   \n",
       "153159  fffcd0960ee309b5  0.571843  0.035270      0.283031  0.018722   \n",
       "153160  fffd7a9a6eb32c16  0.818939  0.109268      0.609379  0.034883   \n",
       "153161  fffda9e8d6fafa9e  0.571843  0.035269      0.283031  0.018722   \n",
       "153162  fffe8f1340a79fc2  0.571843  0.035269      0.283031  0.018722   \n",
       "153163  ffffce3fb183ee80  0.571843  0.035270      0.283031  0.018722   \n",
       "\n",
       "          insult  identity_hate  \n",
       "153144  0.340106  0.056535       \n",
       "153145  0.306081  0.050376       \n",
       "153146  0.285878  0.046867       \n",
       "153147  0.276321  0.045241       \n",
       "153148  0.275132  0.045040       \n",
       "153149  0.275134  0.045041       \n",
       "153150  0.275108  0.045036       \n",
       "153151  0.001886  0.000415       \n",
       "153152  0.464476  0.080382       \n",
       "153153  0.286768  0.047019       \n",
       "153154  0.275107  0.045036       \n",
       "153155  0.001886  0.000415       \n",
       "153156  0.275107  0.045036       \n",
       "153157  0.275107  0.045036       \n",
       "153158  0.275107  0.045036       \n",
       "153159  0.275107  0.045036       \n",
       "153160  0.523440  0.091500       \n",
       "153161  0.275107  0.045036       \n",
       "153162  0.275107  0.045036       \n",
       "153163  0.275107  0.045036       "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = pd.DataFrame(data=preds, columns=label_cols) # -- if \"none\" included\n",
    "# subm_df = pd.DataFrame(data=preds[:,:6], columns=label_cols) # -- if \"none\" included\n",
    "\n",
    "subm_df.insert(0, 'id', test_df.id)\n",
    "subm_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 153164)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.to_csv(f'{PATH}/multi-label_sub-removed-none-label.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Classification Problem\n",
    "\n",
    "Predict a class probabilities where a single class is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(raw_train_df), val_pct=0.20)\n",
    "\n",
    "train_df =  raw_train_df.drop(val_idxs)\n",
    "val_df = raw_train_df.copy().iloc[val_idxs]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure our targets are strings (torchtext will automatically build categorical embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[label_cols + ['none']] = train_df[label_cols + ['none']].astype(str)\n",
    "val_df[label_cols + ['none']] = val_df[label_cols + ['none']].astype(str)\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using the target's unique string values to define our categories, set `use_vocab=True`.  For this example, it will return 3 values for each of the following 3 classes ('<unk>', '0', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_TEXT = data.Field(sequential=True, tokenize=tokenizer, fix_length=max_len)\n",
    "tt_LABEL = data.Field(sequential=False, use_vocab=True) # use_vocab=False if labels are numerical\n",
    "\n",
    "splits = TextMultiLabelDataset.splits(tt_TEXT, tt_LABEL, train_df, 'comment_text', [target_col], val_df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_TEXT.build_vocab(splits[0], max_size=max_tokens)\n",
    "\n",
    "md = TextMultiLabelData.from_splits(PATH, splits, bsz, text_name='text', label_names=[target_col])\n",
    "\n",
    "len(md.trn_dl), md.nt, md.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ multi-class problem ------\n",
    "t = splits[0].examples[0]\n",
    "t.toxic, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "y.size(), y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LstmClassifier(md.nt, n_fac, bsz, [512, 256], [0.4, 0.2],\n",
    "                   n_hidden, n_lstm_layers=1, out_sz=md.c, use_bn=True).cuda()\n",
    "\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2)]#, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl)*10)]#, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 10, lo.opt, F.nll_loss, callbacks=cb, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 3. Regression Problem\n",
    "\n",
    "Predict a single continuous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_col = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(raw_train_df), val_pct=0.20)\n",
    "\n",
    "train_df =  raw_train_df.drop(val_idxs)\n",
    "val_df = raw_train_df.copy().iloc[val_idxs]\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ensure correct datatypes for our target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df[label_cols + ['none']] = train_df[label_cols + ['none']].astype(np.float32)\n",
    "val_df[label_cols + ['none']] = val_df[label_cols + ['none']].astype(np.float32)\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set `use_vocab=False` since we are predicting a single number (a regression problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tt_TEXT = data.Field(sequential=True, tokenize=tokenizer, fix_length=max_len)\n",
    "tt_LABEL = data.Field(sequential=False, use_vocab=False) # use_vocab=False if labels are numerical\n",
    "\n",
    "splits = TextMultiLabelDataset.splits(tt_TEXT, tt_LABEL, train_df, 'comment_text', [target_col], val_df, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tt_TEXT.build_vocab(splits[0], max_size=max_tokens)\n",
    "\n",
    "md = TextMultiLabelData.from_splits(PATH, splits, bsz, text_name='text', label_names=[target_col])\n",
    "\n",
    "len(md.trn_dl), md.nt, md.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ------ multi-class problem ------\n",
    "t = splits[0].examples[0]\n",
    "t.toxic, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "y.size(), y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "m = LstmClassifier(md.nt, n_fac, bsz, [512, 256], [0.4, 0.2],\n",
    "                   n_hidden, n_lstm_layers=1, out_sz=md.c, y_range=(0,1), use_bn=True).cuda()\n",
    "\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fit(m, md, 1, lo.opt, F.mse_loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2)]#, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 2**4-1, lo.opt, F.mse_loss, callbacks=cb, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl)*10, cycle_mult=2)]#, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 10, lo.opt, F.mse_loss, callbacks=cb, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(splits[0], batch_size=32, device=0, sort_key=lambda ex: len(ex.text))\n",
    "vars(next(iter(train_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_iter = iter(md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(batch_iter) # x, y\n",
    "p = m(V(b[0]))       # predictions\n",
    "\n",
    "print(b[0].size(), b[1].size(), p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 25 predictions and actuals\n",
    "p[:25], b[1][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the text of the 7th example\n",
    "# b[0] = training data\n",
    "# b[0][:,6] = give me all values of column 6; remember with bptt the shape = \n",
    "\n",
    "' '.join(tt_TEXT.vocab.itos[i] for i in b[0][:,6].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT - close iterator when done!!!\n",
    "md.val_dl.it.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
